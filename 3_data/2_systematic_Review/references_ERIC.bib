@techreport{.2014,
  title = {Guidance {{Materials}} to {{Support}} the {{Use}} of {{Hawai}}'i-{{Specific}}, {{Publicly Available Data Sources}}},
  year = {2014},
  institution = {{Regional Educational Laboratory Pacific}},
  abstract = {Effective evidence-based action requires getting the right data into the right hands at the right time to help make decisions. The Data Quality Campaign (2011) has provided suggestions to state education agencies for effectively using data within state longitudinal data systems. One suggestion is to identify "the variety of ways available data can be used and the types of analyses required to answer critical policy questions". In addition to answering policy questions, publicly available data sources have the potential to assist educators, policy makers, and other education stakeholders in Hawai'i with making evidence-based decisions related to education policy, programming, and support. As such, this document provides guidance to education researchers on how to access publicly available data sources, the questions that can be supported by the data sources, and the limitations of the data sources in order to support the advancement of education research and evidence-based decision making in Hawai'i. To identify available sources of publicly available data specific to Hawai'i, REL Pacific researchers solicited recommendations from 2013 Annual Hawaii Partnership for Educational Research Consortium (HPERC) Symposium attendees. REL Pacific researchers examined the list provided by the symposium attendees to identify data sources that were publicly available, Hawai'i-specific, and address at least one of HPERC's nine research priority areas (see Appendix A for the methods used to vet the data sources for inclusion in this document). The nine HPERC priority areas are: (1) Teacher training; (2) Technology-supported curriculum/use of technology in the classroom; (3) English language learner services and support; (4) Teacher evaluation; (5) Graduation rate; (6) Model schools/best practices; (7) NCLB requirement waivers/redefining school success; (8) Instructional time; and (9) Special education services. The data sources included in this document are divided into state and national data sources. Of the 11 state data sources, the Hawaii State Department of Education maintains four, Kamehameha Schools houses three, and the University of Hawai'i (UH) manages four. For the national data sources, the Department of Education maintains two data sources, Department of Health and Human Services houses two data sources, the Department of Labor maintains one data source, the National Science Foundation maintains one data source, and the U.S. Census Bureau houses one data source, totaling seven national data sources. In total, in-depth information on 18 publicly available, Hawai'i-specific data sources that can be used by education researchers to address at least one of HPERC's nine research priority areas is provided in this document. The following are appended: (1) Methodology; (2) Data Source Table; (3) Accountability Data Center; (4) College and Career Readiness Indicators Reports; (5) Hawaii Public Schools Reports for IDEA Part B; (6) Strive HI Performance System; (7) After Graduation Plan for KS Class of 2006; (8) Native Hawaiian Educational Attainment Charts; (9) No Child Left Behind, 2004; (10) Center on the Family Data Center; (11) Hawai'i School Health Survey: Youth Risk Behavior Survey; (12) Institutional Research and Analysis Office; (13) KIDS COUNT Data Center; (14) State Education Data Profiles (Common Core of Data); (15) 2009-10 \& 2011-12 District or School Reports (Civil Rights Data Collection); (16) Detailed Data Tables (Civil Rights Data Collection); (17) State and National Estimations (Civil Rights Data Collection); (18) National Survey of Children with Special Health Care Needs; (19) National Survey of Children's Health; (20) Special Tabulations of U.S. Census Data--Limited English Proficiency; (21) Science and Engineering Indicators 2014 State Data Tool; and (22) U.S. Census Bureau's 2008-2012 American Community Survey 5-Year Estimates.},
  keywords = {Academic Degrees,Access to Information,Accountability,Career Readiness,Census Figures,Child Health,College Readiness,Community Surveys,Data,Early Childhood Education,Educational Attainment,Educational Indicators,Educational Legislation,Elementary Secondary Education,Engineering Education,Enrollment,Federal Legislation,Federal Programs,Hawaiians,High School Graduates,Information Sources,Institutional Characteristics,Limited English Speaking,National Competency Tests,National Surveys,Public Agencies,Public Schools,School Districts,School Effectiveness,Schools,Science Education,Social Indicators,Special Education,State Departments of Education,State Surveys,Universities},
  annotation = {ERIC Number: ED550097}
}

@techreport{.2016,
  title = {Student {{Data Privacy Communications Toolkit}}},
  year = {2016},
  institution = {{Foundation for Excellence in Education (ExcelinEd)}},
  abstract = {Parents expect school districts and schools to keep their children safe while they are in school. That expectation of safety and security also extends to the protection of their children's learning data. Therefore, it is critical that school districts and schools are open and transparent about their student data privacy practices, and that those efforts are clearly communicated to parents and other stakeholder groups. By sharing information on the types of student data collected, the purpose and benefits of collecting this information and the ways in which it is protected, school districts and schools can help dispel misperceptions about student data use and assuage concerns. This student data privacy toolkit provides school districts and schools with recommendations on how to most effectively communicate with parents and other stakeholder groups about student data privacy, as well as a host of communications tools that can be used in these communications efforts. All toolkit resources are generalized for blanket use, so areas in which customized district-specific information are required are in brackets and highlighted in yellow. Districts also need to be sure that their policies, practices and procedures match the recommendations implied throughout the toolkit. Those instances will be noted as well. Be sure to have appropriate school or school district personnel review and approve any communications or materials prior to releasing. This could include, but is not be limited to, the school or school district general counsel and privacy officer. Additionally, while the focus of this toolkit is communicating data privacy practices and plans, demonstrating the value to data to parents is also important. When equipped with the right skills and tools, everyone who plays a role in education can have a strong impact on students and their communities. Parents can be their child's champion along the path to success. Teachers can be sure that their students are really learning what they are teaching. Principals and district administrators can use data to manage schools, allocate resources, and communicate with their communities. Policymakers can create the conditions for success in states and throughout the country. Education data are a powerful tool, but only if they are securely in the hands of the people who need the data, when they need the data. For more resources from Data Quality Campaign (DQC) and others to communicate the power of data to improve a child's education visit the Additional Resources section of this toolkit.},
  keywords = {Access to Information,Child Safety,Childrens Rights,Crisis Management,Data Collection,Educational Legislation,Electronic Mail,Guidelines,Information Dissemination,Information Security,Information Utilization,Letters (Correspondence),Newspapers,Organizational Communication,Parent Materials,Parent Rights,Parent School Relationship,Planning,Privacy,School Policy,Social Media,Student Records,Student Rights},
  annotation = {ERIC Number: ED576931}
}

@techreport{.2019,
  title = {Forum {{Guide}} to {{Planning}} for, {{Collecting}}, and {{Managing Data}} about {{Students Displaced}} by a {{Crisis}}. {{NFES}} 2019-163},
  year = {2019},
  institution = {{National Forum on Education Statistics}},
  abstract = {The purpose of this guide is to provide timely and useful best practice information for collecting and managing data about students who have temporarily or permanently enrolled in another school or district because of a crisis. It includes lessons learned and provides recommendations for collecting and maintaining data about students who may move into or out of a school or district during and following a crisis. This publication builds upon "Crisis Data Management: A Forum Guide to Collecting and Managing Data about Displaced Students," published in 2010. It includes case studies and real-world examples; updates best practices related to collecting and managing education data before, during, and after a crisis based on the severe impacts of recent weather events and other crises; and addresses innovations in education data technology that have changed how education agencies collect, manage, and disseminate data. This guide focuses on crisis data management, with a specific emphasis on data on displaced students, from the perspective of the education data community. [For "Crisis Data Management: A Forum Guide to Collecting and Managing Data about Displaced Students. NFES 2010-804," see ED511639.]},
  keywords = {Check Lists,Crisis Management,Data Collection,Educational Legislation,Elementary Secondary Education,Emergency Programs,Enrollment,Federal Legislation,Information Management,Information Systems,Natural Disasters,Planning,Relocation,Student Mobility},
  annotation = {ERIC Number: ED599381}
}

@techreport{.2021,
  title = {Education {{Sector Analysis}}: {{Using Data}} to {{Evaluate}} the {{Needs}} of {{Kentucky}}'s {{Education Workforce}}},
  year = {2021},
  institution = {{Kentucky Council on Postsecondary Education}},
  abstract = {The Council on Postsecondary Education (Council) is charged with guiding the reform efforts envisioned by state policy leaders in the Kentucky Postsecondary Education Improvement Act of 1997 and is Kentucky's statewide postsecondary and adult education coordinating agency. To gain better insight into economic conditions and workforce trends, specifically within three targeted sectors, the Council partnered with Emsi, a labor market analytics firm serving higher education, economic and workforce development, talent acquisition, and site selection. In this report, Emsi focuses on the Education sector by providing an overview of education occupations and industries through traditional labor market information and a job postings analysis, conducting a program demand gap analysis of Kentucky institutions' education program offerings, and analyzing migration patterns and other qualitative characteristics that help explain why Kentucky education alumni stay in or migrate out of the state. Emsi also provides an environmental scan of the state's economy to provide context for the Education sector. Data around the Education sector are provided for the state and, where pertinent, by region. The regions are based on Kentucky's Workforce Planning Regions (WPRs). In addition, data for the city of Louisville and its surrounding counties, which comprise the Kentuckiana Local Workforce Area (LWA), are shown distinct from the Central WPR.},
  keywords = {COVID-19,Educational Attainment,Elementary School Teachers,Employment Patterns,Family Income,Industry,Labor Force,Labor Force Development,Labor Market,Occupational Information,Pandemics,Postsecondary Education,Poverty,Preschool Teachers,Secondary School Teachers,Socioeconomic Status,Special Education Teachers,Statistics,Unemployment},
  annotation = {ERIC Number: ED615244}
}

@phdthesis{Akoma.2012,
  title = {Decision-{{Making}}, {{Information Communication Technology}}, and {{Data Analysis}} by {{School Leaders}} about {{Student Achievement}}},
  author = {Akoma, Ahunna Margaux},
  year = {2012},
  abstract = {This case study of one school district examined how school leaders use student performance data and technology-based data analysis tools to engage in data-informed decision-making for continuous improvement. School leaders in this context included leaders at the district, school, and classroom levels. An extensive literature review provided the framework for this study including Brunner, Fasca, Heinze, Honey, Light, Mardinach, and Wexler (2005), Knapp, Swinnerton, Copland, and Monpas-Huber (2006), Mandinach, Honey, Light, Heinze, and Nudell (2005), Mandinach, Honey, and Light (2006), Marsh, Pane, and Hamilton (2006), National Education Technology Trends Survey (2005, 2007), among others. Though data-informed decision-making is not a new concept in industry or education, the data-reporting demands of the No Child Left Behind Act has fueled districts' investments in technology and data analysis tools. The case study employed a mixed data collection approach. Qualitative data were collected through interviews of 12 leaders (1 superintendent, 1 technology leader, 2 principals, 2 curriculum coordinators, 2 instructional specialists, and 4 lead teachers), and review of district documents. Quantitative data were collected through an online survey of the teachers in the district to validate or triangulate portions of the interview data. Qualitative data were analyzed at various levels of descriptive analyses, in which codes were generated, organized, and grouped into analytical categories. Findings showed that leaders used various forms of data to make various types of decisions. The district provided the tools and training. In addition, leaders' organizational roles or levels impacted the forms of data they used and the types of decisions made. Organizational roles also impacted leaders' perceptions of which environmental factors (political, economic, cultural, and technological) influenced their use of student data to make decisions. A culture of data use was more prevalent among accountability workgroups such as English, math, and science teachers--evidence that political forces influence teachers' data use. Cultural and human resource capacities were developed through professional learning communities and early release days. Teachers had time but wanted more time. District Y is modeled after best practices. Recommendations were made for all stakeholders as well as the government and schools of education. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {9781267950772},
  school = {Columbia University},
  keywords = {Academic Achievement,Case Studies,Data,Data Analysis,Decision Making,Elementary Secondary Education,Information Technology,Interviews,Leaders,Mixed Methods Research,Online Surveys,School Districts},
  annotation = {ERIC Number: ED552086}
}

@article{Albiladi.etal.2020,
  title = {Data {{Use}} among {{Principals}} and {{Teachers}}: {{Divergent Paths}} or {{Common Ground}}? {{Implications}} for the {{Leadership Preparation Programs}}},
  author = {Albiladi, Waheeb S. and Lasater, Kara and Bengtson, Ed},
  year = {2020},
  journal = {Journal of School Administration Research and Development},
  volume = {5},
  number = {2},
  pages = {63--76},
  issn = {2470-8496},
  abstract = {This study examines teachers' and administrators' use of data to inform their practice in one south-central state. Using a qualitative research approach, the study involved 76 educators representing eight school districts. Data were collected using focus groups with teachers and in-depth interviews with school principals. Data were inductively and deductively analyzed using multiple cycles of coding. Analysis of data revealed three themes that exposed differences in the use of data by teachers and administrators: the challenges of data use, the "levels" at which data are viewed (micro and macro lenses), and the value placed on formal and informal data. Findings suggest that by understanding the differences between teachers' and administrators' perspectives on data use and recognizing the common ground that unites their perspectives, schools can create data cultures that foster shared expectations, collaboration, and trust between teachers and administrators.},
  langid = {english},
  keywords = {Administrator Attitudes,Barriers,Data Use,Decision Making,Elementary School Teachers,Expectation,Leadership Training,Principals,Public Schools,School Culture,Secondary School Teachers,Teacher Administrator Relationship,Teacher Attitudes,Time Management,Trust (Psychology)},
  annotation = {ERIC Number: EJ1301180}
}

@phdthesis{ALFaresi.2011,
  title = {Risk-{{Based Models}} for {{Managing Data Privacy}} in {{Healthcare}}},
  author = {AL Faresi, Ahmed},
  year = {2011},
  abstract = {Current research in health care lacks a systematic investigation to identify and classify various sources of threats to information privacy when sharing health data. Identifying and classifying such threats would enable the development of effective information security risk monitoring and management policies. In this research I put the first step towards identifying and classifying privacy threats from a selection of health data exchange scenarios. Specifically I investigate data sharing scenarios that occur within a health care organization, between a health organization and a research group, and between patients and online social networks. I first derive the privacy requirements from legislative laws for protecting patient privacy in the U.S., namely the Health Insurance Portability and Accountability Act (HIPAA). Using the derived requirements I develop methods to enforce them in the data sharing scenarios specified. I use risk modeling to quantify the privacy threat in each sharing scenario and I incorporate that risk intelligence to develop security solutions to counteract the vulnerabilities found.    I found that sharing health data within a care entity is vulnerable to breaches by authorized users. I developed a risk-scoring model, that profiles authorized healthcare employees based on their tendency to commit privacy breaches. I also found that current access control models that handle health data lack the necessary conditions to enforce HIPAA rules and to involve patients in the management of data. In response I designed an access control framework that enforces HIPAA rules and preserves data privacy when it is shared among authorized users. The access control model makes use of automated object policies that allows patients to set their privacy preferences regarding how data is disclosed and shared.    I identified a privacy vulnerability when genomic data is shared for secondary usage using a real case study. The vulnerability allows the re-identification of contributors to genomic studies by combining information from publicly available data with the geographical location of the study participants. Knowledge of location can be explicitly stated in published results or implicitly inferred from the collection point (i.e. requesting data from a known location). In response I proposed a security protocol to anonymously share medical sequencing data and demonstrated that the risk of re-identification can be reduced with the proposed technique while keeping the fidelity of the data intact.    Finally I identified a privacy vulnerability when patients share data on health social networks, by exploiting the fact that they reuse their pseudonyms in other social networks that contain identifying information about them. A Bayesian model was used to estimate risk, and the method of re-identification was demonstrated empirically. I propose a set of heuristics to reduce the risk of this privacy vulnerability.    [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {9781267100429},
  school = {George Mason University},
  keywords = {Access to Information,Case Studies,Classification,Compliance (Legal),Computer System Design,Federal Legislation,Genetics,Health Personnel,Health Services,Identification,Information Management,Information Policy,Information Security,Information Technology,Internet,Models,Patients,Policy Formation,Preferences,Privacy,Risk,Risk Management,Social Networks},
  annotation = {ERIC Number: ED540374}
}

@techreport{Allard.etal.2016,
  title = {The {{Open Data Imperative}}: {{How}} the {{Cultural Heritage Community Can Address}} the {{Federal Mandate}}. {{CLIR Publication No}}. 171},
  author = {Allard, Suzie and Lee, Christopher and McGovern, Nancy Y. and Bishop, Alice},
  year = {2016},
  institution = {{Council on Library and Information Resources}},
  abstract = {Data are a valuable national resource for a variety of stakeholders across all sectors of society. Dramatic advances in information and communication technology have opened up unprecedented opportunities for broad public access, innovative research, and citizen engagement, but this potential can be realized only if data are properly managed and exposed over time. New U.S. government requirements for exposing and managing federally funded research data add urgency to the call for curating data so that they can be used, re-used, and exploited by future generations. These new requirements have significant implications for cultural heritage institutions in addressing the current deficit in the capacity to support the re-use of data over time and across generations of technology (digital curation) and in enabling collaboration based on shared infrastructure. Cultural heritage encompasses various types of artifacts (analog or digital), as well as attributes and behaviors that groups or societies maintain over time to preserve connections to the past, present, and future. Cultural heritage institutions have a mission to support, perpetuate, and provide access to essential elements of culture as a whole. There are many different types of cultural heritage institutions, but three of the most commonly recognized are libraries, archives, and museums. Materials in their care are vital to the ongoing advancement and perpetuation of the sciences, social sciences, arts, and humanities. This report presents the implications for the cultural heritage community of the recent focus on creating public access to data and publications resulting from federal funding, and our recommendations for relevant stakeholders. The recommendations are based on a review of federal agencies' responses to new government requirements, case studies of seven digital curation projects, and an investigation of the current professional capacity for the long-term management of cultural heritage digital content, including data. The following are appended: (1) Analysis of Public Access Plans: Research Design and Methods; (2) Links to Federal Department and Agency Public Access Plans Used for This Report; (3) Projects on Digital Curation Curriculum and Skills Development Funded by the Institute of Museum and Library Services, 2004-2015; (4) Competency Categories and Skills Defined for the Four Curriculum Models; and (5) Job Postings to the American Library Association (ALA) DigiPres Electronic Mailing List, 2013-2015.},
  isbn = {9781932326567},
  keywords = {Access to Information,Alignment (Education),Appropriate Technology,Archives,Capacity Building,Curriculum Development,Data,Federal Aid,Federal Regulation,Heritage Education,Information Management,Information Policy,Information Services,Libraries,Minimum Competencies,Museums,Occupational Information,Program Implementation,Qualitative Research,Semi Structured Interviews,Statistical Analysis,Technology Planning},
  annotation = {ERIC Number: ED568755}
}

@phdthesis{Apple.2017,
  title = {How the {{Adoption}} of the {{Big-Data Paradigm Affects}} the {{Key Factors That Influence}} the {{Effectiveness}} of an {{Information Assurance}} ({{IA}}) {{Framework}}: {{A Multiple-Case Study}}},
  author = {Apple, Benjamin G.},
  year = {2017},
  abstract = {This qualitative study identified those factors that influence the perceived effectiveness of traditional IA control frameworks. The key factors examined in this study are risk management, governance, access control, privacy protection, integrity, availability, reliability, and usability. The researcher endeavored to determine how the effectiveness of the factors of effectiveness is impacted when the IA frameworks are applied to a big-data environment within the context of the unified theory of acceptance and use of technology (UTAUT) Model. The multiple-case study approached the issue from the perspective of three operational groups, senior decision makers, information assurance professionals, and information security practitioners across three organizations. Data was gathered by face-to-face interview, direct observation, and historic documentation review. Gathered data was processed and evaluated by use of the NVivo 10 software process. The data gathered and analyzed during the multiple-case study leads one to infer that traditional IA control frameworks are engineered to take advantage of the foundational controls of a traditional network-centric data base environment. In a traditional data base environment, the data base management software provides controls such as read/write, content type, and audit logging which are the foundation for the keys of effectiveness. In a big data environment, those foundational controls must be provided by intention through policy, structure, or performance agreement, as opposed to by implementation. Thus, while the key factors of traditional controls are perceived as structurally sound and effective, to remain effective in a big data environment traditional controls and their associated key factors require some level of re-engineering. Or, as in the case of training, greater application is required to gain the perception of trust in a big data environment. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {9781369617054},
  school = {Capella University},
  keywords = {Case Studies,Data,Governance,Influences,Information Security,Integrity,Privacy,Qualitative Research,Reliability,Risk Management,Usability},
  annotation = {ERIC Number: ED575457}
}

@article{Arnold.etal.2023,
  title = {Exploring {{Core Ideas}} of {{Procedural Understanding}} in {{Scientific Inquiry Using Educational Data Mining}}},
  author = {Arnold, Julia C. and M{\"u}hling, Andreas and Kremer, Kerstin},
  year = {2023},
  journal = {Research in Science \& Technological Education},
  volume = {41},
  number = {1},
  pages = {372--392},
  issn = {1470-1138},
  abstract = {Background: Scientific thinking is an essential learning goal of science education and it can be fostered by inquiry learning. One important prerequisite for scientific thinking is procedural understanding. Procedural understanding is the knowledge about specific steps in scientific inquiry (e.g. formulating hypotheses, measuring dependent and varying independent variables, repeating measurements), and why they are essential (regarding objectivity, reliability, and validity). We present two studies exploring students' ideas about procedural understanding in scientific inquiry using Concept Cartoons. Concept Cartoons are cartoon-like drawings of different characters who have different views about a concept. They are to activate students' ideas about the specific concept and/or make them discuss them. Purpose: The purpose of this paper is to survey students' ideas of procedural understanding and identify core ideas of procedural understanding that are central for understanding scientific inquiry. Design and methods: In the first study, we asked 47 students about reasons for different steps in inquiry work via an open-ended questionnaire using eight Concept Cartoons as triggers (e.g. about the question why one would need hypotheses). The qualitative analysis of answers revealed 42 ideas of procedural understanding (3-8 per Cartoon). We used these ideas to formulate a closed-ended questionnaire that contained the same Concept Cartoons, followed by statements with Likert-scales to measure agreement. In a second study, 64 students answered the second questionnaire as well as a multiple-choice test on procedural understanding. Results: Using methods from educational data mining, we identified five central statements, all emphasizing the concept of confounding variables: (1) One needs alternative hypotheses, because there may be other variables worth considering as cause. (2) The planning helps to take into account confounding variables or external circumstances. (3) Confounding variables should be controlled since they influence the experiment/the dependent variable. (4) Confounding variables should be controlled since the omission may lead to inconclusive results. (5) Confounding variables should be controlled to ensure accurate measurement. Conclusions We discuss these ideas in terms of functioning as core ideas of procedural understanding. We hypothesize that these core-ideas could facilitate the teaching and learning of procedural understanding about experiments, which should be investigated in further studies.},
  langid = {english},
  keywords = {Active Learning,Cartoons,Concept Formation,Data Analysis,Educational Research,Hypothesis Testing,Inquiry,Knowledge Level,Science Education,Science Experiments,Science Instruction,Science Process Skills,Scientific Concepts,Teaching Methods},
  annotation = {ERIC Number: EJ1381351}
}

@techreport{Baenen.2013,
  title = {Limited {{English Proficient Students}}: {{Progress}} of 2008-09 {{High School Cohort}}. {{Data Trends}}. {{D}}\&{{A Report No}}. 13.14},
  author = {Baenen, Nancy},
  year = {2013},
  institution = {{Wake County Public School System}},
  abstract = {Students with Limited English Proficiency (LEP) entering U.S. schools in grade 9 face a tight timeline to simultaneously learn English and graduate from high school in four or five years. This study focuses on student outcomes and progress indicators for the cohort of ninth graders new to WCPSS in 2008-09 who had limited English proficiency. Based on the cohort of LEP students who entered WCPSS for the first time in grade 9 in 2008-09 and did not transfer out, 46\% graduated within 4.5 years. Some (17\%) graduated while still LEP. Cohort graduates tended to start ninth grade with greater initial English proficiency, strong educational backgrounds obtained elsewhere, or high motivation and support. Unfortunately, 41\% of the cohort dropped out of high school. Early warning indicators include not passing required courses and being retained (only one third of the cohort was able to be promoted every year). Only 20\% participated in ESL support programs outside of school (36\% of those with the lowest English proficiency participated). The following are appended: (1) Four Year Graduation Rates by LEP Status 2011-12 (2008-09 cohort); (2) 2008-09 Grade 9 LEP Cohort Description; (3) LEP Case Study Questions; (4) Breakdown of K-12 LEP MOEs for 2013-14 by Half Positions; and (5) Extra Supports offered by Schools.},
  keywords = {Academic Support Services,After School Programs,Background,Dropout Rate,Dropouts,Grade 9,Graduation Rate,High School Graduates,High School Students,Interviews,Language Proficiency,Language Teachers,Limited English Speaking,Mathematics Achievement,Progress Monitoring,Qualitative Research,Reading Achievement,Scores,Second Language Learning,Secondary School Teachers,Student Characteristics,Student Motivation,Student Participation,Summer Programs,Teacher Attitudes},
  annotation = {ERIC Number: ED559203}
}

@article{Bardez.1973,
  title = {Data {{Processing Requirements}} for {{School Desegregation}}: {{A Case Study}} of the {{San Francisco Unified School District}}.},
  author = {Bardez, Joan},
  year = {1973},
  abstract = {The goal of this report is to introduce the kinds of data and the kinds of reports which are useful in the process of desegregating schools. In September of 1971, the San Francisco Unified School District desegregated its elementary schools. That it was able to open these schools in semi-normal fashion was due in large part to the services provided by the District's Data Processing Department. This report is intended to serve as a guidebook for Data Processing personnel in other school districts who may be faced with a similar situation. One fundamental change which is made necessary by school desegregation is the evaluation and development of new student assignments to schools based on the racial/ethnic distribution of students. The desegregation plan which had been developed  during the spring of 1971 and accepted by the Court in July organized the City into seven geographic areas or "zones." School assignments are made by Census block. The close to 100 elementary schools which had been previously organized as kindergarten through grade six now were converted to "primary" (i.e., kindergarten to grade three) or "intermediate" (grades four to six.). This required the re-evaluation of school sites and their suitability for primary and intermediate grade levels. The advantage to changing grade level designation is that most children can be assigned to their local school for at least part of their elementary school years. (Author/JM)},
  keywords = {Data Processing,Desegregation Methods,Educational Environment,Elementary School Students,Information Needs,Reports,School Desegregation,School District Reorganization,School Organization,Secondary School Students,Student Characteristics,Student Placement,Technical Writing,Transfer Programs},
  annotation = {ERIC Number: ED085463}
}

@phdthesis{Beachy.2017,
  title = {Data {{Literacy}} of {{Reading Educators}}: {{Teacher Perception}} and {{Knowledge}} of the {{Use}} of {{Reading Data}} to {{Influence Instruction}}},
  author = {Beachy, Rachel Rayburn},
  year = {2017},
  abstract = {This dissertation is developed around two studies created with the goal of describing and quantifying current educators' knowledge and perceptions of reading assessment and subsequent data-based instructional decision making. Unique to the field, a critical component of this study is an emphasis on educators' development of "data literacy" as a knowledge base necessary to the successful education of students in today's classrooms. Study 1 documents the development and validation of a new survey instrument, the "Perceptions, Knowledge, and Interpretation of Reading Assessment" (PKIRA) survey, to assess the perceptions and knowledge of current educators of reading/language arts in grades PK-12. The final version of the PKIRA consists of five sections and/or subscales; (1) demographics, participants' general experience and perceived instructional preparedness section; (2) teacher perception of reading assessment and instruction subscale; (3) teacher reading assessment knowledge and data literacy subscale; (4) teacher knowledge of language structure subscale; and (5) the teacher ability to use data to drive instruction open ended response section. The reliability and validity of this new instrument were analyzed using exploratory factor analysis, item response theory and inter-item correlations. Results indicate the PKIRA is a reliable and valid instrument to measure the knowledge and perceptions of inservice reading teachers. The purpose of Study 2 was to collect data on the knowledge and perceptions from a unique group of inservice reading educators to further validate the PKIRA and determine which aspects of teacher training or experience were associated with reading content knowledge, reading assessment knowledge and data literacy knowledge. Cronbach's alpha, confirmatory factor analysis, item response theory, and ANOVA were used to analyze the data collected. Results provide further support for instrument validation. Results also indicate participants' certification and master's degree status have no statistically significant differences on their mean knowledge score. However, differences in mean knowledge score were found to be associated with teachers' total years teaching and more strongly with, their total years teaching reading. The value of these studies lies in the creation and validation of a reliable new survey instrument that can be used to support the growth and development of data literacy in current educators nationwide. As the PKIRA can provide extensive data on teacher knowledge and perceptions of reading and reading assessment, those who prepare or supervise educators could use the tool to better differentiate and align their instruction to the ever changing needs of the classroom teachers of today. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {9780355276077},
  langid = {english},
  school = {Texas A\&M University},
  keywords = {Correlation,Data,Decision Making,Demography,Elementary Secondary Education,Evidence Based Practice,Factor Analysis,Information Literacy,Information Utilization,Item Response Theory,Knowledge Base for Teaching,Knowledge Level,Language Arts,Masters Degrees,Readiness,Reading Instruction,Reading Teachers,Reading Tests,Scores,Statistical Significance,Teacher Certification,Teacher Surveys,Teaching Experience,Test Construction,Test Items,Test Reliability,Test Validity},
  annotation = {ERIC Number: ED579408}
}

@techreport{Bellis.2005,
  title = {Education's {{Data Management Initiative}}: {{Significant Progress Made}}, but {{Better Planning Needed}} to {{Accomplish Project Goals}}. {{Report}} to {{Congressional Committees}}. {{GAO-06-6}}},
  author = {Bellis, David},
  year = {2005},
  institution = {{Government Accountability Office}},
  abstract = {As a condition of receiving federal funding for elementary and secondary education programs, states each year provide vast amounts of data to Education. While the need for information that informs evaluation is important (particularly with the No Child Left Behind Act), Education's data gathering has heretofore presented some problems. It has been burdensome to states because there are multiple and redundant requests administered by a number of offices. In addition, the resulting data supplied by states has not been accurate, timely, or conducive to assessing program performance. To improve the information by which it evaluates such programs and also to ease states' reporting burden, Education in 2002 initiated an ambitious, multi-year plan to consolidate elementary and secondary data collections into a single, department-wide system focused on performance. Given its importance, a study, under the authority of the Comptroller General, to provide Congress with information on its progress was prepared. Through its Performance-Based Data Management Initiative (PBDMI), Education has consolidated and defined much of the data it anticipates collecting under a unified system. Education reports that many data definitions have been agreed-to and data redundancies eliminated. PBDMI officials also said that to date, however, it has not been able to resolve all remaining differences among the program offices that manage many of the different data collections. PBDMI officials have conducted extensive outreach to the states to advance the initiative. The outreach to states involved regional conferences, two rounds of site visits, and according to officials, \$100,000 in grants to most states to help offset their costs. State data providers responding to our survey expressed general satisfaction with the department's outreach, but some were not optimistic that the initiative would ease their reporting burden or enhance their own analytic capacity. The states were not able to produce enough data during test submissions in 2003 and 2004 to enable data quality verification or phasing out the department's multiple data collections. With regard to the lack of sufficient data from many states, Education officials said some lack the technical capacity needed to produce new performance data requirements. State data providers reported having competing demands for their time and resources, given other federal initiatives. Education officials have decided to proceed with the undertaking and have developed a draft interim strategy for moving forward. But they currently have no formal plan for how they would overcome obstacles such as the lack of state data and other technical and training delays to the initiative. Appended are: (1) Scope and Methodology; (2) Comments from the Department of Education; and (3) GAO Contact and Staff Acknowledgments.},
  keywords = {Data Analysis,Data Collection,Elementary Secondary Education,Federal Legislation,Federal Programs,Outreach Programs,Program Effectiveness,Program Evaluation,State Departments of Education},
  annotation = {ERIC Number: ED486446}
}

@article{Boaduo.2011,
  title = {Systematic {{Analysis}} and {{Interpretation}} of {{Collected Data}} for a {{Research Study}}: {{A Practical Methodological Framework}} for {{Writing Research Report}}},
  author = {Boaduo, Nana Adu-Pipim},
  year = {2011},
  month = feb,
  journal = {Educational Research and Reviews},
  volume = {6},
  number = {2},
  pages = {140--146},
  issn = {1990-3839},
  abstract = {Two basic data sources required for research studies have been secondary and primary. Secondary data collection helps the researcher to provide relevant background to the study and are, in most cases, available for retrieval from recorded sources. Primary data collection requires the researcher to venture into the field where the study is to take place; armed with the relevant instruments--questionnaire, interview schedules or arranged meetings with the selected population--to solicit the necessary information. Data collected assist the researcher to answer the research questions and address the research problem. The collection, treatment, analysis and interpretation of both secondary and primary data combine to make the researcher produce a report. This paper proposes to present a systematic methodological application where data collected for a research study can be conveniently treated, analysed and interpreted. Attempt to present the collected primary data in both quantitative and qualitative spheres will be made so that researchers who use either method or both are able to apply them confidently. (Contains 3 figures.)},
  langid = {english},
  keywords = {Classification,Data Analysis,Data Collection,Data Interpretation,Hypothesis Testing,Models,Qualitative Research,Questionnaires,Research,Research Methodology,Research Problems,Researchers,Statistics,Writing Research},
  annotation = {ERIC Number: EJ923638}
}

@article{Botvin.etal.2023,
  title = {Data-{{Driven Decision-Making}} in {{Emergency Remote Teaching}}},
  author = {Botvin, Maya and Hershkovitz, Arnon and {Forkosh-Baruch}, Alona},
  year = {2023},
  month = jan,
  journal = {Education and Information Technologies},
  volume = {28},
  number = {1},
  pages = {489--506},
  issn = {1573-7608},
  abstract = {Decision-making is key for teaching, with informed decisions promoting students and teachers most effectively. In this study, we explored data-driven decision-making processes of K-12 teachers (N = 302) at times of emergency remote teaching, as experienced during the COVID-19 pandemic outbreak in Israel. Using both quantitative and qualitative methodologies, and a within-subject design, we studied how teachers' data use had changed during COVID-19~days, and which data they would like to receive for improving their decision-making. We based our analysis of the data on the Universal Design of Learning (UDL) model that characterizes the diverse ways of adapting teaching and learning to different learners as a means of understanding teachers' use of data. Overall, we found a decline in data use, regardless of age or teaching experience. Interestingly, we found an increase in data use for optimizing students' access to technology and for enabling them to manage their own learning, two aspects that are strongly connected to remote learning in times of emergency. Notably, teachers wished to receive a host of data about their students' academic progress, social-emotional state, and familial situations.},
  langid = {english},
  keywords = {Change,COVID-19,Data Use,Decision Making,Elementary School Teachers,Emergency Programs,Foreign Countries,Pandemics,Secondary School Teachers,Student Needs,Teacher Attitudes},
  annotation = {ERIC Number: EJ1363884}
}

@book{Bracey.2000,
  author = {Bracey, Gerald W.},
  year = {2000},
  abstract = {This guide is designed to take the mystery out of educational research data and to help educators become better, and more critical, readers of facts, figures, charts, and graphs about U.S. public schools. Educators will also become better able to answer the questions of parents, students, and the community. A brief historical look at the loss in confidence in the public schools shows how data have been used to create half-truths and erroneous positions. In addition, the most common test forms are analyzed. The chapters are: (1) "Beware of Averages"; 92) "Follow the Money"; (3) "Beware of the Uncritical acceptance of Convenient Conclusions"; (4) "Watch for Selectivity in the Data"; (5) "Show Me the Data!"; (6) "Beware of Nostalgia"; (7) "Beware of Casual Explanations Made from  Correlational Data"; (8) "Be Aware of Whether the Statistics Being Used Are Numbers or Rates (Percentages)"; (9) "Know Whether You're Dealing with Ranks or Scores"; (10) "Make Sure the Statistic Used is the Right One"; (11) "Ask How the Variable Is Defined"; (12) "Ask How the Variable Is Defined--And Then Ask What the Criterion Measure Is"; (13) "Differentiate Practical and Statistical Significance"; (14) "Look for Trends, Not Snapshots"; (15) "Beware of Trends"; (16) "Ask What the Consequences Are Even If the Interpretation of the Data Is True"; (17) "Beware of Changing Demographics"; (18) "Try To 'See Through' Graphs"; (19) "Beware of Big (Small) Numbers"; (20) "Beware of Generalizations"; (21) "The Rise of Testing"; (22) "Types of Tests"; (23) "Other Indicators of Achievement"; (24)"How Come American Students Fall Farther Behind Their International Peers the Longer They Stay in School?"; (25) "Why Are Test Scores Falling?"; (26) "How Come Private Schools Do So Much Better than Public Schools?"; (27) "Why Don't We Have Vouchers so the Money Would Follow the Child?"; (28) "Why Don't We Use Charter Schools as Laboratories for Innovation for the Rest of the System?"; (29) "Why Are We Throwing Money at Schools?"; (30) "Why are SAT Scores Still Falling?"; (31) "Why Don't Bright People Go Into Teaching?"; and (32) "With All This Talk about Standards and Accountability, Why Aren't Teachers and Administrators Held Accountable?" (Contains 157 references.) (SLD)},
  isbn = {0-7619-7603-5},
  keywords = {Data Analysis,Educational Research,Elementary Secondary Education,Information Dissemination,Public Schools,Research Utilization,Test Interpretation},
  annotation = {ERIC Number: ED443860}
}

@phdthesis{Brokes.2010,
  title = {The {{Effect}} of {{Using}} a {{Problem}}/{{Project-Based}}, {{Document Driven Unit}} of {{Instruction}}, on {{High School Students}}' {{Achievement}} on the {{Data Analysis Cluster}} of the {{HSPA}} and on {{Their Attitude}} toward {{Mathematics}} and {{Data Analysis}}},
  author = {Brokes, Joy Cunningham},
  year = {2010},
  abstract = {New Jersey's urban students traditionally don't do well on the high stakes NJ High School Proficiency Assessment. Most current remedial mathematics curricula provide students with a plethora of problems like those traditionally found on the state test. This approach is not working. Finding better ways to teach our urban students may help close this achievement gap. This study examined whether a problem/project-based data analysis unit incorporating the document features of the TI-Nspire would help students master data analysis concepts. The study used a quasi-experimental pre/Post-test design enhanced by a qualitative component. A four-week problem/project based data analysis unit served as the curriculum for the intervention treatment. Students were assigned either the TI-84 or the TI-Nspire calculator. Twelve sections of ninth grade students were divided into four basic study groups: (Intervention (TI-84), Traditional (TI-84), Intervention (TI-Nspire), and Traditional (TI-Nspire)).    The quantitative component of the study analyzed differences between students' pre/post-Total, Multiple-choice, Open-ended mean scores and quantified attitudinal responses. The analysis showed students in the TI-Nspire groups improved more on the Total test and Multiple-choice questions while students in the TI-84 group performed better on Open-ended questions. The Intervention Curriculum was more effective for Multiple-choice questions, Traditional Curriculum for Open-ended questions and Total scores. Student interviews revealed they didn't like taking notes and answering questions on the TI-Nspire. Some students liked referring to the information in the calculator while others felt that accessing information was too time consuming. The merits of the TI-Nspire document feature needs further exploration. Analysis of the quantified attitudinal survey showed an increase in the positive attitudes of students using the TI-Nspire.    Both qualitative and quantitative evidence showed the Traditional TI-84 group had fewer changes in attitude and content knowledge than everyone else combined, suggesting the need to change how we teach data analysis. Problem/project-based learning, if introduced gradually, may prove to be an effective teaching/learning educational practice.    Further exploration needs to match students' technological and data analysis proficiencies when determining readiness for student-centered learning that expects students to be calculator proficient and comfortable with basic quantitative procedures such as finding measures of central tendency and variation.    [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {9781124041100},
  school = {Montclair State University},
  keywords = {Active Learning,Calculators,Data Analysis,Educational Practices,Educational Technology,Grade 9,Intervention,Mathematics Education,Notetaking,Pretests Posttests,Student Attitudes,Student Projects,Teacher Effectiveness,Urban Schools},
  annotation = {ERIC Number: ED517314}
}

@techreport{Brower.etal.2019,
  title = {Big {{Qual}}: {{Defining}} and {{Debating Qualitative Inquiry}} for {{Large Data Sets}}},
  author = {Brower, Rebecca L. and Bertrand Jones, Tamara and {Osborne-Lampkin}, La'Tara and Hu, Shouping and {Park-Gaghan}, Toby J.},
  year = {International Journal of Qualitative Methods 2019},
  volume = {18},
  pages = {1--10},
  institution = {{Grantee Submission}},
  abstract = {Big qualitative data (Big Qual), or research involving large qualitative data sets, has introduced many newly evolving conventions that have begun to change the fundamental nature of some qualitative research. In this methodological essay, we first distinguish big data from big qual. We define big qual as data sets containing either primary or secondary qualitative data from at least 100 participants analyzed by teams of researchers, often funded by a government agency or private foundation, conducted either as a stand-alone project or in conjunction with a large quantitative study. We then present a broad debate about the extent to which big qual may be transforming some forms of qualitative inquiry. We present three questions, which examine the extent to which large qualitative data sets offer both constraints and opportunities for innovation related to funded research, sampling strategies, team-based analysis, and computer-assisted qualitative data analysis software (CAQDAS). The debate is framed by four related trends to which we attribute the rise of big qual: the rise of big quantitative data, the growing legitimacy of qualitative and mixed methods work in the research community, technological advances in CAQDAS, and the willingness of government and private foundations to fund large qualitative projects.},
  langid = {english},
  keywords = {Barriers,Change,Computer Use,Data,Data Analysis,Educational Research,Financial Support,Innovation,Mixed Methods Research,Opportunities,Qualitative Research,Remedial Instruction,Sampling,State Colleges,Statistical Analysis,Technological Advancement},
  annotation = {ERIC Number: ED610530}
}

@article{Caparas.2021,
  title = {Spotlighting {{Whole-Person Success}}: {{A Guide}} for {{Using Statewide Data}} to {{Identify Exemplar Districts}} in {{SEL}} and {{School Climate}}. {{Serving}} the {{Whole Person}}},
  author = {Caparas, Ruthie},
  year = {2021},
  journal = {WestEd},
  abstract = {Across the United States, educators and education leaders are increasingly recognizing the value of social and emotional learning (SEL), school climate, and related whole-person efforts as keys to enabling student success. Many school districts are still exploring or just beginning implementation of these whole-person efforts, and many have expressed the desire for exemplars from which they can learn. This guide aims to support state and regional leaders to identify districts or schools with notably positive outcomes in the areas of SEL and school climate, learn about those exemplars' strategies and experiences, and share their learnings in order to scale up whole-person efforts and outcomes. The report is divided into three sections: (1) Part 1: Quantitative Analyses to Identify Potential Exemplars; (2) Part 2: Qualitative Analysis to Verify and Finalize Exemplars; and (3) Next Steps: Communicate and Scale the Exemplars' Success.},
  keywords = {Academic Achievement,Educational Environment,Elementary Secondary Education,Evaluation Criteria,Guides,Identification,Outcomes of Education,Program Effectiveness,Program Implementation,School Districts,Social Emotional Learning,State Programs},
  annotation = {ERIC Number: ED615980}
}

@article{Champion.2002,
  title = {Sampling {{Can Produce Solid Findings}}: {{Increase Your Effectiveness}} and {{Manage Volumes}} of {{Data}}.},
  author = {Champion, Robby},
  year = {Win 2002},
  journal = {Journal of Staff Development},
  volume = {23},
  number = {1},
  pages = {62--63},
  issn = {0276-928X},
  abstract = {Limiting data collection to a sample group is one way to increase effectiveness in dealing with data. The paper describes how to draw a sample group (random sampling, stratified random sampling, purposeful sampling, and convenient or opportunity sampling) and discusses how to determine the size of the sample group. (SM)},
  langid = {english},
  keywords = {Data Analysis,Data Collection,Elementary Secondary Education,Evaluation Methods,Program Evaluation,Sampling},
  annotation = {ERIC Number: EJ640121}
}

@techreport{Cidade.Lessne.2016,
  title = {Trends in {{Hate-Related Words}} at {{School}} among {{Students Ages}} 12 to 18. {{Data Point}}. {{NCES}} 2016-166},
  author = {Cidade, Melissa and Lessne, Deborah},
  year = {2016},
  institution = {{National Center for Education Statistics}},
  abstract = {Data from the School Crime Supplement (SCS) to the National Crime Victimization Survey, a nationally representative sample survey of students ages 12 through 18, were used to analyze trends in hate-related words. The SCS study is completed every other year. Data from seven consecutive surveys are included in this report: school years 2000-01, 2002-03, 2004-05, 2006-07, 2008-09, 2010-11, and 2012-13. Analysis is restricted to the SCS respondents in each year who were enrolled in grades 6 through 12, and did not receive any part of their education through homeschooling during the school year. In the study, students were asked if they had been called a hate-related word in the school building, on school property, on the school bus, or going to or from school, or if they had seen hate-related graffiti in school. Specifically, students were asked if during the school year anyone called them an insulting or bad name at school having to do with their race, religion, ethnic background or national origin, disability, gender, or sexual orientation (hate-related words). Students were also asked if they had seen any hate-related words or symbols (graffiti) written in school classrooms, school hallways, or outside of the school building. It was found that: (1) Among students between the ages of 12 and 18, the percentages who reported being called a hate-related word or seeing hate-related graffiti at school were lower in 2013 than they were in 2001; and (2) Among students ages 12 through 18 who reported being called a hate-related word at school, the percentage of students called a gender-based hate word decreased from 2001 to 2013, while the percentages of those students called race-, ethnically-, and sexual orientation-based hate words increased.},
  keywords = {Adolescents,Aggression,Antisocial Behavior,Gender Bias,Language Usage,National Surveys,Qualitative Research,Racial Bias,Secondary School Students,Sexual Orientation,Social Bias,Speech Communication,Trend Analysis},
  annotation = {ERIC Number: ED567747}
}

@techreport{Cidade.Lessne.2016a,
  title = {Trends in {{Bullying}} at {{School}} among {{Students Ages}} 12 to 18. {{Data Point}}. {{NCES}} 2016-004},
  author = {Cidade, Melissa and Lessne, Deborah},
  year = {2016},
  institution = {{National Center for Education Statistics}},
  abstract = {Data from the School Crime Supplement (SCS) to the National Crime Victimization Survey, a nationally representative sample survey of students ages 12 through 18, were used to examine trends in bullying at school. The SCS study is completed every other year. Data from five consecutive surveys are included in this report: school years 2004-05, 2006-07, 2008-09, 2010-11, and 2012-13. Analysis is restricted to the SCS respondents in each year who were enrolled in grades 6 through 12, and did not receive any part of their education through homeschooling during the school year. The SCS asks students whether they were bullied in the school building, on school property, on the school bus, or going to or from school. Specifically, students are asked to report being made fun of, called names, or insulted; being the subject of rumors; being threatened with harm; being pushed, shoved, tripped, or spit on; being pressured into doing things they did not want to do; being excluded from activities on purpose; and having property destroyed on purpose. It was found that: (1) The percentage of students ages 12 through 18 who reported being bullied at school was lower in 2013 than every year since 2005. In 2005, 28 percent of students ages 12 through 18 reported being bullied at school. In 2013, the percentage was 22 percent; and (2) The changes in the percentage of students ages 12 through 18 who reported being bullied at school followed a similar pattern among males and females from 2005 to 2013.},
  keywords = {Adolescents,Aggression,Bullying,Crime,Gender Differences,National Surveys,Qualitative Research,Secondary School Students,Speech Communication,Student Behavior,Student Surveys,Victims},
  annotation = {ERIC Number: ED567748}
}

@techreport{Cleveland.Aberton.2015,
  title = {Using {{Video Data}} to {{Research Pedagogic Practices}} in {{New Generation Learning Environments}} in {{Schools}}: {{Development}} of a {{Framework}} for {{Analysing}} and {{Representing Teacher Practice}}},
  author = {Cleveland, Benjamin and Aberton, Helen},
  year = {2015},
  institution = {{Australian Association for Research in Education}},
  abstract = {This paper discusses the use of video data to research pedagogic practices in new generation learning environments (NGLEs) in primary and secondary schools. Using video footage drawn from a collaborative research project between the University of Melbourne and the Victorian Department of Education and Early Childhood Development (2013), the paper charts the development of a framework for analysing and representing teacher practice across a range of NGLEs: learning spaces that provide a greater degree of spatial variation, geographic freedom and access to resources for students and teachers than traditional classrooms. Video of teacher practice collected in four Victorian government schools was used as the basis for developing the framework. This footage was initially coded using Studiocode, a software tool that has been employed to analyse teacher practice in classrooms across the world, including by the International Centre for Classroom Research (ICCR), but not as far as we know used to analyse teacher practice in NGLEs through a human geographic or spatial lens. The paper describes the research methodology, the data collection methods and the analysis framework that was developed to represent data about the 'intersections' between people, space, practice and time i.e. the complex spatialized pedagogic practice of teachers in NGLEs. The practical dilemmas and hurdles that were encountered during the process of developing a simple coding system and visual tool that could represent teacher practice in NGLEs are discussed, along with the final analysis framework and representational tool that arose from the empirical data.},
  keywords = {Educational Research,Elementary Secondary Education,Foreign Countries,Research Methodology,Teaching Methods,Video Technology},
  annotation = {ERIC Number: ED593849}
}

@phdthesis{Cunningham.2012,
  title = {Classroom {{Walkthroughs}} at {{Two Suburban High Schools}}: {{Gathering Data}} to {{Improve Instructional Practice}}},
  author = {Cunningham, Alexa Renee},
  year = {2012},
  abstract = {With changes in federal legislation and the proposed reauthorization of "The Elementary and Secondary Education Act," school administrators are held to high standards in an attempt to improve achievement for all students. They no longer just manage their schools but must now be instructional leaders charged with observing and conferencing with teachers, leading professional development aligned to data, and measuring results. Classroom walkthroughs have become a way of assisting with these tasks while supporting the mission of each school. The purpose of this research was to describe how walkthroughs operate in practice and how they were experienced by school administration, teacher leaders, and teachers at two schools within the same suburban district. Interviews illustrated that experiences were varied using the classroom walkthrough protocol. Continued professional development needed to occur with administrators and teachers. Participants shared their thoughts on implementation and usage, as well as made recommendations to schools and/or districts considering implementing classroom walkthroughs. Results also indicated a great deal of attention paid to the collection of data within the schools but there was less consensus on the analysis and use of the collected data. There was also confusion with teachers as to the vision, purpose, and goals of using classroom walkthroughs. Changes in leadership during the five years since implementation and young administrators, who were relatively new in their positions, helped shape school experiences. Recommendations to schools and/or districts considering implementation focused on support from the district office, a need for help with data collection and analysis, and a clear vision for the use of the protocol. Interviewees mentioned it would benefit districts and schools to develop a shared vocabulary for instructional engagement, alignment, and rigor, as well as a focus for professional development. They also shared the view that calibration conferences and conversations, centered on instruction, provided a focus for teaching and learning within a school and/or district. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {9781267815170},
  school = {Arizona State University},
  keywords = {Administrators,Data Collection,Experience,High Schools,Instructional Improvement,Interviews,Observation,Professional Development,School Administration,Secondary School Teachers,Suburban Schools,Teacher Leadership},
  annotation = {ERIC Number: ED551571}
}

@article{Dalal.2022,
  title = {An {{Exercise}} for {{Teaching Transportation Problem Using Spatial Data}}},
  author = {Dalal, Jyotirmoy},
  year = {2022},
  month = sep,
  journal = {INFORMS Transactions on Education},
  volume = {23},
  number = {1},
  pages = {12--26},
  issn = {1532-0545},
  abstract = {We present an exercise for teaching the transportation problem using a mix of spatial and randomly generated data. It illustrates the potential of using qualitative and quantitative data and is suitable for undergraduate or introductory business school courses on operations research (OR), logistics, and supply chain management. It poses two challenges: (i) given the demand locations and volume, open a certain number of warehouses to ensure customer responsiveness and (ii) given those warehouses with capacity limits, determine an optimal distribution plan that minimizes the total distribution cost. This exercise is developed with the active participation of MBA students in an introductory OR course. The participants, attending the class online from different parts of India during the COVID-19 pandemic, helped generate realistic customer locations by sharing their location data. Visualizing this spatial data (after masking) in Google My Maps helps the students decide on suitable warehouse locations by considering the proximity to customers as well as diverse socioeconomic, political, and environmental factors. Then, using these warehouse and customer data, the optimal distribution plan is obtained by employing OpenSolver. Students appreciate the exposure--starting from data set generation to deriving an optimal solution--offered by this data-driven decision-making exercise.},
  langid = {english},
  keywords = {Business Administration Education,Business Schools,Data,Decision Making,Foreign Countries,Introductory Courses,Online Courses,Operations Research,Problem Solving,Teaching Methods,Transportation,Undergraduate Students},
  annotation = {ERIC Number: EJ1372413}
}

@article{Datnow.etal.2013,
  title = {Affordances and {{Constraints}} in the {{Context}} of {{Teacher Collaboration}} for the {{Purpose}} of {{Data Use}}},
  author = {Datnow, Amanda and Park, Vicki and {Kennedy-Lewis}, Brianna},
  year = {2013},
  journal = {Journal of Educational Administration},
  volume = {51},
  number = {3},
  pages = {341--362},
  issn = {0957-8234},
  abstract = {Purpose: An increasing number of schools and districts across the US are requiring teachers to collaborate for the purpose of data-driven decision making. Research suggests that both data use and teacher collaboration are important ingredients in the school improvement process. Existing studies also reveal the complexities of teacher collaboration and the importance of context in shaping teachers' collaborative work, especially with data. Yet, the intersection of teacher collaboration and data use has been understudied. The purpose of this paper is to examine the affordances and constraints that exist in the context of established teacher collaboration time for the purposes of data-driven decision making. Design/methodology/approach: The paper draws upon qualitative case study data gathered in six schools that structured teacher time for collaboration on data use. Findings: An analysis of the data revealed that a variety of leadership activities and organizational conditions shaped teachers' collaborative work with data. These included leadership focused on thoughtful use of data and the framing of data-driven decision making in terms of collective responsibility; the establishment of norms for teacher collaboration; the implementation of data discussion protocols; and teacher groupings and subject matter subcultures. Originality/value: Knowing how and when a leadership activity or organizational condition becomes either an affordance or a constraint to teacher collaboration around data use has important implications for leadership and educational change. The findings of this study also help to lay the groundwork for future research regarding teacher collaboration around data use. (Contains 1 table.)},
  langid = {english},
  keywords = {Barriers,Case Studies,Context Effect,Data,Decision Making,Elementary School Teachers,Influences,Leadership,Public Schools,Secondary School Teachers,Teacher Collaboration,Time Management},
  annotation = {ERIC Number: EJ1006319}
}

@article{Datnow.Park.2018,
  title = {Opening or {{Closing Doors}} for {{Students}}? {{Equity}} and {{Data Use}} in {{Schools}}},
  author = {Datnow, Amanda and Park, Vicki},
  year = {2018},
  month = may,
  journal = {Journal of Educational Change},
  volume = {19},
  number = {2},
  pages = {131--152},
  issn = {1573-1812},
  abstract = {Ensuring equitable opportunities and outcomes for all students is a top priority of many educators and policymakers across the globe. Data use can be an important lever for achieving equity, but how this can occur is not well understood. In this article, we draw upon knowledge gained in a decade of in-depth qualitative research to examine the ways in which data use helps to open or close doors for students. We discuss data use practices that influence equity goals: (1) accountability-driven data use and data use for continuous improvement; (2) using data to confirm assumptions and using data to challenge beliefs, and (3) tracking and flexible grouping to promote student growth. Along each of these dimensions, there are active decision makers, complex processes of data use at play, and a great deal of variation both within and across contexts. Ultimately, educators and policymakers are faced with critical choices regarding data use that can profoundly affect students' daily educational experiences and trajectories.},
  langid = {english},
  keywords = {Accountability,Data,Educational Improvement,Equal Education,Outcomes of Education,Qualitative Research},
  annotation = {ERIC Number: EJ1179402}
}

@article{Deb.etal.2023,
  title = {The {{UK Psychiatrists}}' {{Experience}} of {{Rationalising Antipsychotics}} in {{Adults}} with {{Intellectual Disabilities}}: {{A Qualitative Data Analysis}} of {{Free-Text Questionnaire Responses}}},
  author = {Deb, Shoumitro and Limbu, Bharati and Nancarrow, Tom and Gerrard, David and Shankar, Rohit},
  year = {2023},
  month = may,
  journal = {Journal of Applied Research in Intellectual Disabilities},
  volume = {36},
  number = {3},
  pages = {594--603},
  issn = {1468-3148},
  abstract = {Background: Overprescribing of off-licence psychotropic medications, particularly antipsychotics, for challenging behaviours in people with intellectual disabilities without a psychiatric disorder is a significant public health concern. In the United Kingdom, the National Health Service England launched an initiative in 2016, 'STopping Over-Medication of People with learning disabilities, autism or both (STOMP)', to address this concern. STOMP is supposed to encourage psychiatrists in the United Kingdom and elsewhere to rationalise psychotropic medication use in people with intellectual disabilities. The current study aims to gather UK psychiatrists' views and experience of implementing the STOMP initiative. Methods: An online questionnaire was sent to all UK psychiatrists working in the field of intellectual disabilities (estimated 225). Two open-ended questions allowed participants to write comments in response to these questions in the free text boxes. One question asked about the challenges psychiatrists faced locally to implement STOMP, and the other asked for examples of successes and positive experiences from the process. The free text data were analysed using a qualitative method with the help of the NVivo 12 plus software. Results: Eighty-eight (estimated 39\%) psychiatrists returned the completed questionnaire. The qualitative analysis of free-text data has shown variation within services in the experience and views of the psychiatrists. In areas with good support for STOMP implementation provided through adequate resources, psychiatrists reported satisfaction in the process with successful antipsychotic rationalisation, better local multi-disciplinary and multi-agency working, and increased awareness of STOMP issues among the stakeholders such as people with intellectual disabilities and their caregivers and multidisciplinary teams, and improved quality of life caused by reduced medication-related adverse events in people with intellectual disabilities. However, where resource utilisation is not optimum, psychiatrists seemed dissatisfied with the process with little success in medication rationalisation. Conclusions: Whereas some psychiatrists are successful and enthusiastic about rationalising antipsychotics, others still face barriers and challenges. Much work is needed to achieve a uniformly positive outcome throughout the United Kingdom.},
  langid = {english},
  keywords = {Adults,Drug Therapy,Experience,Federal Programs,Foreign Countries,Government Role,Intellectual Disability,Program Implementation,Psychiatry},
  annotation = {ERIC Number: EJ1372094}
}

@article{Dierdorp.etal.2011,
  title = {Authentic {{Practices}} as {{Contexts}} for {{Learning}} to {{Draw Inferences}} beyond {{Correlated Data}}},
  author = {Dierdorp, Adri and Bakker, Arthur and Eijkelhof, Harrie and {van Maanen}, Jan},
  year = {2011},
  journal = {Mathematical Thinking and Learning: An International Journal},
  volume = {13},
  pages = {132--151},
  issn = {1098-6065},
  abstract = {To support 11th-grade students' informal inferential reasoning, a teaching and learning strategy was designed based on authentic practices in which professionals use correlation or linear regression. These practices included identifying suitable physical training programmes, dyke monitoring, and the calibration of measurement instruments. The question addressed in this study is: How does a teaching and learning strategy based on authentic practices support students in making statistical inferences about authentic problems with the help of correlation and linear regression? To respond to this question we used video-recordings of lessons, audio-taped interviews, classroom field notes, and student work from a teaching experiment with 12 Dutch students (aged 16-17 years). The analysis provided insights into how the teaching and learning strategies based on authentic practices supported them to draw inferences about authentic problems using correlated data. The evidence illustrates how an understanding of the authentic problem being solved, collecting their own data to become acquainted with the situation, and learning to coordinate individual and aggregate views on data sets seemed to support these students in learning to draw inferences that make sense in the context. (Contains 4 tables and 3 figures.)},
  langid = {english},
  keywords = {Abstract Reasoning,Correlation,Data,Foreign Countries,Grade 11,Instructional Materials,Learning,Mathematics Instruction,Regression (Statistics),Secondary School Students,Statistical Inference,Teaching Methods},
  annotation = {ERIC Number: EJ912315}
}

@article{DMello.etal.2013,
  title = {Proceedings of the {{International Conference}} on {{Educational Data Mining}} ({{EDM}}) (6th, {{Memphis}}, {{Tennessee}}, {{July}} 6-9, 2013)},
  author = {D'Mello, S. K. and Calvo, R. A. and Olney, A.},
  year = {2013},
  journal = {International Educational Data Mining Society},
  abstract = {Since its inception in 2008, the Educational Data Mining (EDM) conference series has featured some of the most innovative and fascinating basic and applied research centered on data mining, education, and learning technologies. This tradition of exemplary interdisciplinary research has been kept alive in 2013 as evident through an imaginative, exciting, and diverse set of papers spanning the fields of Machine Learning, Artificial Intelligence, Learning Technologies, Education, Linguistics, and Psychology. The following were presented at this sixth installment of the International Conference on Educational Data Mining (EDM 2013), held in Memphis, Tennessee from the 6th to 9th of July 2013: (1) Stealth Assessment in Games: Why, What, and How (Valerie Shute); (2) Discovering the Structure of Mathematical Problem Solving (John R. Anderson); (3) EDM in a Complex and Changing World (Ryan S. J. D. Baker); (4) Limits to Accuracy: How Well Can We Do at Student Modeling? (Joseph Beck and Xiaolu Xiong); (5) Student Profiling from Tutoring System Log Data: When do Multiple Graphical Representations Matter? (Ryan Carlson, Konstantin Genin, Martina Rau and Richard Scheines); (6) Unsupervised Classification of Student Dialogue Acts with Query-Likelihood Clustering (Aysu Ezen-Can and Kristy Elizabeth Boyer); (7) A Spectral Learning Approach to Knowledge Tracing (Mohammad H. Falakmasir, Zachary A. Pardos, Geoffrey J. Gordon and Peter Brusilovsky); (8) Optimal and Worst-Case Performance of Mastery Learning Assessment with Bayesian Knowledge Tracing (Stephen Fancsali, Tristan Nixon and Steven Ritter); (9) Automatically Recognizing Facial Expression: Predicting Engagement and Frustration (Joseph Grafsgaard, Joseph B. Wiggins, Kristy Elizabeth Boyer, Eric N. Wiebe and James Lester); (10) Investigating the Solution Space of an Open-Ended Educational Game Using Conceptual Feature Extraction (Erik Harpstead, Christopher J. MacLellan, Kenneth R. Koedinger, Vincent Aleven, Steven P. Dow and Brad A. Myers); (11) Extending the Assistance Model: Analyzing the Use of Assistance over Time (William Hawkins, Neil Heffernan, Yutao Wang and Ryan S. J. D. Baker); (12) Differential Pattern Mining of Students' Handwritten Coursework (James Herold, Alex Zundel and Thomas Stahovich); (13) Predicting Future Learning Better Using Quantitative Analysis of Moment-by-Moment Learning (Arnon Hershkovitz, Ryan S. J. D. Baker, Sujith M Gowda and Albert T. Corbett; (14) InVis: An Interactive Visualization Tool for Exploring Interaction Networks (Matthew Johnson, Michael Eagle and Tiffany Barnes); (15) Tag-Aware Ordinal Sparse Factor Analysis for Learning and Content Analytics (Andrew Lan, Christoph Studer, Andrew Waters and Richard Baraniuk); (16) Discovering Student Models with a Clustering Algorithm Using Problem Content (Nan Li, William Cohen and Kenneth R. Koedinger); (17) Predicting Player Moves in an Educational Game: A Hybrid Approach (Yun-En Liu, Travis Mandel, Eric Butler, Erik Andersen, Eleanor O'Rourke, Emma Brunskill and Zoran Popovi); (18) Sequences of Frustration and Confusion, and Learning(Zhongxiu Liu, Visit Pataranutaporn, Jaclyn Ocumpaugh and Ryan S. J. D. Baker); (19) Data Mining in the Classroom: Discovering Groups Strategies at a Multi-Tabletop Environment (Roberto Martinez-Maldonado, Kalina Yacef and Judy Kay); (20) Meta-Reasoning Algorithm for Improving Analysis of Student Interactions with Learning Objects using Supervised Learning (L. Dee Miller and Leen-Kiat Soh); (21) Adapting Bayesian Knowledge Tracing to a Massive Open Online Course in edX (Zachary Pardos, Yoav Bergner, Daniel Seaton and David Pritchard); (22) Modeling and Optimizing Forgetting and Spacing Effects during Musical Interval Training (Philip I. Pavlik Jr., Henry Hua, Jamal Williams and Gavin Bidelman); (23) Tuned Models of Peer Assessment in MOOCs (Chris Piech, Jon Huang, Zhenghao Chen, Chuong Do, Andrew Ng and Daphne Koller); (24) Does Representational Understanding Enhance Fluency Or Vice Versa? Searching for Mediation Models (Martina Rau, Richard Scheines, Vincent Aleven and Nikol Rummel); (25) Predicting Standardized Test Scores from Cognitive Tutor Interactions (Steve Ritter, Ambarish Joshi, Stephen Fancsali and Tristan Nixon); (26) Predicting College Enrollment from Student Interaction with an Intelligent Tutoring System in Middle School (Maria Ofelia Clarissa San Pedro, Ryan S. J. D. Baker, Alex Bowers and Neil Heffernan); (27) Incorporating Scaffolding and Tutor Context into Bayesian Knowledge Tracing to Predict Inquiry Skill Acquisition (Michael Sao Pedro, Ryan S. J. D. Baker and Janice Gobert); (28) Applying Three Models of Learning to Individual Student Log Data (Brett van de Sande); (29) Evaluating Topic-Word Review Analysis for Understanding Student Peer Review Performance (Wenting Xiong and Diane Litman); (30) Mining Social Deliberation in Online Communication - If You Were Me and I Were You (Xiaoxi Xu, Tom Murray, Beverly Park Woolf and David Smith); (31) Paragraph Specific N-Gram Approaches to Automatically Assessing Essay Quality (Scott Crossley, Caleb Defore, Kris Kyle, Jianmin Dai and Danielle S. Mcnamara); (32) Degeneracy in Student Modeling with Dynamic Bayesian Networks in Intelligent Edu-Games (Alireza Davoodi and Cristina Conati); (33) Clustering and Visualizing Study State Sequences (Michel Desmarais and Francois Lemieux); (34) Analyzing the Mental Health of Engineering Students using Classification and Regression (Melissa Deziel, Dayo Olawo, Lisa Truchon and Lukasz Golab); (35) Hints: You Can't Have Just One (Ilya Goldin, Kenneth Koedinger and Vincent Aleven); (36) What and When do Students Learn? Fully Data-Driven Joint Estimation of Cognitive and Student Models (Jose Gonzalez-Brenes and Jack Mostow); (37) An Investigation of Psychometric Measures for Modelling Academic Performance in Tertiary Education (Geraldine Gray, Colm McGuinness and Philip Owende); (38) Modeling Affect in Student-Driven Learning Scenarios (Paul Salvador Inventado, Roberto Legaspi, Rafael Cabredo and Masayuki Numao); (39) An Algorithm for Reducing the Complexity of Interaction Networks (Matthew Johnson, Michael Eagle, John Stamper and Tiffany Barnes); (40) Mining Temporally-Interesting Learning Behavior Patterns (John Kinnebrew, Daniel Mack and Gautam Biswas); (41) Modeling Students' Learning and Variability of Performance in Problem Solving (Radek Pelanek, Petr Jarusek and Matej Klusacek); (42) Estimating Student Knowledge from Paired Interaction Data (Anna Raerty, Jodi Davenport and Emma Brunskill); (43) Using a Lexical Analysis of Students Self-Explanation to Predict Course Performance (Nicholas Rhodes, Matthew Ung, Alexander Zundel, Jim Herold and Thomas Stahovich); (44) A Meta-Learning Approach for Recommending a Subset of White-Box Classification Algorithms for Moodle Datasets (Cristobal Romero, Juan Luis Olmo and Sebastian Ventura); (45) Investigating the Effects of Off-Task Personalization on System Performance and Attitudes within a Game-Based Environment (Erica Snow, G. Tanner Jackson, Laura Varner and Danielle S. McNamara); (46) Students Walk through Tutoring: Using a Random Walk Analysis to Profile Students (Erica L. Snow, Aaron D. Likens, G. Tanner Jackson and Danielle S. McNamara); (47) From Events to Activities: Creating Abstraction Techniques for Mining Students Model-Based Inquiry Processes (Vilaythong Southavilay, Lina Markauskaite and Michael J. Jacobson); (48) A Comparison of Model Selection Metrics in DataShop (John Stamper, Kenneth Koedinger and Elizabeth McLaughlin); (49) Measuring the Moment of Learning with An Information-Theoretic Approach (Brett van de Sande); (50) Test-Size Reduction for Concept Estimation (Divyanshu Vats, Christoph Studer, Andrew S. Lan, Lawrence Carin and Richard Baraniuk); (51) Reading into the Text: Investigating the Influence of Text Complexity on Cognitive Engagement (Benjamin Vega, Shi Feng, Blair Lehman, Art Graesser and Sidney D'Mello); (52) Using Students' Programming Behavior to Predict Success in an Introductory Mathematics Course (Arto Vihavainen, Matti Luukkainen and Jaakko Kurhila); (53) Do Students Really Learn an Equal Amount Independent of Whether They Get an Item Correct or Wrong? (Seth Adjei, Seye Salehizadeh, Yutao Wang and Neil Heffernan); (54) Analysis of Students Clustering Results Based on Moodle Log Data (Angela Bovo, Stephane Sanchez, Olivier Heguy and Yves Duthen); (55) Mining the Impact of Course Assignments on Student Performance (Ritu Chaturvedi and Christie Ezeife); (56) Mining Users Behaviors in Intelligent Educational Games: Prime Climb a Case Study (Alireza Davoodi, Samad Kardan and Cristina Conati); (57) Bringing Student Backgrounds Online: MOOC User Demographics, Site Usage, and Online Learning (Jennifer Deboer, Glenda S. Stump, Daniel Seaton, Andrew Ho, David E. Pritchard and Lori Breslow); (58) Detecting Player Goals from Game Log Files (Kristen Dicerbo and Khusro Kidwai); (59) A Prediction Model that Uses the Sequence of Attempts and Hints to Better Predict Knowledge: Better to Attempt the Problem First, Rather Than Ask for a Hint (Hien Duong, Linglong Zhu, Yutao Wang and Neil Heffernan); (60) Towards the Development of a Classification Service for Predicting Students' Performance (Diego Garca-Saiz and Marta Zorrilla); (61) Identifying and Visualizing the Similarities Between Course Content at a Learning Object, Module and Program Level (Kyle Goslin and Markus Hofmann); (62) Using ITS Generated Data to Predict Standardized Test Scores (Kim Kelly, Ivon Arroyo and Neil Heffernan); (63) Joint Topic Modeling and Factor Analysis of Textual Information and Graded Response Data (Andrew Lan, Christoph Studer, Andrew Waters and Richard Baraniuk); (64) Component Model in Discourse Analysis (Haiying Li, Art Graesser and Zhiqiang Cai); (65) Modeling Student Retention in an Environment with Delayed Testing (Shoujing Li, Xiaolu Xiong and Joseph Beck); (66) Predicting Group Programming Project Perfo},
  isbn = {9780983952527},
  keywords = {Bayesian Statistics,Computer Uses in Education,Data Analysis,Educational Games,Educational Research,Educational Technology,Elementary Secondary Education,Evaluation,Higher Education,Intelligent Tutoring Systems,Interdisciplinary Approach,Prediction},
  annotation = {ERIC Number: ED558215}
}

@article{Drill.Sorenson.1995,
  title = {{{VISAGE}}: {{Videos}} in {{Special}} and {{Gifted Education}} [{{Machine-Readable Data File}}.]},
  author = {Drill, Janet and Sorenson, Barbara},
  year = {1995},
  abstract = {This computer-searchable database, available on diskette in DOS and Macintosh versions, contains descriptions of approximately 475 video and other media products related to special education of students with disabilities and/or giftedness. Most of the products listed are videotape recordings; other formats include audiocassettes, films, filmstrips, and slides. Information provided for each database listing includes: title; subject; area of exceptionality; format; length; special features (such as discussion guides, teachers' guides, worksheets, and captioning for individuals with hearing impairments); description; intended audience; awards; producer; availability; and purchase and rental price. (JDD)},
  keywords = {Databases,Disabilities,Educational Methods,Elementary Secondary Education,Gifted,Videotape Recordings},
  annotation = {ERIC Number: ED386879}
}

@article{Dunn.etal.2019,
  title = {Disdain to {{Acceptance}}: {{Future Teachers}}' {{Conceptual Change Related}} to {{Data-Driven Decision Making}}},
  author = {Dunn, Karee E. and Skutnik, Anne and Patti, Christine and Sohn, Brian},
  year = {2019},
  journal = {Action in Teacher Education},
  volume = {41},
  number = {3},
  pages = {193--211},
  issn = {0162-6620},
  abstract = {The purpose of this qualitative study was to explore how pre-service teachers perceive, understand, and feel about Data-driven decision making (DDDM), as well as the impact of targeted, persuasive instruction on those constructs. According to conceptual change theory, learners sometimes hold knowledge, feelings, and beliefs that may be counterproductive to acquiring new knowledge, as a result addressing those variables is crucial to the learning process. Research on teachers suggests they often hold views that make them reluctant to learn more about or engage in DDDM (e.g.), but by tailoring instruction to address teacher concerns, they may become more open to DDDM (Airola \& Dunn, 2011). Our qualitative analysis and findings indicated our sample of preservice teachers did overwhelmingly hold initially negative views of DDDM, but our persuasive instructional unit created a cognitive shift away from this negativity and towards openness to and interest in DDDM.},
  langid = {english},
  keywords = {Attitude Change,Beliefs,Data Use,Educational Psychology,Instructional Effectiveness,Knowledge Base for Teaching,Misconceptions,Persuasive Discourse,Preservice Teachers,Professional Identity,Public Education,Student Attitudes},
  annotation = {ERIC Number: EJ1222962}
}

@article{Dunn.Kowitz.1967,
  title = {A {{Statistical Analysis}} of {{Data Used}} in {{Critical Decision Making}} by {{Secondary School Personnel}}.},
  author = {Dunn, Charleta J. and Kowitz, Gerald T.},
  year = {1967},
  abstract = {Guidance decisions depend on the validity of standardized tests and teacher judgment records as measures of student achievement. To test this validity, a sample of 400 high school juniors, randomly selected from two large Gulf Coas t area schools, were administered the Iowa Tests of Educational Development. The nine subtest scores and each student's first semester grades (including two grades for nine-week periods, the semester examination score, and the semester average) in English, American History, and Biology were factor analyzed. The factors clustered among themselves, but separated from one another. Some 40 student traits or characteristics were rated on a five-point desirability scale by 100 classroom teachers, administrators, and other faculty. The 40 traits were tested  for relationship and frequency ratings. Teachers tended to select factors showing high degrees of personal adequacy (including conscientious, industrious, alert, reliable, open-minded, thorough, and efficient). The factor analysis did not reveal many characteristics apparently significant in academic achievement in different disciplines . Rather, the variables seemed to associate with highly valued social characteristics often identified as middle-class values. (Author/WR)},
  keywords = {Academic Achievement,Decision Making Skills,Evaluation Methods,Factor Analysis,Grading,Personality,Secondary School Students,Social Characteristics,Standardized Tests,Statistical Analysis,Teacher Attitudes,Test Validity},
  annotation = {ERIC Number: ED022194}
}

@article{Eckhaus.Davidovitch.2021,
  title = {Driving {{Value Creation}} in the {{New Economy Following}} the {{COVID-19 Crisis}}. {{Data-Mining Students}}' {{Satisfaction}} from {{Online Teaching}} in the {{Virtual Academic Climate}}},
  author = {Eckhaus, Eyal and Davidovitch, Nitza},
  year = {2021},
  journal = {Electronic Journal of e-Learning},
  volume = {19},
  number = {5},
  pages = {452--468},
  issn = {1479-4403},
  abstract = {This study examines the advantages of online teaching from the perspective of students at eleven institutions of higher education, universities, and colleges in Israel. The study was conducted at the end of the second semester of their academic studies, after students had experienced "face to face" studies, and they were asked to reply freely to an open question on how they evaluate the benefits of transitioning to online teaching. Students were forced to cope with a new reality, where they were compelled to study in a digital classroom. The academic-social climate, lecturer-student relations, and the relations among the students themselves changed instantaneously, with no preparation by any of those involved. The research findings can illuminate the strengths of online teaching with a view to the future. Was the impact of teaching and learning during the coronavirus era a one-time event for the students or one from which it is possible to examine and embrace new ways of learning as they see them? Based on 1,937 fully completed surveys, a mixed methods research design was employed. Major themes were manually tagged, and an empirical model was developed. Structural Equation Modeling (SEM) was utilized to test the model's goodness-of-fit. Findings present a host of parameters that have a significant positive influence on students' positive perception of the transition to online teaching. This study is the first to thoroughly examine the advantages of switching to online teaching among a large group of students from several different academic institutions, and it presents both qualitative and empirical results. Ethical implications of the findings are discussed.},
  langid = {english},
  keywords = {College Students,COVID-19,Educational Benefits,Educational Change,Electronic Learning,Foreign Countries,Information Technology,Pandemics,Student Satisfaction,Virtual Classrooms,Web Based Instruction},
  annotation = {ERIC Number: EJ1328929}
}

@article{Engel.2017,
  title = {Statistical {{Literacy}} for {{Active Citizenship}}: {{A Call}} for {{Data Science Education}}},
  author = {Engel, Joachim},
  year = {2017},
  month = may,
  journal = {Statistics Education Research Journal},
  volume = {16},
  number = {1},
  pages = {44--49},
  issn = {1570-1824},
  abstract = {Data are abundant, quantitative information about the state of society and the wider world is around us more than ever. Paradoxically, recent trends in the public discourse point towards a post-factual world that seems content to ignore or misrepresent empirical evidence. As statistics educators we are challenged to promote understanding of statistics about society. In order to re-root public debate to be based on facts instead of emotions and to promote evidence-based policy decisions, statistics education needs to embrace two areas widely neglected in secondary and tertiary education: understanding of multivariate phenomena and the thinking with and learning from complex data.},
  langid = {english},
  keywords = {Citizen Participation,Data,Mathematics Education,Numeracy,Postsecondary Education,Scientific Concepts,Secondary Education,Statistics,Thinking Skills},
  annotation = {ERIC Number: EJ1152522}
}

@article{Espelage.2015,
  title = {Data {{Needs}} for {{Emerging Research Issues}} in {{Bully}} and {{Violence Prevention}}: {{Strengths}} and {{Limitations}} of the {{National Center}} for {{Educational Statistics Data Sets}}},
  author = {Espelage, Dorothy},
  year = {2015},
  month = jul,
  journal = {AERA Open},
  volume = {1},
  number = {3},
  issn = {2332-8584},
  abstract = {School violence and bullying are two public health concerns with consequences for youth in and out of school, for families, students, and community members. In this article, a social-ecological framework is briefly described as a way to understand bullying and school violence; then the National Center for Educational Statistics (NCES) longitudinal and cross-sectional data sets are described in detail. Data that assess bullying and/or school violence are described, and recommendations for additional items are proposed. In general, a longitudinal, multisite, multi-informant study is needed to address definitional and etiological issues related to school violence and bullying so that prevention efforts can be developed, implemented, and evaluated that incorporate multiple levels of the ecology, including peers, schools, communities, and neighborhoods.},
  langid = {english},
  keywords = {Academic Achievement,Bullying,Case Studies,Children,Crime,Disabilities,Educational Research,Elementary Secondary Education,High School Students,Homosexuality,Learner Engagement,Longitudinal Studies,National Surveys,Prevention,Public Agencies,Research Needs,School Safety,School Surveys,Sexual Orientation,Statistical Data,Surveys,Violence},
  annotation = {ERIC Number: EJ1194778}
}

@techreport{Evenson.1982,
  title = {Workplace {{Mentorship}}. {{Interviews}} on {{Workplace Mentorship}}: {{Background}}, {{Methodology}} and {{Data Analysis}}.},
  author = {Evenson, Jill S.},
  year = {1982},
  abstract = {As one activity of the Workplace Mentorship study, 75 interviews were conducted in 15 programs to examine 30 mentorships. In each program five persons were interviewed: two mentors, two students, and one program staff person. Students were in eleventh or twelfth grade or recently out of high school. The interviews collected from the three types of informants parallel information of their perceptions of (1) what occurred in the mentorship that was related to employability development; (2) the value of the mentorship experiences, and (3) factors that affected the mentorship. Activities that were indicated as important to employability development included learning about a particular job, skills in talking and listening to others, learning about rules and how people behave at work,  and exhibiting mature workplace behavior. Almost all students felt the mentorship had an effect on their future plans; for some the mentor had been the most important influence. Staff and mentors saw the mentorships as positively and significantly helpful in preparing the young person for work. Students and staff most often cited the strengthening of personal and interpersonal skills growing out of the mentor relationship as proof of a successful mentorship. (The instruments and a qualitative analysis are appended.) (YLB)},
  keywords = {Career Education,Career Exploration,Education Work Relationship,Educational Research,Employer Attitudes,Employment Potential,Experiential Learning,High Schools,Interviews,Job Skills,Mentors,Secondary Education,Student Attitudes,Vocational Education,Vocational Maturity,Work Experience Programs},
  annotation = {ERIC Number: ED246182}
}

@article{Farrell.2015,
  title = {Designing {{School Systems}} to {{Encourage Data Use}} and {{Instructional Improvement}}: {{A Comparison}} of {{School Districts}} and {{Charter Management Organizations}}},
  author = {Farrell, Caitlin C.},
  year = {2015},
  month = aug,
  journal = {Educational Administration Quarterly},
  volume = {51},
  number = {3},
  pages = {438--471},
  issn = {0013-161X},
  abstract = {Purpose: As state and federal accountability systems have increased demands for evidence of student achievement, the use of data to inform practice has become more prevalent. More research is needed to understand not only "what" organizational factors shape data-use efforts but also "how" these factors enable or constrain educators' use of data for instructional improvement. This article addresses this gap by examining how two types of education systems--school districts and charter management organizations (CMOs)--use data and allocate their organizational resources to this end. Methods: Data were collected from six secondary schools in two districts and two CMOs during the 2010-2011 school year. Over 70 interviews were conducted with teachers and school and system leaders. Patterns from within and across school systems are presented. Findings: Key contextual differences had a strong influence on data-use efforts: Accountability pressures shaped the patterns in data use, whereas other organizational conditions--structure and decision-making rights, size and growth trajectory, financial resources, and degree of regulation--restricted or facilitated the systems' mobilization of resources for these efforts. Implications: This study suggests that the school systems as a whole play a critical role in supporting schools and educators in using data, regardless of whether that system is district or charter. As this article is one of the first to offer a comparative look at data use between school districts and CMOs, it lays the groundwork for diffusion of promising practices across these systems for school and system leaders.},
  langid = {english},
  keywords = {Accountability,Administrative Organization,Case Studies,Charter Schools,Comparative Analysis,Data,Decision Making,Differences,Instructional Improvement,Qualitative Research,School Administration,School Districts,Secondary Schools,Semi Structured Interviews},
  annotation = {ERIC Number: EJ1066873}
}

@phdthesis{Feldman.2011,
  title = {Public-{{Private Interorganizational Sharing}} of {{Health Data}} for {{Disability Determination}}},
  author = {Feldman, Sue S.},
  year = {2011},
  abstract = {Information exchange is a cornerstone in facilitating a strategic advantage in business. However, health information exchange has not shared that same foundation in health care and related secondary uses, especially when the information is used for something other than diagnosis, treatment, or payment. This case study provides an in-depth examination of successful health data sharing for disability determination between three organizations: the US Social Security Administration (SSA), MedVirginia (a Health Information Exchange (HIE)), and the Office of the National Coordinator (ONC). In this case, use of SSA's MEGAHIT application (Medical Evidence Gathering and Analysis through Health Information Technology) and ONC's Nationwide Health Information Network (NwHIN) facilitated the electronic health data sharing from MedVirginia's electronic health records (EHRs). A Blended Value Collaboration Enactment Framework was used to understand the overall value proposition (answering the organizational question: "What's in it for me?") from both social and economic perspectives along technical, organizational, and governance dimensions. This qualitative study consisted of 41 interviews and document analyses across the three organizations over a six-week period from July 2010-September 2010. Primary findings revealed that social motivations were prevalent in the original collaboration and a blend of social and economic motivations sustained the collaboration. Further findings showed that, as compared to previous medical evidence development methods, the use of MEGAHIT resulted in a 33\% time savings from disability application to SSA benefit approval. Such SSA benefits led to \$1.9 million in uncompensated care cost recovery for the provider. Supporting findings revealed that regular and consistent communication and structured governance are essential for creating a sustainable health information exchange collaboration. The findings illuminate the dynamic nature of social and economic blended value such that early motivations in health information exchange may not be the sustaining motivations; at some point in time a shift toward economic value occurs.    [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {9781124602813},
  school = {The Claremont Graduate University},
  keywords = {Agency Cooperation,Case Studies,Content Analysis,Data,Disability Identification,Health Services,Information Technology,Interviews,Motivation,Private Agencies,Public Agencies},
  annotation = {ERIC Number: ED529546}
}

@article{Golding.2013,
  title = {Must {{We Gather Data}}? {{A Place}} for the {{Philosophical Study}} of {{Higher Education}}},
  author = {Golding, Clinton},
  year = {2013},
  journal = {Higher Education Research and Development},
  volume = {32},
  number = {1},
  pages = {152--155},
  issn = {0729-4360},
  abstract = {In the field of higher education there are few places reserved for philosophical exploration, and this, this author argues, can limit and distort the cartography. Higher education research tends to be framed as the empirical process of collecting and analysing qualitative or quantitative data. But this conception of research leaves little space for the philosophical, which is neither qualitative nor quantitative and neither collects nor analyses data. Even if one is open to philosophy, this conception of higher education research implies that philosophical, non-empirical, armchair research is either bad research or not research at all. So how should the field of higher education be framed? Macfarlane (2012) and Tight (2003) took a useful empirical route and "described" higher education research, but this author wants to take the more treacherous philosophical path and examine how it "should" be.He begins this path with the current state of higher education research (Sections 1-2) then moves through how it "could" be more philosophical (Sections 3-6) and into how it "should" be more philosophical (Sections 7-9).},
  langid = {english},
  keywords = {Data Analysis,Data Collection,Educational Philosophy,Educational Practices,Educational Research,Higher Education,Research Methodology,Research Needs},
  annotation = {ERIC Number: EJ1010892}
}

@article{Grigg.Others.1989,
  title = {Visual {{Analysis}} of {{Student Evaluation Data}}: {{A Qualitative Analysis}} of {{Teacher Decision Making}}.},
  author = {Grigg, Nancy C. and Others, And},
  year = {Spr 1989},
  journal = {Journal of the Association for Persons with Severe Handicaps (JASH)},
  volume = {14},
  number = {1},
  pages = {23--32},
  abstract = {Qualitative interviews with 20 teachers of students with moderate/severe disabilities determined their use of visual analysis of graphically displayed data to evaluate the effectiveness of educational interventions. Results indicated that experienced teachers stressed student characteristics or the conditions under which the data were collected, rather than data set characteristics, in their decision making. (DB)},
  keywords = {Computer Managed Instruction,Decision Making,Diagnostic Teaching,Elementary Secondary Education,Evaluation Methods,Graphs,Instructional Effectiveness,Severe Disabilities,Student Characteristics,Teacher Attitudes},
  annotation = {ERIC Number: EJ392176}
}

@techreport{Grisham-Brown.etal.2000,
  title = {Training {{Rural Educators}} in {{Kentucky}}: {{Impact}} with {{Follow-Up Data}}.},
  author = {{Grisham-Brown}, Jennifer and Collins, Belva C. and Baird, Constance M.},
  year = {2000},
  abstract = {The University of Kentucky has been providing graduate-level distance learning programs in moderate and severe disabilities and early childhood special education since 1989 through the Training Rural Educators in Kentucky (TREK) Projects. To document the effectiveness of the program, a follow-up survey was conducted in 1998 with an emphasis on the program's impact on students with disabilities, other teachers, and school districts. Surveys were returned from 29 former and current TREK participants. Results indicate that a significant number of participants had achieved an advanced degree or additional certification in some area of special education. A majority of respondents who indicated a job change felt that the change was due to their completion of the TREK course. On a scale  of 1 (not useful) to 5 (very useful), the range of scores across all courses was 4.4. Components of the three delivery formats--on-site, satellite, and compressed video--were rated, with the satellite and combination approach tying for preferred format, followed by compressed video and on-site. A greater percentage of participants were implementing best practices for children with disabilities after taking TREK courses, and a majority of these participants shared information about the practices with other adults. Nineteen respondents reported that systemic changes in their places of employment resulted from the knowledge they gained in the TREK program. The emphasis on research-based decision making resulted in TREK participants becoming agents of change in their rural districts on behalf  of children with disabilities. (TD)},
  keywords = {Disabilities,Distance Education,Educational Practices,Elementary Secondary Education,Followup Studies,Graduate Study,Higher Education,Outcomes of Education,Participant Satisfaction,Program Effectiveness,Program Evaluation,Rural Education,Special Education,Teacher Education},
  annotation = {ERIC Number: ED439887}
}

@techreport{Grovenstein.2016,
  title = {State {{Longitudinal Data Systems}}: {{The Power}} and the {{Promise}}. {{CoNCepts}}},
  author = {Grovenstein, Elizabeth},
  year = {2016},
  institution = {{Hunt Institute}},
  abstract = {"Which preschool programs best prepare students for kindergarten?" "Which students from which schools need remediation classes in higher education?" "How successful are college graduates in the workforce by major or credential?" These are just a few of the questions that can be answered by a robust longitudinal data system that enables a state to track student performance from early learning through the workforce. Statewide Longitudinal Data Systems (SLDS) can enhance the ability of states, districts, schools, educators and other stakeholders to efficiently and accurately manage, analyze, and use education data to make informed decisions that can improve student learning and outcomes. SLDS also facilitate research to evaluate and improve institutional and program performance. This issue of "CoNCepts" describes how SLDS are used, how North Carolina implements SLDS, and important considerations for states to ensure successful implementation and public reporting.},
  keywords = {Data Analysis,Data Collection,Educational Administration,Elementary Secondary Education,Higher Education,Information Management,Postsecondary Education,Preschool Education},
  annotation = {ERIC Number: ED569951}
}

@phdthesis{Haack.2017,
  title = {Teachers' {{Inquiry Stance}}: {{Collaboration}} through {{Data Analysis}} in a {{Professional Learning Community}}},
  author = {Haack, Darin Marcus},
  year = {2017},
  abstract = {The purpose of this qualitative case study was to understand how teachers experience a stance toward inquiry through participation in Professional Learning Communities (PLCs). In order to meet this objective, the following questions framed this research: (1) How do individual teachers make meaning of the epistemological and dialogic aspects of their PLC's inquiry stance toward student data? (2) How do teachers interpret the influence of their personal inquiry stance toward student data on the stance of their PLC? and (3) How do teachers interpret the influence of external supports and constraints on their PLC's inquiry stance toward student data? The site of this research was a mid-sized Midwestern high school. The school had used the PLC structure for several years prior to this research. However, a new principal and assistant principal were hired for the 2016-2017 school year, which brought changes to the school's PLC processes. Eight teachers from five PLCs participated in qualitative, semi-structured interviews. Each participant was interviewed two times over the course of the second semester of the 2016-2017 school year. In addition, three PLCs were observed in meetings during the same time period. Finally, district, school and PLC documents were analyzed. Findings revealed that participants believed in an optimistic premise that professional collaboration had the potential to improve instruction and student learning. However, differences in the approach to knowledge and practice between individual teachers and their colleagues in the PLC, as well as constraints specific to the school context prevented participants from engaging in inquiry based on student-learning data to the degree desired. Participants experienced their PLC's epistemological and dialogic inquiry stance toward student-learning data as a proving stance. Much of their PLC work centered around the development of student learning goals aligned to the Common Core curriculum. When student data was discussed in the PLC, participants experienced the data process as proving the effectiveness of past instruction and generalizing student understanding of past instruction. In addition to spending the majority of the PLC time on the development of student learning goals, participants described much of their conversation centering around task completion, with the PLC agenda directing the work. Differences in participants' experiences of stance toward knowledge and practice emerged from this research. Tension existed in how knowledge was privileged. Participant responses demonstrated a belief that a set of best practices for professional collaboration existed, and the teachers felt they were expected to learn these best practices and implement the practices in their work. Participants also placed value in knowledge gained through classroom experience, and some participants expressed concern that the knowledge gained through experience was not valued in the school system. The tension between formal knowledge in the form of best practices and knowledge gained through experience was described as a concern or frustration specific to the context of the school that made inquiry in PLC work much more difficult than anticipated. The frustration with the difficulty of implementation of PLC work and the tension between different stances toward knowledge and practice resulted in tangible negative effects on the participants in this study. Social relationships were damaged. Some teachers sought compliance with perceived directives and mandates. Other teachers decided to question those same perceptions. Still others remained committed to collaboration and waited for teachers they considered to be resistant to leave the school so that replacements could be hired with compatible beliefs. Despite the difficulties and concerns expressed, all the participants expressed a belief that collaboration with colleagues was important to them socially and professionally. Their concerns were with the nature of implementation not the nature of collaboration. Through purposeful discussions on data processes and the ways in which differing stances toward knowledge and practice influence perception, it remains possible for teachers to experience an increasing sense of collective efficacy in their collaborative work. The results of this study revealed four practical strategies for school leaders to promote collaborative inquiry in schools. These strategies include developing structures that support collaborative inquiry, developing a shared vision that supports collaborative inquiry, developing data processes that support authentic collaborative inquiry, and promoting political and social conditions that support collaborative inquiry. This study also revealed two implications for teachers who participate in PLCs. The strategies for teachers include on-going reflection on images of knowledge and practice and on-going engagement in learning. In addition, the findings revealed suggestions for the use of this case study in both administrator and teacher preparation programs. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {9780355653793},
  langid = {english},
  school = {Iowa State University},
  keywords = {Alignment (Education),Beliefs,Best Practices,Case Studies,Communities of Practice,Content Analysis,Data Collection,Documentation,Educational Objectives,Epistemology,Experience,Experiential Learning,Faculty Development,High Schools,Influences,Inquiry,Knowledge Level,Qualitative Research,Secondary School Teachers,Semi Structured Interviews,Teacher Attitudes,Teacher Collaboration,Teaching Methods},
  annotation = {ERIC Number: ED583343}
}

@article{Harmer.Hill.2021,
  title = {Unique {{Data Sets}} and {{Bespoke Laboratory Videos}}: {{Teaching}} and {{Assessing}} of {{Experimental Methods}} and {{Data Analysis}} in a {{Pandemic}}},
  author = {Harmer, Nicholas J. and Hill, Alison M.},
  year = {2021},
  month = dec,
  journal = {Journal of Chemical Education},
  volume = {98},
  number = {12},
  pages = {4094--4100},
  issn = {0021-9584},
  abstract = {The COVID-19 pandemic necessitated the move to online teaching and assessment. This has created challenges in teaching laboratory skills and producing assessments that are robust and fair. Our solution was to use bespoke laboratory videos to provide laboratory training and to generate unique data sets for each student in coursework and exams. For assessments, R was used to produce student data packs comprising data and images, and associated staff answer files with plotted data and worked answers. In the new open-book online environment, this approach enabled us to create assessments that were the students' own work with no evidence of student collusion. We observed no difference in student performance for the coursework or exam: The mean and median marks for the course remained the same as in previous years.},
  langid = {english},
  keywords = {COVID-19,Educational Change,Grades (Scholastic),Laboratory Experiments,Laboratory Training,Learning Analytics,Online Courses,Pandemics,Programming Languages,Science Achievement,Science Instruction,Science Tests,Teaching Methods,Video Technology},
  annotation = {ERIC Number: EJ1319480}
}

@techreport{Harmon.Ridley.2014,
  title = {Workforce {{Results Matter}}: "{{The Critical Role}} of {{Employment Outcome Data}} in {{Improving Transparency}} of {{Postsecondary Education}} and {{Training}}"},
  author = {Harmon, Tim and Ridley, Neil},
  year = {2014},
  institution = {{Center for Postsecondary and Economic Success}},
  abstract = {At a time of sustained unemployment and sluggish job growth, students and policymakers are increasingly asking tough questions about postsecondary education and training outcomes. Do graduates find jobs? What are they paid? What will they earn in the future? Despite growing national interest in this information, good answers are not widely available for many programs. As college costs have soared in recent years, "unmet financial need" (the share of college costs not covered by financial aid or what the family is expected to contribute) has also climbed sharply. Rising costs and increased student debt, combined with a weak economy, make college a riskier investment than in the past. Students and families can reduce that risk by gauging the quality of institutions and programs and choosing carefully among fields of study. Armed with better information about post-graduation outcomes, low-income and first-generation students and their families are more likely to consider the full range of programs and institutions that can help them succeed. This paper focuses on the need for better information about post-graduation outcomes of postsecondary education and training, with a particular focus on workforce results. Workforce results include employment-related outcomes, such as post-graduation employment rates and earnings levels. Survey research and other evidence reviewed below shows that consumers are keenly interested in these outcomes. This paper suggests the types of employment measures and data that would help meet this demand for better information and describes recent progress by states in producing more comprehensive and consistent information about labor market results. Federal and state policymakers are grappling with the best ways to improve employment data and incorporate metrics into higher education policy. Developing a fair, accurate method for measuring and presenting workforce results should be a top priority for institutions and policymakers at all levels of government. [For the companion report "Transparency and Accountability: 'Implementing a Postsecondary Institution Rating System That Empowers Students While Avoiding Unintended Consequences'", see ED561779.]},
  keywords = {College Attendance,College Choice,College Students,Community Colleges,Costs,Educational Quality,Employment Level,Employment Qualifications,First Generation College Students,Labor Force Development,Labor Market,Low Income Groups,Outcomes of Education,Parent Attitudes,Paying for College,Postsecondary Education,Role of Education,Salaries,Secondary School Students,Student Attitudes,Wages},
  annotation = {ERIC Number: ED561780}
}

@techreport{Harris.etal.2014,
  title = {Speak {{Out}}, {{Listen Up}}! {{Tools}} for {{Using Student Perspectives}} and {{Local Data}} for {{School Improvement}}. {{REL}} 2014-035},
  author = {Harris, Jennifer and Davidson, Laura and Hayes, Ben and Humphreys, Kelly and LaMarca, Paul and Berliner, BethAnn and Poynor, Leslie and Van Houten, Lori},
  year = {2014},
  institution = {{Regional Educational Laboratory West}},
  abstract = {Listening closely to what students say about their school experiences can be beneficial to educators for understanding and addressing school-related topics and problems and rethinking policies and practices. The purpose of this toolkit is to provide educators with a purposeful and systematic way to elicit and listen to student voice to inform school improvement efforts. School improvement is complex work that relies on multiple sources of information to frame challenges and address and monitor change efforts. Student voice brings an additional, important source of information to these efforts. The toolkit offers three tools. ASK (Analyzing Surveys with Kids) involves students in analyzing and interpreting survey results associated with a school-related topic or problem and then producing suggestions for school improvement. Inside-Outside Fishbowl organizes a special kind of focus group in which students and educators trade roles as speakers and listeners during a facilitated discussion of a school-related topic or problem, and jointly develop an action plan. S4 (Students Studying Students' Stories) guides a digital storytelling process in which students produce and analyze videotaped interviews of other students about a school-related topic or problem and then host forums with educators to suggest improvements. The toolkit includes detailed information about how the tools work, the questions they address, the number and types of participants needed, the amount of time required, space and materials considerations, and directions for using the tools. It also includes a tool template so schools and districts can create new student voice tools for their particular needs and interests. The following are appended: (1) Student Voice Reflection Worksheet; and (2) Annotated List of Resources.},
  keywords = {Data Analysis,Data Collection,Discussion,Educational Improvement,Elementary Secondary Education,Focus Groups,Interviews,Story Telling,Student Attitudes,Student Empowerment,Student Experience,Student Surveys,Video Technology},
  annotation = {ERIC Number: ED545367}
}

@article{Hawkins.1980,
  title = {Graphing: {{A Stimulating Way}} to {{Process Data}}. {{How}} to {{Do It Series}}, {{Series}} 2, {{No}}. 10.},
  author = {Hawkins, Michael L.},
  year = {1980},
  abstract = {This paper is concerned with helping elementary and junior high school students interpret and construct graphs. Four types of graphs are emphasized--bar, picture, line, and circle or area. The hypothesis is that students in elementary and intermediate grades are generally insufficiently prepared to use graphs effectively, although they are expected to use them as data sources on a regular basis, particularly in social studies classes. This hypothesis is based on a review of literature on uses of graphs with school age children and on an analysis of three social studies textbook series (18 books). This analysis revealed that 124 graphs were presented with very little background information on graphing knowledge and/or skills. To help social studies classroom teachers overcome this  deficiency, information is presented for the four types of graphs on uses, construction, evaluation, type of graph paper, derivation of the data used in the sample graphs, follow-up activities, and interpretation. Teaching strategies are also suggested, including types of questions teachers should ask to guide students through the process of analyzing a graph (open, focus, interpretive, and capstone). Examples of questions are (1) "What is the graph about?" (open question), (2) "What do the numbers arranged along the vertical axis mean?" (focus question), (3) "What happened at a specific date to produce a given effect?" (interpretive question), and (4) "What conclusions can be drawn from this data?" (capstone question). A special note on guarding against bias concludes the paper.  (DB)},
  keywords = {Data Analysis,Educational Objectives,Elementary Secondary Education,Graphs,Junior High School Students,Skill Development,Social Studies,Teaching Guides,Teaching Methods,Visual Aids},
  annotation = {ERIC Number: ED194441}
}

@article{Hayes.1984,
  title = {Microcomputer {{Data}}.},
  author = {Hayes, Jeanne},
  year = {1984},
  abstract = {Based on published statistics and on information collected by Quality Education Data (QED) during telephone calls to every United States school district in 1981-82, 1982-83, and 1983-84 (including all intermediate units and subdistricts of large school districts), this publication presents in tabular form information on the size of the microcomputer marketplace and the types of organizations involved in it; availability of software by microcomputer brand name; the number of publishers producing software for the home; bestseller home education software packages; types of data collected by QED; growth patterns in school ownership of microcomputers; microcomputer brands owned by schools; shifts in brand ownership; the effect of student enrollment, relative community wealth/poverty,  instructional dollars per pupil, type of school (urban, suburban, and rural), percentage of minority students, and level of school (elementary, junior, and senior high) on level of school district and/or school ownership of microcomputers; the expansion of microcomputer use in elementary schools; the effect of school enrollment versus expenditure on presence of microcomputers; which brand owners are more likely to purchase software; the centralization of software coordination in school districts; units of microcomputer brands owned by schools; the number of schools who have enough micros to support networking; characteristics of the top 50 districts in terms of microcomputers per school; the number of students per microcomputer and number of microcomputer units by state; spending of  Education Consolidation and Improvement Act (ECIA) Chapter 2 federal funds; and use of video for instruction in schools. (ESR)},
  keywords = {Computer Software,Educational Trends,Elementary Secondary Education,Institutional Characteristics,Microcomputers,National Surveys,Public Schools,School Districts,School Statistics,Trend Analysis,Video Equipment},
  annotation = {ERIC Number: ED243473}
}

@article{Hill.1985,
  title = {The {{Politics}} of {{Educational Data Collection}}.},
  author = {Hill, Paul T.},
  year = {1985},
  abstract = {Educational data collection may be fraught with problems because of individuals' resentment and resistance to providing data. State and local education agencies often report that data requests from federal agencies represent an administrative burden, especially when they are not an expected part of the personnel workload. Educators may not know why the data are relevant or needed, and may fear that releasing complete data might result in a compliance review, a lawsuit, or embarrassment to the school district or state when it is compared to other school districts or states. There are a number of ways to manage or reduce resistance to providing data, which would be appropriate for the National Center for Education Statistics (NCES): (1) reduce the data reporting burden by sampling  only a portion of local education agencies; (2) employ contractors rather than agencies to conduct the surveys; (3) distribute useful reports from the surveys to the participants; (4) enlist Congressional support; (5) reduce the number of surveys conducted by the Office for Civil Rights (OCR); and (6) approach and negotiate with chief state school officers individually, not as a group. (GDC)},
  keywords = {Administrative Problems,Agency Cooperation,Change Strategies,Data Collection,Elementary Secondary Education,Federal State Relationship,Government School Relationship,Information Utilization,National Surveys,Political Attitudes,Politics of Education,Research Methodology,Research Problems},
  annotation = {ERIC Number: ED272551}
}

@techreport{Howe.etal.1997,
  title = {Planning for {{Action}}: {{Turning Meaningful Data}} into {{Programs}} and {{Promotion}}.},
  author = {Howe, Eleanor and Stack, Jack and {Rettig-Seitam}, Marcia},
  year = {1997},
  abstract = {This paper presents guidelines and tools for action research in the school library which will help the librarian justify expenditures and personnel and evaluate and plan services. It shows how statistics can be turned into meaningful knowledge about what is currently being done in the library, how well it is being done, whether it should be done, and what needs to be known to prepare for the future. The paper covers: what needs to be measured in school libraries; what can be measured; how to measure--types of data and measurement techniques; analyzing the data--quantitative and qualitative analysis; and reporting the data--who needs the data, what data should be reported, and how to report the data to a variety of audiences. All institutions, including libraries, need to assess  their value and performance in order to justify funding. In an era of increased expenses and reduced funding, programs which are not highly rated can be deprived of even maintenance levels of funding, phased out, or placed on the ballot for referendum by taxpayers. Information technology has dramatically increased the budgets of school libraries, and school librarians need to demonstrate the real benefits of these technologies for students. Action research is a tool which can help to examine, report on, and improve the total school library program. (Author/SWC)},
  keywords = {Action Research,Data Analysis,Elementary Secondary Education,Information Technology,Library Expenditures,Library Funding,Library Planning,Library Research,Library Services,Library Statistics,Program Evaluation,School Libraries,User Needs (Information)},
  annotation = {ERIC Number: ED412969}
}

@article{Hughes.etal.2020,
  title = {Re-{{Approaching Interview Data}} through {{Qualitative Secondary Analysis}}: {{Interviews}} with {{Internet Gamblers}}},
  author = {Hughes, Kahryn and Hughes, Jason and Tarrant, Anna},
  year = {2020},
  journal = {International Journal of Social Research Methodology},
  volume = {23},
  number = {5},
  pages = {565--579},
  issn = {1364-5579},
  abstract = {This paper addresses two interrelated questions concerning what interview data are and how researchers might use them. The first considers the value of a~shift from a~predominant or exclusive focus upon how data are constructed and produced at interview, and towards how such data might be~apprehended~through different forms of engagement.~The~second question relates to how and what qualitative secondary analysis (QSA) might be used to tell about the social world. In exploring this, we advance a~critique of the divide between primary and secondary analysis, recasting the debate in terms of different degrees and qualities of 'proximity' and 'distance' from the formative contexts of data generation, and the distinctive analytical affordances that relate to these. Using QSA of interview data from a~study of problem internet gambling as an empirical crucible, we consider the kinds of participation that interviewees develop through reciprocal engagement with interviewers. We illustrate how participants reflexively negotiate the affordances and limits to the narratives through which they frame and recount their experiences. Finally, we show how interview data can be used both to~speak of~the temporal, relational, spatial, epistemic contexts of their production, and also to contexts and questions beyond these.},
  langid = {english},
  keywords = {Addictive Behavior,Affordances,Data Analysis,Epistemology,Games,Internet,Interviews,Participant Characteristics,Proximity,Qualitative Research,Research Design},
  annotation = {ERIC Number: EJ1259553}
}

@article{Hunt.etal.2016,
  title = {"{{Do You Want}} an {{Idea}} of {{What They}}'re {{Doing}}?" {{Transgressive Data Generation}} and {{Analysis}} within a {{Bilingual Writers Workshop}}},
  author = {Hunt, Carolyn S. and Crumpler, Thomas P. and Handsfield, Lara J.},
  year = {2016},
  journal = {International Journal of Qualitative Studies in Education (QSE)},
  volume = {29},
  number = {3},
  pages = {399--425},
  issn = {0951-8398},
  abstract = {We consider how research participants engage alongside researchers as choreographers of data generation and highlight the everyday practices of researchers and participants "in motion" within and across time and space. Data for this case analysis were generated during a two-year qualitative study investigating multimodal literacies, multilingualism, and literacy teacher development. We utilized microethnographic discourse analysis to analyze a video excerpt from a classroom observation during writers workshop in a fourth-grade bilingual classroom. We sought to understand how the teacher's and students' discursive moves during the event tactically disrupted the researchers' agenda in the moment and complicated attempts at data analysis. Our analyses illustrate how the teacher multiply situated herself in ways that trouble dichotomous framings of teachers' work, such as traditional or nontraditional, as well as dominant conceptualizations of qualitative research, such as data "collection." We end with implications for interpreting and representing research findings.},
  langid = {english},
  keywords = {Bilingual Education,Data Analysis,Data Collection,Discourse Analysis,Educational Research,Elementary School Students,Elementary School Teachers,Ethnography,Grade 4,Interpersonal Relationship,Interviews,Observation,Participation,Power Structure,Qualitative Research,Writing Workshops},
  annotation = {ERIC Number: EJ1086604}
}

@article{Ing.Samkian.2018,
  title = {Raising {{Concerns}} about {{Sharing}} and {{Reusing Large-Scale Mathematics Classroom Observation Video Data}}},
  author = {Ing, Marsha and Samkian, Artineh},
  year = {2018},
  month = may,
  journal = {Journal for Research in Mathematics Education},
  volume = {49},
  number = {3},
  pages = {247--260},
  issn = {0021-8251},
  abstract = {There are great opportunities and challenges to sharing large-scale mathematics classroom observation data. This Research Commentary describes the methodological opportunities and challenges and provides a specific example from a mathematics education research project to illustrate how the research questions and framework drove observational choices, and how these choices might constrain or limit sharing of data for other research purposes.},
  langid = {english},
  keywords = {Classroom Techniques,Elementary School Mathematics,Elementary School Students,Elementary School Teachers,Information Dissemination,Mathematics Instruction,Mixed Methods Research,Observation,Qualitative Research,Research Methodology,Research Projects,Shared Resources and Services,Statistical Analysis,Teaching Methods,Video Technology},
  annotation = {ERIC Number: EJ1178087}
}

@article{Italiano.Hine.2014,
  title = {Finding {{Ways}} to {{Effectively Use Year}} 12 {{Achievement Data}} to {{Inform Practice}} in {{Secondary Schools}}},
  author = {Italiano, Frank and Hine, Gregory},
  year = {Article May 2014},
  journal = {Australian Journal of Teacher Education},
  volume = {39},
  number = {5},
  issn = {0313-5373},
  abstract = {This action research explored how Year 12 achievement data were used by school personnel to inform practice within seven Catholic secondary schools. Deputy Principals of Curriculum from participating schools were interviewed regarding their perceptions of the improvement of Year 12 student achievement outcomes, and their insights into how to strengthen future efforts (or achievements). Three key insights included: Communication of achievement data to key stakeholders in the school community, strategic use of achievement data by teaching staff, and leadership strategies to promote an achievement culture to the students. The findings of this research will serve to improve and strengthen practice at participating schools and to stimulate discussions in other schools about the effective use of achievement data.},
  langid = {english},
  keywords = {Academic Achievement,Action Research,Administrator Attitudes,Case Studies,Catholic Schools,Data,Educational Practices,Foreign Countries,Instructional Leadership,Leadership Role,Principals,Qualitative Research,Sampling,Secondary School Teachers,Semi Structured Interviews,Stakeholders},
  annotation = {ERIC Number: EJ1017649}
}

@phdthesis{James-Maxie.2012,
  title = {The {{Impact}} of {{Data-Driven Decision Making}} on {{Educational Practice}} in {{Louisiana Schools}}},
  author = {{James-Maxie}, Dana},
  year = {2012},
  abstract = {Using data to improve educational practice in schools has become a popular reform strategy that has grown as a result of the No Child Left Behind Act of 2001. Districts and schools across the United States are under a great deal of pressure to collect and analyze data in hopes of identifying student weaknesses to implement corrective action plans that will lead to overall student achievement in the classroom. Technology tools such as computer-based assessment and reporting systems have provided schools with immediate access to student-level data. The problem is the lack of direction in how to use the information to make instructional changes in the classroom. A review of literature provided an overview of research-based strategies that support data-driven decision making (DDDM) in the classroom. Three case studies in Louisiana were examined to build a conceptual understanding about how districts and schools use data to make informed decisions. Three research questions guided the investigation and focused on the tools used to assess, store, and retrieve student data, evidence that connects the data and improvements in teaching, and recommendations for other districts and schools. Educational practices were documented through a collection of documents, interview/questionnaire data, and physical artifacts. Results were reported in a question and answer format for three case studies. School administrators reported using data to plan, evaluate, and provide feedback to teachers. In contrast, teachers and instructional specialists revealed that data were used to assess and measure student's weekly performance. All schools utilized at least two computer-based assessment and/or reporting systems to manage student-level data within the district and/or school. Instructional coaches provided direct support to teachers. Data analysis revealed that teachers collaborated and supported each other through data team meetings and working sessions. Principals and teachers monitored student behavior through use of data management and reporting tools. Schools showed promising and positive attitudes about making changes and building a data-driven culture. Findings were supported through current research on DDDM. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {9781267718822},
  school = {Nova Southeastern University},
  keywords = {Academic Achievement,Administrators,Case Studies,Correlation,Data,Decision Making,Educational Assessment,Educational Legislation,Educational Practices,Elementary Secondary Education,Evidence,Federal Legislation,Information Management,Interviews,Measures (Individuals),Questionnaires,Student Behavior,Teacher Collaboration,Teacher Improvement,Teachers},
  annotation = {ERIC Number: ED550997}
}

@article{Jimerson.Wayman.2015,
  title = {Professional {{Learning}} for {{Using Data}}: {{Examining Teacher Needs}} and {{Supports}}},
  author = {Jimerson, Jo Beth and Wayman, Jeffrey C.},
  year = {2015},
  journal = {Teachers College Record},
  volume = {117},
  number = {4},
  issn = {0161-4681},
  abstract = {Background: In the last few decades, a focus on school accountability at the state and federal levels has created expectations for teachers to attend to data in increasingly structured ways. Although professional learning is often cited as an important facilitator of effective data use, research that focuses on the intersection of professional learning and data use is scarce. Examining teacher perceptions of data use supports, and contrasting assertions of what is desired in data-related professional learning with accounts of the ways in which this professional learning actually happens provide an avenue for exploring these issues and for building a research base that can inform the work of district and campus leaders as well as support providers. Focus of Study: This study aimed at examining teacher needs specific to data-related professional learning through a lens informed by knowledge-based organizational learning. We were guided by two broad questions: (a) What knowledge and skills do teachers need in order to engage in data-informed practice? (b) How do professional learning supports address these needs? Research Design: The qualitative study draws on document analysis as well as interview and focus group data collected from n = 110 participants (teachers, school leaders, and district support staff) in three school districts in central Texas. Flexible a priori coding rooted in our conceptual framework was employed to examine data for themes common across district settings and across school levels (e.g., elementary, middle, high). Code counts were used to further examine areas of professional learning focus and/or apparent imbalance. Findings: Educators articulated professional learning needs related to data use in six main areas: (a) asking appropriate questions of data (to guide analysis and use); (b) accessing and operating district data systems; (c) data literacy/interpretation; (d) fitting data use with day-do-day practice; (e) sharing information via collaboration; and (f) knowledge codification. Of these, data capture via computer data systems was by far the most prominent focus reported by educators in each district. Clear plans for addressing data use capacity through professional learning supports were lacking. Recommendations: Taking into account teacher perspectives on what professional learning for data use was needed and on how such supports were, in reality, structured, we make three recommendations: (a) purposefully embed professional learning for data use in ongoing organizational routines; (b) mitigate the district level silos that separate training-on-computer-systems from professional learning focused on turning data into action at the classroom level; and (c) seek balance in supporting the constellation of knowledge and skills that contribute to data use capacity.},
  langid = {english},
  keywords = {Access to Information,Cooperation,Data,Elementary School Teachers,Faculty Development,Focus Groups,Information Literacy,Information Systems,Information Utilization,Interviews,Learning,Nursing,Organizational Culture,Qualitative Research,Secondary School Teachers},
  annotation = {ERIC Number: EJ1056726}
}

@article{Jonsdottir.etal.2021,
  title = {Using {{Real Data}} for {{Statistics Education}} in an {{Open-Source Learning Environment}}},
  author = {Jonsdottir, Anna H. and Lentin, Jamie and Calian, Violeta and Hafsteinsson, Eggert K. and Stefansson, Gunnar},
  year = {Spr 2021},
  journal = {Teaching Statistics: An International  Journal for Teachers},
  volume = {43},
  number = {1},
  pages = {5--12},
  issn = {0141-982X},
  abstract = {The tutor-web is an open-source learning environment designed to be used for teaching mathematics and statistics. The system offers thousands of exercises at high school and university level, and has been used for a decade to teach introductory statistics courses with good results. A new component has recently been added to the tutor-web so that students can enter their own data or get real data from several data sources for practicing and learning new concepts.},
  langid = {english},
  keywords = {College Mathematics,Data Use,Educational Environment,Mathematics Instruction,Secondary School Mathematics,Statistics Education,Web Based Instruction},
  annotation = {ERIC Number: EJ1282938}
}

@article{Kahn.2020,
  title = {Learning at the {{Intersection}} of {{Self}} and {{Society}}: The {{Family Geobiography}} as a {{Context}} for {{Data Science Education}}},
  author = {Kahn, Jennifer},
  year = {2020},
  journal = {Journal of the Learning Sciences},
  volume = {29},
  number = {1},
  pages = {57--80},
  issn = {1050-8406},
  abstract = {Open large-scale datasets (LSDS) and data visualization technologies are new cultural tools that have potential to inform public dialogue and learning about important socioeconomic and scientific matters, particularly if the data is used to consider both personal and shared experiences. This paper reports on a design study in which diverse middle and high school youth in a free summer workshop at an urban public library were asked to model their family geobiographies, or their personal family migration stories, with socioeconomic LSDS. Youth represented family decision-making and social conditions that might have motivated family movements with online, dynamic data modeling and mapping tools (Gapminder.org; SocialExplorer.com). The qualitative video analysis examined participants' experiences and learning in storytelling and modeling the family geobiography, focusing on multimodal talk-in-interaction to understand how the study design engaged learners' capacities, histories, and imagined futures in relation to the LSDS and supported learning about oneself and society. Grounded examples from two family cases are used to illustrate how participants placed their families and selves into data ontologies and the role of family members in composing storylines.},
  langid = {english},
  keywords = {African American Students,Data,Data Use,Genealogy,Geography,High School Students,Middle School Students,Migration,Public Libraries,Story Telling,Visual Aids,Visualization,Workshops},
  annotation = {ERIC Number: EJ1242251}
}

@techreport{Keaton.2013,
  title = {Selected {{Statistics}} from the {{Common Core}} of {{Data}}: {{School Year}} 2011-12. {{First Look}}. {{NCES}}  2013-441},
  author = {Keaton, Patrick},
  year = {2013},
  institution = {{National Center for Education Statistics}},
  abstract = {The Common Core of Data (CCD) is an annual collection of public elementary and secondary education data by the National Center for Education Statistics (NCES) in the Institute of Education Sciences of the U.S. Department of Education. The data presented in this report are selected from the three nonfiscal components of the Common Core of Data (CCD) survey system: the Public Elementary/Secondary School Universe Survey; the Local Education Agency (LEA) Universe Survey; and the State Nonfiscal Survey of Public Elementary/Secondary Education. This First Look report presents findings on the numbers and types of public elementary and secondary schools and local education agencies and public school student enrollment and staff in the United States and other jurisdictions for school year (SY) 2011-12 from the provisional version 1a school universe file, provisional version 1a LEA universe file, and the provisional version 1a state universe file. The purpose of this First Look report is to introduce new data through the presentation of tables containing descriptive information; therefore, the selected findings chosen for this report demonstrate the range of information available when using data from the CCD non fiscal survey components. This First Look provides users with an opportunity to access provisional data that have been fully reviewed and edited. State education agencies (SEAs) report data annually for the nonfiscal CCD via the ED"Facts" collection system. SEAs submit separate files for each of the three nonfiscal survey components (school, LEA and state). For each survey, SEAs submit only aggregate sums of person-level data such as membership or number of teachers. The ED"Facts" collection opens for each school year beginning in January, with groups of data collected over a schedule throughout the year. The data in this report represent data reported from January 2012 through April 2013. The SY 2011-12 ED"Facts" collection will remain open to SEAs for revisions and corrections for approximately 3 years after the opening of the initial collection, continuing through the end of 2015. NCES may release additional revisions of the provisional data when necessary to reflect the most recent revisions reported from SEAs. Once the collection for SY 2011-12 closes, NCES will issue a Final version of the nonfiscal survey data files to include any final reported revisions. Appended are: (1) Methodology and Technical Notes; and (2) Common Core of Data Glossary. (Contains 4 tables and 2 footnotes.)},
  langid = {english},
  keywords = {Annual Reports,Elementary Secondary Education,Enrollment Rate,Enrollment Trends,Institutional Characteristics,Personnel Data,Public Agencies,Public Schools,School Statistics,School Surveys,State Standards,Statistical Analysis,Statistical Distributions,Statistical Surveys,Tables (Data)},
  annotation = {ERIC Number: ED544222}
}

@article{Kelchen.etal.2019,
  title = {How to {{Create}} and {{Use State-Level Policy Data Sets}} in {{Education Research}}},
  author = {Kelchen, Robert and Rosinger, Kelly Ochs and Ortagus, Justin C.},
  year = {2019},
  month = jul,
  journal = {AERA Open},
  volume = {5},
  number = {3},
  issn = {2332-8584},
  abstract = {As state governments seek to improve the performance of institutions of K-12 and higher education, they often adopt educational policies that have similar names but different characteristics across states and with variations over time within states. Yet quantitative analyses generally examine the absence or presence of an educational policy instead of diving into details such as the dosage or percentage of funding tied to a policy or the specific groups being targeted by the implementation of the policy. The aim of this article is to provide guidance for education policy researchers in constructing and analyzing detailed data that can inform the design of state-level policies, using state performance-based funding policies in public higher education as an example. We also show how to conduct difference-in-differences analyses with continuous treatment variables in order to take advantage of more-nuanced data and better understand the context in which policies are effective (or ineffective).},
  langid = {english},
  keywords = {Accountability,Case Studies,Data Analysis,Data Collection,Educational Finance,Educational Improvement,Educational Policy,Elementary Secondary Education,Higher Education,Performance Based Assessment,Policy Analysis,Policy Formation,State Government,State Policy},
  annotation = {ERIC Number: EJ1229669}
}

@article{Kenyon.etal.2020,
  title = {Help-{{Seeking Behaviors}} in {{Research Data Management}}},
  author = {Kenyon, Jeremy and Attebury, Ramirose Ilene and Doney, Jylisa and {Seiferle-Valencia}, Marco and Martinez, Jessica and Godfrey, Bruce},
  year = {2020},
  journal = {Issues in Science and Technology Librarianship},
  issn = {1092-1206},
  abstract = {Investigations on the help-seeking behavior of academic library patrons have to date primarily focused on the undergraduate experience, most often in the context of reference interactions. This study seeks to explore the help-seeking behaviors of a different audience - faculty in the natural and physical sciences at an R2 land-grant university. Eighteen faculty in the natural and physical sciences at the University of Idaho were individually interviewed using an in-depth qualitative interview format and all transcripts were coded and analyzed using an open transcript data visualization tool created at the University of Idaho Library. Responses revealed that faculty are seeking help from colleagues; peers outside the university, via connections formed in graduate school or professional circles; and through DIY solutions like "just googling it," but less often through university resources and programs. Using the results of this project as a starting point, we will explore how libraries might better understand the help-seeking behavior of research faculty, with an eye towards developing services and sources that better meet faculty research needs.},
  langid = {english},
  keywords = {Academic Libraries,Best Practices,College Faculty,Data,Help Seeking,Information Management,Library Services,Planning,Research,Research Skills,Teacher Attitudes,Teacher Behavior,Teacher Collaboration},
  annotation = {ERIC Number: EJ1286479}
}

@article{Kerski.2019,
  title = {Teaching {{Demography}} and {{Population Change Using Web GIS Tools}} and {{Data}}},
  author = {Kerski, Joseph J.},
  year = {2019},
  journal = {Geography Teacher},
  volume = {16},
  number = {3},
  pages = {126--132},
  issn = {ISSN-1933 8341},
  abstract = {Teaching and learning about demographics and population change in an effective, engaging manner is enriched and enlivened through the use of web mapping tools and spatial data. These tools, enabled by the advent of cloud-based geographic information systems (GIS) technology, bring problem solving, critical thinking, and spatial analysis to every classroom instructor and student. Because modern web GIS platforms are open for anyone to contribute, data quality runs the gamut from poor and/or a complete lack of metadata to authoritative, curated, well-documented sources. Therefore, students need to be critical in using online maps, examining the source, date, author, and other pertinent information. With the flood of information available today, students also need to be able to deal with the limitations and benefits of working with and managing data. These tools provide a way of exploring a body of content knowledge and the geographic perspective (Bednarz 2004; Kerski 2008), identified as essential to primary and secondary education (National Academy of Sciences 2006). The number of maps and data layers available for teaching about demographics and population change extend beyond the scope of this article, so this article focuses on eight resources and methods: (1) Examining world population and demographic data by country with the Living Atlas of the World; (2) examining population dynamics using the Center for International Earth Science Information Network (CIESIN) map viewer; (3) examining demographic patterns in selected cities using the Urban Observatory; (4) comparing world population density, latitude, altitude, and ecoregions; (5) examining regional change with satellite imagery using the Landsat Lens; (6) investigating local changes with historical maps and imagery; (7) examining demographic relationships and trends at the local scale; and (8) examining population trends over time and by country with Gapminder.},
  langid = {english},
  keywords = {Demography,Educational Resources,Elementary Secondary Education,Geographic Information Systems,Geography Instruction,Internet,Maps,Population Trends},
  annotation = {ERIC Number: EJ1223327}
}

@phdthesis{Kilgore.2013,
  title = {An {{Analysis}} of {{Student Achievement}}, {{Student Interaction}}, and {{Social Elements That Support Online Course Completion}} for {{High School Students}} as {{Compared Qualitatively}} with {{Quantitative Data Retrieved}} via a {{Learning Management System}}},
  author = {Kilgore, Leah dee Carter},
  year = {2013},
  abstract = {This mixed-method research examines student achievement, student interaction and social elements to determine which elements support online course completion for students in a state virtual school. The quantitative goals seek to find a possible degree of convergence with the course completion average grade. Qualitative data from 10 high school students, their teachers, and quantitative data from their courses were gathered. Quantitative data from the learning management system (LMS) was reproduced, scrubbed of unwanted data, such as dropped students. Mixed method constant comparison was performed to determine a descriptive analysis of three variables: student achievement, student interaction, and social elements. Using the data gathered from the qualitative interviews, a yes or no was assigned to the students for behavioral, cognitive, and social skills. Using descriptive statistics, the skills were compared to the students' course grades. The results revealed a strong pattern match of data for Research Question 1. This data was indicative of the need for behavioral, cognitive, and social skills to complete an online course. Quantitative and teacher data were grouped by themes: asynchronous, administrative, and assessments; synchronous added for teacher data. A constant comparison of data correspondence was performed between the student course average grade, the access data, LMS theme data, and the course average final grade. The investigation of Research Question 2 indicated that the LMS's reporting module can determine interactions to support online course completion by providing average grade analysis along with access analysis and tool usage analysis. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {9781303557064},
  keywords = {Academic Achievement,Comparative Analysis,Grades (Scholastic),High School Students,Integrated Learning Systems,Interpersonal Competence,Interviews,Mixed Methods Research,Online Courses,Secondary School Teachers,Statistical Analysis,Teacher Student Relationship,Thinking Skills,Virtual Classrooms},
  annotation = {ERIC Number: ED563574}
}

@article{King.Male.1965,
  title = {Sweden. {{Educational Data}}.},
  author = {King, Margaret L. and Male, George A.},
  year = {1965},
  abstract = {Today Sweden has a highly developed comprehensive system of public elementary and secondary schools, along with universities and other institutions of higher education. Most of the actual administration of educational matters is the responsibility of three appointed national government agencies operating under the overall jurisdiction of the Minister of Education and Ecclesiastical Affairs --National Board of Education, Board of Institutes of Technology, Office of the Chancellor of Universities. Most types of schools are operated by local school committees. Financing of education comes from the National Government and the Municipalities. Compulsory schooling begins at the age of seven and lasts for seven years. Because a number of types of older secondary schools exist, there are  several paths open to the student --upper secondary schools, vocational schools, or art and music schools. Sweden has four universities, two higher technological institutions, and fifteen special institutions of higher education. As far as teacher education is concerned, students usually begin teacher training midway through secondary school. Folk High Schools are the chief means of carrying on adult education activities. Special education is also an integral part of the educational system. (SBE)},
  keywords = {Adult Education,Comparative Education,Educational Administration,Educational Development,Educational History,Educational Policy,Educational Practices,Educational Programs,Elementary Education,Higher Education,Preschool Education,Secondary Education,Special Education,Vocational Education},
  annotation = {ERIC Number: ED046811}
}

@phdthesis{Laney.2013,
  title = {Toward {{New Data}} and {{Information Management Solutions}} for {{Data-Intensive Ecological Research}}},
  author = {Laney, Christine Marie},
  year = {2013},
  abstract = {Ecosystem health is deteriorating in many parts of the world due to direct and indirect anthropogenic pressures. Generating accurate, useful, and impactful models of past, current, and future states of ecosystem structure and function is a complex endeavor that often requires vast amounts of data from multiple sources and knowledge from collaborating researchers. Ecological data collection has improved rapidly over the past few decades due to the development, innovation, and large scale deployment of automated sensors, which are capable of measuring a gamut of ecosystem properties over broad spatiotemporal scales. Although complex ecosystem models and analyses are increasingly parameterized with data from such sensors, the challenges of managing, analyzing, and sharing large data sets remain for this field of research. The goals of this research were to: 1) better identify and understand challenges that academic ecological research groups face when incorporating automated sensors into their research, and 2) improve capacities for the fusion and analysis of multifarious ecological data from multiple sources. To address the first goal, a nationwide survey of ecologists was conducted to elucidate how academic research groups are deploying sensors, managing sensor data, collaborating with major research networks, and publishing their data, results, and other findings. The survey feedback from over 100 research groups from 82 academic institutions showed that academic ecological research groups are collectively using thousands of sensors in the field--a number comparable to a large research network--and would like to more than double their sensor use. However, in addition to being limited by funding, they also identified that they are limited in information management knowledge and tools that would help them make their data permanently archived and made available for reuse. To address the second goal, a case study was performed to explore, identify, and prototype solutions to challenges faced by typical academic ecological research groups when streamlining data processing and management. By reviewing the operations of the heavily-instrumented UTEP Systems Ecology Lab research site at the Jornada Experimental Range, NM, a need was identified for a web-based information management system that allows for interaction with spatial layers, imagery, and time-series data. Working collaboratively with a team of ecologists and computer scientists, a prototype web mapping and information system was developed using several free and/or open-source products that are freely available for use and modification by the ecological community. The system consists of i) a generic database well suited for storing and fusing multifarious ecological datasets from multiple sources and for supporting multiple interest areas and personnel; ii) a web-mapping application that allows users to query and dynamically view and interact with a variety of spatial data imagery and time-series data; and iii) specialized, open-source data analysis software (written in R, a programming language familiar to many ecologists) that can be implemented within the information management framework. The "long-tail" of ecological research, where many small research groups collectively make a large contribution to the body of knowledge that help us understand, manage, and adapt to our changing earth system is steadily becoming more data-intensive. This research highlights and addresses some of the challenges that need to be overcome by the academic ecological research community to make their data reusable for collaborative science. The dissertation concludes by discussing future research challenges associated with the management of large, multifarious ecological data and connecting the activities of numerous but relatively small academic research groups to national research efforts. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {9781303683664},
  school = {The University},
  keywords = {Archives,Automation,Computer Networks,Data Collection,Data Processing,Ecology,Environmental Research,Information Management,Information Storage,National Surveys},
  annotation = {ERIC Number: ED565575}
}

@phdthesis{Lange.2014,
  title = {Interim {{Assessment Data}}: {{A Case Study}} on {{Modifying Instruction Based}} on {{Benchmark Feedback}}},
  author = {Lange, Tracey M.},
  year = {2014},
  abstract = {The role of data analysis in the jobs of instructional leaders has become as commonplace as teachers creating lesson plans and taking roll in the classroom. Teachers and building leaders routinely use interim assessment data to develop thoughtful and robust instructional plans that address identified areas of student need. The link between the interim assessment data collection and student learning includes the pedagogical changes that teachers implement based on the data from these interim assessments. However, teachers do not always know how to use the data for this purpose or do not always make necessary changes in their instruction. As a result, student achievement goes unchanged. The purpose of this evaluative qualitative case study was to explore how high school teachers used interim assessment data to evaluate their instruction, and if, or how they made resulting changes in that instruction as they prepared students for the Virginia Reading, Literature, and Research (RLR), as well as the Algebra I, II, and Geometry Standards of Learning (SOL) assessments in one school located in Virginia. A secondary purpose of the study was to explore the pedagogical changes teachers had made, if any, in response to reviewing this data. The discovery process highlighted how the teachers used the interim assessment data, their own content knowledge, and pedagogical skills to change their instructional approaches to the content based on the interim assessment feedback. Descriptors: Virginia Standards of Learning, interim assessments, formative assessments, summative assessments, and data-driven-decision making. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {9781303866517},
  school = {Liberty University},
  keywords = {Action Research,Benchmarking,Case Studies,Data,Data Analysis,Decision Making,Educational Change,Educational Practices,Evaluation Utilization,Evidence Based Practice,Feedback (Response),Formative Evaluation,Instructional Innovation,Pedagogical Content Knowledge,Qualitative Research,State Standards,Summative Evaluation,Teaching Methods,Teaching Skills},
  annotation = {ERIC Number: ED568489}
}

@article{Lefever.etal.2007,
  title = {Online {{Data Collection}} in {{Academic Research}}: {{Advantages}} and {{Limitations}}},
  author = {Lefever, Samuel and Dal, Michael and Matthiasdottir, Asrun},
  year = {2007},
  month = jul,
  journal = {British Journal of Educational Technology},
  volume = {38},
  number = {4},
  pages = {574--582},
  issn = {0007-1013},
  abstract = {Online data collection in academic research might be replacing paper-and-pencil surveys or questionnaires in the near future. This paper discusses the advantages and limitations of online data collection, with particular reference to the conduct of two qualitative studies involving upper secondary school teachers and students in Iceland in 2002. Email was used for contacting the participants to ask them to visit a designated website in order to complete the questionnaire. Some problems arose with the use of an online web-based programme for data collection. Among them were the unreliability of the email address lists and the lack of willingness, particularly among students, to participate. The paper concludes that while online surveys can access large and geographically distributed populations and achieve quick returns, they may no longer be as universally appealing as was once believed. Reaching the population sample remains a problem in online as well as in traditional data collection.},
  langid = {english},
  keywords = {Computer Mediated Communication,Data Collection,Educational Research,Internet,Questionnaires,Response Rates (Questionnaires),Secondary School Teachers,Student Attitudes,Student Surveys,Teacher Attitudes,Teacher Surveys,Technology Uses in Education},
  annotation = {ERIC Number: EJ765878}
}

@techreport{Lockwood.1992,
  title = {The {{Potential}} of {{Self Recorded Audio Tape}} for {{Data Collection}} in {{Distance Education}}.},
  author = {Lockwood, Fred},
  year = {1992},
  abstract = {The collection of data by face-to-face interviews and questionnaires is common and literature in these areas is extensive; but few cases are reported in which respondents have been provided with a blank audio cassette tape, interview schedule, or open-ended questionnaire items, and been invited to record their own comments and forward these to the researcher. This paper begins to redress this imbalance by reporting two studies using a technique involving self-recorded audio cassette tape used along with conventional qualitative data collection methods. The studies involved 2 groups of 64 and 40 students, respectively who were taking courses given by the British Open University in Milton Keynes, England. In the first study, face-to-face interviews and open-ended questionnaire  items were compared with the audio-taped responses. In the second study, the three data collection methods were supplemented by the use of telephone interviews. A review of two other studies using self-reported audiotapes supports the findings of these studies, which demonstrate that the use of self-recorded audiotapes is straightforward and presents few problems in subsequent analysis. Some of the limitations of the technique are discussed. (Contains 8 references.) (SLD)},
  keywords = {Audiotape Cassettes,Audiotape Recordings,College Students,Comparative Testing,Data Analysis,Data Collection,Distance Education,Foreign Countries,Higher Education,Interviews,Nontraditional Students,Qualitative Research,Questionnaires,Research Methodology},
  annotation = {ERIC Number: ED355939}
}

@article{Mardis.Ambavarapu.2017,
  title = {Usage {{Data}} as {{Indicators}} of {{OER Utility}}},
  author = {Mardis, Marcia A. and Ambavarapu, Chandrahasa R.},
  year = {2017},
  journal = {Journal of Online Learning Research},
  volume = {3},
  number = {2},
  pages = {197--221},
  issn = {2374-1473},
  abstract = {A key component of online and blended learning content, open educational resources, (OER) are heralded in a global movement toward high-quality, affordable, accessible, and personalized education. However, stakeholders have expressed concern about scaling OER use due to a lack of means to ensure a fit between learner, resource, and task. Usage data, or "paradata," such as reviews, ratings, views, downloads, favorites, and shares, may yield insight into the fit. We examined paradata from National Science Digital Library (NSDL), the largest extant accessible corpus, for the extent to which K-12 science, technology, engineering, and mathematics (STEM) resource fit can be determined from user- and system-generated data. We conducted sentiment analyses of user reviews and correlations between the sentiment scores and data elements. Some relationships between NSDL paradata elements suggested aspects of resource fit. Despite prior research indicating that user reviews tended to be strongly positive or strongly negative, the results of this study indicated that educators left feedback that contained a blend of sentiments and that users usually downloaded resources they viewed. The results of this study suggest that while it is unlikely that educator feedback can currently be used to assess resource quality, with larger and more robust usage data sets, this area is a fertile area for further research into nuanced sentiment. We conclude with observed data trends and further research directions to inform online learning.},
  langid = {english},
  keywords = {Computer Uses in Education,Correlation,Data,Data Analysis,Educational Resources,Electronic Libraries,Elementary Secondary Education,Shared Resources and Services,STEM Education,Use Studies,User Satisfaction (Information)},
  annotation = {ERIC Number: EJ1151091}
}

@phdthesis{Marker.2016,
  title = {Understanding {{How Principals Use Data Dashboards}} to {{Inform Systemic School Improvement}}},
  author = {Marker, Kathryn Christner},
  year = {2016},
  abstract = {Because data access may be perceived by principals as overwhelming or irrelevant rather than helpful (Wayman, Spikes, \& Volonnino, 2013), data access does not guarantee effective data use. The data-based decision making literature has largely focused on teacher use of data, considering less often data-based organizational improvements for the school as a whole with the inherent focus on the role of the principal. The purpose of this study was to articulate the theory of change (Carman, 2010; Weiss, 1997a) which underlies the connection between accessing data via a dashboard, and the successful use of data to inform decision making by K-12 principals in their schools. This study's research question asked what knowledge, skills, and dispositions contribute to effective use of data dashboards by principals for school improvement. To answer that question, basic interpretive qualitative methods (Denzin \& Lincoln, 1994; Merriam, 2002) were first used to outline the nature of dashboard use according to experts in industries where dashboards have a longer history and a more robust data technology literature base than in education. Then, with a case study design (Creswell, 2007; Merriam, 1988; Stake, 1995) and a focus on a data dashboard implementation in North Carolina, this study elicited program theory from North Carolina stakeholders. Data from interviews, observations, and documents were analyzed to articulate a theory of change and create (a) a logic model (a visual diagram) of how the dashboard is expected to facilitate data access and result in effective decision making, as well as (b) a logic model illustrating the theory-practice gap. Results of the study led to recommendations specifically for principals, ranging from developing spreadsheet skills to leveraging dashboards for situational awareness (Few, 2013; Marzano, Waters, \& McNulty, 2005). In addition, the findings suggest that education planners should seek a true dashboard and refuse to settle for an interface offering a single sign-on to multiple software products. Further, schools need a framework for the action subsequent to data-based decision making. In the discussion of these findings, the study highlights the connection of Professional Learning Communities (PLCs) to principals and dashboards and offers insights from the business research literature about process improvement. This study has implications not only for the professional development of principals but also for the improvement of dashboard technology implementations, and for an expanded understanding of the potentially transformative impact of dashboards on decision making. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {9781369638691},
  school = {North Carolina State University},
  keywords = {Case Studies,Communities of Practice,Computer Interfaces,Computer Software,Data Collection,Decision Making,Educational Improvement,Educational Planning,Elementary Secondary Education,Evaluation Methods,Models,Principals,Professional Development,Program Implementation,Qualitative Research,Theory Practice Relationship,Transformational Leadership,Visual Aids},
  annotation = {ERIC Number: ED575910}
}

@article{Marks.2021,
  title = {Should {{Value-Added School Effects Models Include Student-}} and {{School-Level Covariates}}? {{Evidence}} from {{Australian Population Assessment Data}}},
  author = {Marks, Gary N.},
  year = {2021},
  month = feb,
  journal = {British Educational Research Journal},
  volume = {47},
  number = {1},
  pages = {181--204},
  issn = {0141-1926},
  abstract = {There is an enduring issue on whether student- and school-level covariates should be included in value-added school effects models, in addition to prior achievement. Proponents argue that the addition of covariates allows fairer comparisons of schools, whereas opponents argue that it excuses poorly performing schools and obscures policy-relevant school differences. School-level covariates are problematic statistically, but it has been argued that mean school prior achievement should be included in school effects analyses to reduce error. This article reports on school effects analyses of Australia-wide data of approximately 1.5 million students in both primary and secondary schools that took national assessments in five achievement domains between 2013 and 2018. With appropriate controls for prior achievement, school effects are generally small and most often not statistically significant. The addition of student-level covariates: further reduces school effects, since part of the school effects is absorbed by the effects of the covariates, which are unlikely to reflect causal social processes; reduces the proportion of schools with significant school effects; does not improve predictive power; increases the amount of missing data; and further reduces the consistency of school effects between domains and their stability over time. Mean school prior achievement did not improve consistency or stability. Incorporating covariates in school effects analyses opens a Pandora's Box of specification and measurement issues, undermining the legitimacy of school comparisons. It is concluded that researchers and administrators of educational jurisdictions should focus mainly on simpler models based on prior achievement.},
  langid = {english},
  keywords = {Academic Achievement,Elementary School Students,Elementary Schools,Foreign Countries,Institutional Characteristics,Reliability,School Effectiveness,Secondary School Students,Secondary Schools,Student Characteristics,Value Added Models},
  annotation = {ERIC Number: EJ1288329}
}

@article{Matsuoka.1993,
  title = {Collecting {{Qualitative Data}} through {{Interviews}} with {{Ethnic Older People}}.},
  author = {Matsuoka, Atsuko Karin},
  year = {Sum 1993},
  journal = {Canadian Journal on Aging},
  volume = {12},
  number = {2},
  pages = {216--232},
  issn = {0714-9808},
  abstract = {Gathering qualitative data on ethnic elders through different kinds of interviews (conversational, guided, and standardized open ended) raises certain questions about using native-speaking interviewers, translators, or bilingual researchers and ensuring that interviewers understand the cultural context. (SK)},
  langid = {english},
  keywords = {Bilingualism,Cultural Context,Ethnic Groups,Interviews,Native Speakers,Older Adults,Qualitative Research,Research Problems,Translation},
  annotation = {ERIC Number: EJ478745}
}

@article{McGriff.etal.2004,
  title = {Collecting the {{Data}}: {{Collaboration}}},
  author = {McGriff, Nancy and Harvey, Carl A. and Preddy, Leslie B.},
  year = {2004},
  month = apr,
  journal = {School Library Media Activities Monthly},
  volume = {20},
  number = {8},
  pages = {27--30},
  issn = {0889-9371},
  abstract = {Collaboration is considered a key to the survival of the school library media specialist in the 21st century school. It is a measure of a library media specialist's abilities and successes as an educator. It is a means for illustrating the need for a professional in the school's library media center during difficult times when trying to save library media specialist jobs. It is useful in times of prosperity when attempting to expand staffing. School library media program's collaboration triumphs and productivity are analyzed by using quantitative data and qualitative data collected through semester surveys, collaboration logs, student surveys, and collaborator-educator surveys. Quantitative data has numerical responses that can be placed into a spreadsheet for quick and easy analysis and interpretation. Qualitative data is collected through open-ended or leading questions that require the respondent to write personal opinions, experiences, and comments related to team-teaching, services, facilities, resources, and technology. Both quantitative and qualitative data are needed for a library media specialist to gain a clear understanding of professional strengths and weaknesses as well as provide data and "sound bites" for school library media program reports. (Contains 7 figures and 8 resources.)},
  langid = {english},
  keywords = {Data Analysis,Data Collection,Librarian Teacher Cooperation,School Libraries,Student Surveys,Surveys,Teacher Surveys},
  annotation = {ERIC Number: EJ784599}
}

@article{McLure.etal.2014,
  title = {Data {{Curation}}: {{A Study}} of {{Researcher Practices}} and {{Needs}}},
  author = {McLure, Merinda and Level, Allison V. and Cranston, Catherine L. and Oehlerts, Beth and Culbertson, Mike},
  year = {2014},
  month = apr,
  journal = {portal: Libraries and the Academy},
  volume = {14},
  number = {2},
  pages = {139--164},
  issn = {1531-2542},
  abstract = {Colorado State University librarians conducted five focus groups with thirty-one faculty, research scientists, and research associates. The groups explored: (1) The nature of data sets that these researchers create or maintain; (2) How participants manage their data; (3) Needs for support that the participants identify in relation to sharing, curating, and preserving their data; and (4) The feasibility of adapting the Purdue University Libraries' Data Curation Profiles Toolkit interview protocol for use in focus groups with researchers. The authors report their review of related literature, themes that emerged from analysis of the focus groups, and implications for related library services.},
  langid = {english},
  keywords = {Academic Libraries,College Faculty,Data,Feasibility Studies,Focus Groups,Information Management,Interviews,Library Services,Qualitative Research,Researchers,State Universities},
  annotation = {ERIC Number: EJ1031463}
}

@techreport{Meholick.etal.2023,
  title = {Profile of {{State Data Capacity}} in 2019 and 2020: {{Statewide Longitudinal Data Systems}} ({{SLDS}}) {{Survey Descriptive Statistics}}. {{Stats}} in {{Brief}}. {{NCES}} 2022-051},
  author = {Meholick, Sarah and Honey, Rose and LaTurner, Jason},
  year = {2023},
  institution = {{National Center for Education Statistics}},
  abstract = {Statewide longitudinal data systems (SLDSs) can enable researchers, policymakers, and practitioners to identify and understand important relationships and trends across the education-to-workforce continuum. A well-developed SLDS can increase state and territory governments' ability to establish more informed and equitable policies, enable agency leaders to act more strategically, and help practitioners make more data-informed decisions. The SLDS Survey was created to capture information about the data capacity of states' and territories' SLDSs across these varying circumstances. In addition to inventorying information about whether a given data type, link, or use is in place, the SLDS Survey explores the development of SLDSs and their varying degrees of implementation. By providing standard measures for various aspects of data capacity, the SLDS Survey helps stakeholders understand and assess the ability of SLDSs to store, manage, link, and use key data types across the preschool through workforce (P-20W+) spectrum. This Statistics in Brief provides aggregate data from the 2019 and 2020 administrations of the SLDS Survey. The primary focus of the report is on the 2020 SLDS Survey with results specific to the 2019 SLDS Survey. This brief is structured to address the following four research questions: (1) What types of K-12 data are included in the statewide longitudinal data system (SLDS)?; (2) What is the capacity for linking K-12 student data in the SLDS to other data? How are the data linked?; (3) Are there data dictionaries published publicly? Are data aligned to the Common Education Data Standards (CEDS)?; and (4) How do states and territories use data for reporting and decision-making?},
  keywords = {Accountability,Automation,Data Collection,Data Processing,Data Use,Decision Making,Elementary Secondary Education,Federal Aid,Longitudinal Studies,State Policy,State Programs},
  annotation = {ERIC Number: ED629873}
}

@article{Meredith.2016,
  title = {Transcribing {{Screen-Capture Data}}: {{The Process}} of {{Developing}} a {{Transcription System}} for {{Multi-Modal Text-Based Data}}},
  author = {Meredith, Joanne},
  year = {2016},
  journal = {International Journal of Social Research Methodology},
  volume = {19},
  number = {6},
  pages = {663--676},
  issn = {1364-5579},
  abstract = {Transcription of audio data is widespread in qualitative research, with transcription of video data also becoming common. Online data is now being collected using screen-capture or video software, which then needs transcribing. This paper draws together literature on transcription of spoken interaction and highlights key transcription principles, namely reflecting the methodological approach, readability, accessibility, and usability. These principles provide a framework for developing a transcription system for multi-modal text-based data. The process of developing a transcription system for data from Facebook chat is described and reflected on. Key issues in the transcription of multi-modal text-based data are discussed, and examples provided of how these were overcome when developing the transcription system.},
  langid = {english},
  keywords = {Computer Mediated Communication,Computer Software,Data,Interaction,Social Media,Synchronous Communication,Transcripts (Written Records),Video Technology},
  annotation = {ERIC Number: EJ1190109}
}

@techreport{Miles.1987,
  title = {Innovative {{Methods}} for {{Collecting}} and {{Analyzing Qualitative Data}}: {{Vignettes}} and {{Pre-Structured Cases}}.},
  author = {Miles, Matthew B.},
  year = {1987},
  abstract = {Two innovative methods for collecting and analyzing qualitative data are vignettes and pre-structured cases. Vignettes are descriptions of situations or problems written by a professional, with a suggested outline and comments provided by a researcher. Advantages of this method are strength of impact of the written descriptions and efficiency of use of researchers' time; limitations are possible bias or reluctance on the part of the professional, and necessity of a good working relationship between professional and researcher. Suggested applications of this technique include formal research, problem solving, and policy planning. Illustrations of the use of this technique in a teacher center show the vividness of descriptions, as well as the potential for effective intervention.  In the pre-structured case method, the researcher writes a case outline, including a display format, before collecting any data. The data, when collected, are entered directly into the display format. Advantages of this method include efficiency of use of researchers' time, and availability of interim feedback and cross-case analysis. Limitations include necessity of knowledgeable, experienced researchers; and risk of researcher bias and of drawing conclusions too soon. Suggested applications of this method include evaluation studies and studies testing theoretical models. It is also suggested that pairs of researchers be used to limit possible bias and "tunnel vision"; and that transcribed, rather than coded, field notes, be entered. (JGL)},
  keywords = {Case Studies,Data Analysis,Data Collection,Elementary Secondary Education,Evaluation Methods,Evaluation Problems,Field Studies,Interprofessional Relationship,Interviews,Qualitative Research,Research Methodology,Research Problems},
  annotation = {ERIC Number: ED286924}
}

@phdthesis{Miles.2013,
  title = {The {{Effects}} of {{Open Enrollment}}, {{Curriculum Alignment}}, and {{Data-Driven Instruction}} on the {{Test Performance}} of {{English Language Learners}} ({{ELLs}}) and {{Re-Designated Fluent English Proficient Students}} ({{RFEPs}}) at {{Shangri-La High School}}},
  author = {Miles, Eva},
  year = {2013},
  abstract = {The purpose of this study was to examine the impact of open enrollment, curriculum alignment, and data-driven instruction on the test performance of English Language Learners (ELLs) and Re-designated Fluent English Proficient students (RFEPs) at Shangri-la High School. Participants of this study consisted of the student population enrolled in English classes from grades 9 to 11 in an urban high school with total student enrollment of 2,445 in school year 2011-2012, of which 697 were ELLs. A retrospective control group design was used to analyze the data collected before and after the intervention period. The measurement tools utilized were the test performance of the students in the English Language Arts portion of the California Standardized tests (CST) and the California High School Exit Exam (CAHSEE). The findings from this study indicate that the intervention had a significant positive effect on the CST ELA scores of the ELLs versus the RFEP students. However, the intervention did not have a significant effect on the CAHSEE ELA scores of the ELLs versus the RFEP students. Moreover, there was no interaction between the language placement and the intervention for either the CST or CAHSEE. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {9781303124891},
  keywords = {Admission (School),Alignment (Education),Correlation,Curriculum Design,Data,Educational Testing,English Instruction,English Language Learners,Exit Examinations,High School Students,High Schools,Instruction,Intervention,Language Proficiency,Measures (Individuals),Open Enrollment,Scores,Standardized Tests,Student Placement,Urban Schools},
  annotation = {ERIC Number: ED553962}
}

@techreport{Molnar.Boninger.2015,
  title = {On the {{Block}}: {{Student Data}} and {{Privacy}} in the {{Digital Age--The Seventheenth Annual Report}} on {{Schoolhouse Commercializing Trends}}, 2013-2014},
  author = {Molnar, Alex and Boninger, Faith},
  year = {2015},
  institution = {{National Education Policy Center}},
  abstract = {Computer technology has made it possible to aggregate, collate, analyze, and store massive amounts of information about students. School districts and private companies that sell their services to the education market now regularly collect such information, raising significant issues about the privacy rights of students. Most school districts lack the resources to manage all of the student data that federal and state laws now require that they collect and report. As a result, they are likely to hire private vendors to identify, collect, manage, and analyze student data. This has opened up opportunities for private vendors to access student information and to share it with others. Further, the computerization of student work offers opportunities for companies that provide education technology and educational applications to obtain and pass on to third parties information about students. Which information may be appropriately collected, who has a right to see it, how long the information may be held, and how errors and inaccuracies are to be corrected have become critical policy issues. Important in this mix is that student information, even information in the form of "anonymized" meta-data (or massive amounts of data reported without linking specific information and individuals), is valuable to marketers interested in selling products and services to students and their families. Because of these critical concerns, this year's report on school commercializing trends reviews the policy landscape related to student data and assesses the dangers associated with the dearth of policies to protect students and their families from third parties who wish to profit from access to information collected through schools. As legislators develop statutory language and district leaders develop their contracting policies, the authors recommend that they review the comprehensive guidelines detailed in the Electronic Privacy Information Center's Student Privacy Bill of Rights. The authors also recommend that policymakers develop policies that encompass not only the privacy of student educational records but also the wide variety of student data (including anonymized data that may now be collected and shared). These policies should explicitly address the potential commercial use of any data collected. Finally, the authors recommend that the burden of protecting student data be placed not only on schools and districts but also on any private vendors with access to student data. This would align the interests of all parties, public and private, in protecting student privacy. An appendix contains: State Laws Addressing Student Data Privacy (2011-2014): Synopses of Major Provisions, Noting Significant Gaps in Protection, Exclusions and Omissions. (This report contains a list of 103 notes and references.)},
  keywords = {Access to Information,Commercialization,Data,Educational Legislation,Educational Policy,Elementary Secondary Education,Information Policy,Information Security,Information Technology,Internet,Marketing,Parent Rights,Privacy,State Legislation,Student Records,Student Rights,Trend Analysis},
  annotation = {ERIC Number: ED558607}
}

@techreport{Moore.Llompart.2017,
  title = {Collecting, {{Transcribing}}, {{Analyzing}} and {{Presenting Plurilingual Interactional Data}}},
  author = {Moore, Emilee and Llompart, J{\'u}lia},
  year = {2017},
  institution = {{Research-publishing.net}},
  abstract = {Interactional data is often central to research in plurilingual learning environments. However, getting a grip on the processes of collecting, organizing, transcribing, analyzing and presenting audio and/or visual data is possibly the most exciting, but also one of the most challenging things about learning to do qualitative research. Although the entire process is interwoven with other aspects of research discussed elsewhere in this handbook (e.g. ethics, qualitative research design), this chapter attempts to set out some basic recommendations to guide the reader through different stages of what Mortensen and Hazel (2012) have called the "data cycle". Sources for recommend reading are provided. [A Spanish version of this chapter is also included in the book. For the complete volume, "Qualitative Approaches to Research on Plurilingual Education," see ED573580.]},
  keywords = {Audio Equipment,Computer Software,Data Analysis,Discourse Analysis,Ethics,Guides,Interaction,Multilingualism,Qualitative Research,Research Methodology,Video Technology},
  annotation = {ERIC Number: ED573605}
}

@article{Namey.etal.2020,
  title = {How {{Does Mode}} of {{Qualitative Data Collection Affect Data}} and {{Cost}}? {{Findings}} from a {{Quasi-Experimental Study}}},
  author = {Namey, Emily and Guest, Greg and O'Regan, Amy and Godwin, Christine L. and Taylor, Jamilah and Martinez, Andres},
  year = {2020},
  month = feb,
  journal = {Field Methods},
  volume = {32},
  number = {1},
  pages = {58--74},
  issn = {1525-822X},
  abstract = {Internet-based platforms are increasingly used to collect qualitative data. We conducted a quasi-experimental study to explore whether data collection mode affects data content and data collection costs. Participants (N = 171) were assigned systematically to one of four modes--(1) in-person (control), (2) online video-based, (3) online chat-based, (4) online e-mail/message board-based--and randomized to individual interview (IDI) or focus group (FG). We conducted 48 IDIs and 24 FGs about medical risk during pregnancy with women in the southeast United States. We found audiovisual (in-person and online video) modes generated significantly greater volumes of data than online text-based modes. However, there were no significant differences in the thematic content among modes, for IDIs or FGs. Online data collection generally cost more per event without travel; in-person IDIs/FGs were more expensive if including travel. Findings offer empirical data for considerations of online versus in-person qualitative data collection.},
  langid = {english},
  keywords = {Asynchronous Communication,Audiovisual Communications,Computer Mediated Communication,Costs,Data,Data Collection,Focus Groups,Intermode Differences,Internet,Interviews,Qualitative Research,Synchronous Communication,Verbal Communication},
  annotation = {ERIC Number: EJ1239432}
}

@article{Nassauer.Legewie.2021,
  title = {Video {{Data Analysis}}: {{A Methodological Frame}} for a {{Novel Research Trend}}},
  author = {Nassauer, Anne and Legewie, Nicolas M.},
  year = {2021},
  month = feb,
  journal = {Sociological Methods \& Research},
  volume = {50},
  number = {1},
  pages = {135--174},
  issn = {0049-1241},
  abstract = {Since the early 2000s, the proliferation of cameras, whether in mobile phones or CCTV, led to a sharp increase in visual recordings of human behavior. This vast pool of data enables new approaches to analyzing situational dynamics. Application is both qualitative and quantitative and ranges widely in fields such as sociology, psychology, criminology, and education. Despite the potential and numerous applications of this approach, a consolidated methodological frame does not exist. This article draws on various fields of study to outline such a frame, what we call video data analysis (VDA). We discuss VDA's research agenda, methodological forebears, and applications, introduce an analytic tool kit, and discuss criteria for validity. We aim to establish VDA as a methodological frame and an interdisciplinary analytic approach, thereby enhancing efficiency and comparability of studies, and communication among disciplines that employ VDA. This article can serve as a point of reference for current and future practitioners, reviewers, and interested readers.},
  langid = {english},
  keywords = {Data Analysis,Evaluation Criteria,Research Methodology,Research Problems,Research Tools,Validity,Video Technology},
  annotation = {ERIC Number: EJ1282093}
}

@techreport{Naylor.2001,
  title = {What {{Do British Columbia Teachers Consider To Be}} the {{Most Significant Aspects}} of {{Workload}} and {{Stress}} in {{Their Work}}? {{Analysis}} of {{Qualitative Data}} from the {{BCTF Worklife}} of {{Teachers Survey Series}}, 1: {{Workload}} and {{Stress}}. {{BCTF Research Report}}.},
  author = {Naylor, Charlie},
  year = {2001},
  abstract = {This paper analyzes data from the 2001 survey "BCTF (British Columbia Teachers' Federation) Worklife of Teacher Survey Series, I: Workload and Stress." Surveys were mailed to 1,500 teachers in British Columbia, and 644 teachers responded. Teachers identified and explained the most significant aspect of workload or stress in their professional lives. Almost all respondents identified multiple sources of stress in their teaching work, and these stress factors occurred repeatedly and concurrently. Three key areas of stress teachers identified were (1) increasing difficulty and complexity of teaching and relating to students (e.g., changing class composition and working with impoverished students); (2) the volume of work during a teacher's day and the expectations that teachers will  address a wide range of tasks and issues (e.g., seasonal pressures, curriculum change, and expectations); and (3) lack of time, resources, support, and respect. The consequences of high workload stress include trying to cope, working excessively or opting for part-time employment, quitting teaching, becoming sick, and negative effects on family life. Overall, the study shows that British Columbia teachers have too high a workload, and many are suffering from stress. The effects of such stress are potentially devastating for many teachers. (SM)},
  keywords = {Elementary Secondary Education,Faculty Workload,Foreign Countries,Stress Variables,Teacher Burnout,Teacher Morale,Teacher Student Relationship,Teaching Conditions},
  annotation = {ERIC Number: ED464030}
}

@article{NorthCentralRegionalEducationalLab..2002,
  title = {Data {{Exploration}}: {{A Journey}} to {{Better Teaching}} and {{Learning}}. {{Activity Booklet}} [with {{Videotape}}].},
  author = {North Central Regional Educational Lab., Naperville},
  year = {2002},
  abstract = {This 20-minute videotape features 2 schools that have maintained a school culture based on using myriad data sources and processes to fuel their school-improvement activities. In the video the voices of teachers and administrators in each school articulate the ways they have used data to improve student achievement. They highlight numerous data sources, analysis strategies, and actions taken as a result of examining data. A companion booklet is intended to support and extend the utility of the video. Following an introductory section, the next section of the booklet contains descriptions of the schools featured in the video. These two brief summaries provide information helpful in understanding the unique contexts of both schools. The next section contains three group activities  intended for use by educators before or after viewing the video. The final section of the booklet contains numerous data resources: books, articles, and websites on data use in schools. In addition, an annotated listing of data tools and services is provided. (Author/WFA)},
  keywords = {Academic Achievement,Achievement Tests,Data Analysis,Data Collection,Data Interpretation,Educational Assessment,Educational Improvement,Educational Technology,Elementary Secondary Education,Information Technology,Measurement,Scores,State Standards,Test Results},
  annotation = {ERIC Number: ED476386}
}

@phdthesis{OlivaresPasillas.2017,
  title = {Toward {{Critical Data-Scientific Literacy}}: {{An Intersectional Analysis}} of the {{Development}} of {{Student Identities}} in {{An Introduction}} to {{Data Science Course}}},
  author = {Olivares Pasillas, Maria Concepci{\'o}n},
  year = {2017},
  abstract = {The national imperative to increase the presence of women and people of color in science, technology, engineering, and mathematics (STEM) coupled with the growing presence of Latinos in the United States has led to the dramatic rise of programs and initiatives aimed at improving access to and equity in STEM careers and education for Latino youth. Through the use of critical social theory and critical theory of education as guiding frameworks, the dissertation examines an instantiation of STEM reform efforts to analyze the classroom participation structure that emerged in a piloted introduction to data science course at a local high school in one of the largest school districts in the country. The study is particularly concerned with identifying emergent classroom norms and practices, and understanding whether and how they came to support and/or hinder students' opportunities to learn richly with data through an analysis of the development of student learning identities. This qualitative case study draws on audio-recorded student interviews, video-recorded classroom observations, and field notes collected during the second year of the curriculum's implementation. To identify classroom norms and practices as they relate to the development of student identities as data science doers, the study examines the classroom participation structure (Cobb and Hodge, 2002) and employs Cobb, Gresalfi, and Hodge's (2009) interpretive scheme for analyzing the development of mathematical student identity (also see Cobb \& Hodge, 2010). While the multiperspectival approach of this study will provide innovatively insightful contributions to a number of fields including education, cultural studies, data and computer science, the study will also push how educators, learning science researchers, curriculum writers, and policymakers think about the pursuit of equity in STEM education in general and data science-oriented programs and initiatives in particular as they relate to STEM reform efforts. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {9780355315790},
  langid = {english},
  keywords = {Access to Education,Case Studies,Class Activities,Critical Theory,Curriculum Implementation,Equal Education,Females,Hispanic American Students,Minority Group Students,Qualitative Research,Science Careers,Science Instruction,Scientific Literacy,STEM Education,Student Participation,Youth},
  annotation = {ERIC Number: ED579131}
}

@article{Oz.Arastaman.2022,
  title = {School {{Principals}}' {{Opinions}} on {{Data-Based School Management}}: {{A Case Study}}},
  author = {{\"O}z, {\"O}mer and Arastaman, G{\"o}khan},
  year = {2022},
  month = may,
  journal = {Participatory Educational Research},
  volume = {9},
  number = {3},
  pages = {132--147},
  issn = {2148-6123},
  abstract = {Data usage-related reforms lead schools to different practices in terms of management. The conceptualization of data usage and data-based management will ensure that robust steps are taken for the future in terms of reforms made or to be made in the name of education. In this direction, this study is developed as a qualitative case study to determine the opinions of school administrators for data-based management on a school basis. The working group consists of 12 administrators, seven of whom are women and five of whom are men, who work in private and public schools. Purposive sampling method was used to determine the participants. Data from the working group were collected through the semi-structured interview form and themes were created by analyzing in NVino 11. In line with the established themes, the opinions of the administrators were also evaluated. According to the research findings, administrators mostly use data on "e-Okul" and "MEBBIS" modules. Administrators use the said data in decision-making processes, to meet the demands of senior management units, to work with stakeholders, to increase student success. While the administrators stated that there is not enough support or software products to use the data more effectively in the management process, they stated that there is a need for a series of trainings and that these trainings should be in the form of hands-on workshops. They also stated that there should be auxiliary personnel and support services for data analysis. Administrators who reported their problems with time management in accessing data stated that they were not proficient in data analysis and had problems with the motivation, quality, and workload of the personnel.},
  langid = {english},
  keywords = {Administrator Attitudes,Data Use,Decision Making,Educational Needs,Elementary Secondary Education,Foreign Countries,Management Development,Principals,Private Schools,Public Schools,School Administration},
  annotation = {ERIC Number: EJ1324667}
}

@article{Phillips.etal.2021,
  title = {Not {{Engaging}} with {{Problems}} in the {{Lab}}: {{Students}}' {{Navigation}} of {{Conflicting Data}} and {{Models}}},
  author = {Phillips, Anna McLean and Sundstrom, Meagan and Wu, David G. and Holmes, N. G.},
  year = {Article 020112 Jul-Dec 2021},
  journal = {Physical Review Physics Education Research},
  volume = {17},
  number = {2},
  issn = {2469-9896},
  abstract = {With the adoption of instructional laboratories that require students to make their own decisions, there is a need to better understand students' activities as they make sense of their data and decide how to proceed. In particular, understanding when students do not engage productively with unexpected data may provide insights into how to better support students in more open-ended labs. We examine video and audio data from groups within a lab session where students were expected to find data inconsistent with the predictions of two models. In prior work, we examined the actions of the four groups that productively grapple with this designed problem. Here, we analyze the engagement of the three groups that do not. We conducted three phases of analysis: (1) documenting large scale behaviors and time spent in on-topic discussion; (2) analyzing interactions with the teaching assistant; and (3) identifying students' framing--their expectations for what is taking place--when they were discussing their data. Our phase 1 and 2 analyses show only minor differences between the groups that engaged with the problem and those that did not. Our phase 3 analysis demonstrated that the groups that did not engage with the problem framed the lab activity as about confirming a known result or as a series of hoops to jump through to fulfill assignment requirements. Implications for instruction include supporting teaching assistants to attend to students' framing and agency within laboratory classrooms.},
  langid = {english},
  keywords = {College Science,College Students,Expectation,Interaction,Introductory Courses,Mechanics (Physics),Science Instruction,Science Laboratories,Student Behavior,Teaching Assistants},
  annotation = {ERIC Number: EJ1314316}
}

@article{Pols.etal.2021,
  title = {What {{Do They Know}}? {{Investigating Students}}' {{Ability}} to {{Analyse Experimental Data}} in {{Secondary Physics Education}}},
  author = {Pols, C. F. J. and Dekkers, P. J. J. M. and {de Vries}, M. J.},
  year = {2021},
  journal = {International Journal of Science Education},
  volume = {43},
  number = {2},
  pages = {274--297},
  issn = {0950-0693},
  abstract = {This paper explores students' ability to analyse and interpret empirical data as inadequate data analysis skills and understandings may contribute to the renowned disappointing outcomes of practical work in secondary school physics. Selected competences, derived from a collection of leading curricula, are explored through interviews and practical tasks, each consisting of three probes. The 51 students, aged 15 and commencing post-compulsory science education in the Netherlands, were able to carry out basic skills such as collecting data and representing these. In interpreting the data in terms of the investigated phenomenon or situation however, performance was weak. Students often appeared to be unable to identify the crucial features of a given graph. Conclusions based on the data were often tautological or superficial, lacking salient features. Students failed to infer implications from the data, to interpret data at a higher level of abstraction, or to specify limitations to the validity of the analysis or conclusions. The findings imply that the students' understanding of data-analysis should be developed further before they can engage successfully in more 'open' practical work. The study offers a collection of activities that may help to address the situation, suggesting a baseline for guided development of data analysis abilities.},
  langid = {english},
  keywords = {College Readiness,Cooperative Learning,Data Analysis,Evidence,Foreign Countries,Graphs,Inquiry,Interference (Learning),Knowledge Level,Postsecondary Education,Science Activities,Science Instruction,Science Process Skills,Scientific Concepts,Scientific Literacy,Secondary School Science,Secondary School Students},
  annotation = {ERIC Number: EJ1291366}
}

@techreport{Powers.etal.2020,
  title = {Communities at the {{Forefront}}: {{Elevating Girls}}' {{Sports}} through {{Local Programs}}. {{Encompassing Data}} from the {{Sports}} 4 {{Life National}} and {{Regional Initiatives}}. {{A Women}}'s {{Sports Foundation Research Report}}},
  author = {Powers, Stacie R. and Hirsch, Heather and Zarrett, Nicole and Ng, Alison},
  year = {2020},
  institution = {{Women's Sports Foundation}},
  abstract = {In October 2014, the Women's Sports Foundation (WSF), and espnW co-founded "Sports 4 Life", a national grant program to increase participation and retention of African American and Hispanic girls in sports, especially in under-resourced communities. These grants are intended to help small and mid-size organizations in all 50 states create or expand sustainable developmental sports programming for girls in middle and high school, as well as provide high-quality sports programming to foster strong recruitment and retention of African American and Hispanic girls. The program also seeks to create leadership opportunities and increase public awareness to address disparities in girls' access to sports. This report presents findings from data collected over the last five years from the Women's Sports Foundation's Sports 4 Life grantees. The Sports 4 Life evaluation team developed several research tools customized to measure strength in the key objectives identified by the national and regional initiatives, and to examine these objectives from the perspectives of multiple stakeholders--the girls who participate, their program leaders, and community stakeholders. These tools, combined with qualitative data drawn from interviews, think tanks that brought together regional partners and the WSF to identify key regional priorities, and open-ended survey questions, provide a robust account of Sports 4 Life's contributions to the field of positive sports youth development. [Additional funding for this report was provided by espnW.]},
  keywords = {Academic Achievement,African Americans,Athletics,Attitude Change,Attitudes,Barriers,Behavior Change,Capacity Building,Community Programs,Consciousness Raising,Economically Disadvantaged,Exercise,Females,Financial Support,Geographic Location,Grants,High School Students,Hispanic Americans,Interests,Leadership Training,Middle School Students,Persistence,Program Effectiveness,Recruitment,Social Support Groups,Stakeholders,Youth Programs},
  annotation = {ERIC Number: ED611602}
}

@article{Rafferty.etal.2020,
  title = {Proceedings of the {{International Conference}} on {{Educational Data Mining}} ({{EDM}}) (13th, {{Online}}, {{July}} 10-13, 2020)},
  author = {Rafferty, Anna N. and Whitehill, Jacob and Romero, Cristobal and {Cavalli-Sforza}, Violetta},
  year = {2020},
  journal = {International Educational Data Mining Society},
  abstract = {The 13th iteration of the International Conference on Educational Data Mining (EDM 2020) was originally arranged to take place in Ifrane, Morocco. Due to the SARS-CoV-2 (coronavirus) epidemic, EDM 2020, as well as most other academic conferences in 2020, had to be changed to a purely online format. To facilitate efficient transmission of presentations all paper presenters pre-recorded their presentation as a video and then hosted it on YouTube with closed-captioning (CC). The official theme of this year's conference is Improving Learning Outcomes for All Learners. The theme comprises two parts: (1) Identifying actionable learning or teaching strategies that can be used to "improve" learning outcomes, not just predict them; (2) Using EDM to promote more "equitable" learning across diverse groups of learners, and to benefit underserved communities in particular. This year's conference features three invited talks: Alina von Davier, Chief Officer at ACTNext; Abelardo Pardo, Professor and Dean of Programs (Engineering), at UniSA STEM, University of South Australia; and Kobi Gal, Associate Professor at the Department of Software and Information Systems Engineering at Ben-Gurion University of the Negev, and Reader at the School of Informatics at the University of Edinburgh.},
  isbn = {9781733673617},
  keywords = {Anxiety,Artificial Intelligence,At Risk Students,Automation,Bayesian Statistics,Blended Learning,Collaborative Writing,College Admission,College Students,Competence,Computer Science Education,Computer Software,Cooperative Learning,Critical Theory,Cues,Curriculum,Data Analysis,Data Collection,Data Processing,Demography,Difficulty Level,Distance Education,Dropouts,Educational Assessment,Educational Improvement,Educational Technology,Electronic Publishing,Elementary Secondary Education,Employment Qualifications,Equal Education,Essays,Ethics,Eye Movements,Feedback (Response),Foreign Countries,Game Based Learning,Gender Differences,Grade 9,Handheld Devices,Higher Education,Information Retrieval,Information Sources,Innovation,Inquiry,Intelligent Tutoring Systems,Intervention,Item Response Theory,Large Group Instruction,Learner Engagement,Learning Strategies,Legal Responsibility,Masters Programs,Measurement Techniques,Mental Health,Middle School Students,Models,Natural Language Processing,Online Courses,Peer Evaluation,Peer Teaching,Performance,Personal Autonomy,Physics,Plagiarism,Prediction,Privacy,Problem Solving,Programming,Reaction Time,Reading Achievement,Reading Comprehension,Reinforcement,Remedial Reading,Scores,Scoring,Second Languages,Secondary Schools,Semitic Languages,Social Media,Social Networks,Spatial Ability,Student Attitudes,Student Behavior,Student Characteristics,Student Diversity,Student Motivation,Student Projects,Student Role,Success,Teaching Methods,Teamwork,Technical Writing,Telecommunications,Tests,Textbooks,Transformative Learning,Video Games,Video Technology,Visual Aids,Visualization},
  annotation = {ERIC Number: ED607784}
}

@article{Raskind.etal.2019,
  title = {A {{Review}} of {{Qualitative Data Analysis Practices}} in {{Health Education}} and {{Health Behavior Research}}},
  author = {Raskind, Ilana G. and Shelton, Rachel C. and Comeau, Dawn L. and Cooper, Hannah L. F. and Griffith, Derek M. and Kegler, Michelle C.},
  year = {2019},
  month = feb,
  journal = {Health Education \& Behavior},
  volume = {46},
  number = {1},
  pages = {32--39},
  issn = {1090-1981},
  abstract = {Data analysis is one of the most important, yet least understood, stages of the qualitative research process. Through rigorous analysis, data can illuminate the complexity of human behavior, inform interventions, and give voice to people's lived experiences. While significant progress has been made in advancing the rigor of qualitative analysis, the process often remains nebulous. To better understand how our field conducts and reports qualitative analysis, we reviewed qualitative articles published in "Health Education \& Behavior" between 2000 and 2015. Two independent reviewers abstracted information in the following categories: data management software, coding approach, analytic approach, indicators of trustworthiness, and reflexivity. Of the 48 (n = 48) articles identified, the majority (n = 31) reported using qualitative software to manage data. Double-coding transcripts was the most common coding method (n = 23); however, nearly one third of articles did not clearly describe the coding approach. Although the terminology used to describe the analytic process varied widely, we identified four overarching trajectories common to most articles (n = 37). Trajectories differed in their use of inductive and deductive coding approaches, formal coding templates, and rounds or levels of coding. Trajectories culminated in the iterative review of coded data to identify emergent themes. Few articles explicitly discussed trustworthiness or reflexivity. Member checks (n = 9), triangulation of methods (n = 8), and peer debriefing (n = 7) were the most common procedures. Variation in the type and depth of information provided poses challenges to assessing quality and enabling replication. Greater transparency and more intentional application of diverse analytic methods can advance the rigor and impact of qualitative research in our field.},
  langid = {english},
  keywords = {Coding,Computer Software,Credibility,Data Analysis,Educational Research,Health Behavior,Health Education,Health Promotion,Information Management,Journal Articles,Qualitative Research,Reliability,Research Design,Validity},
  annotation = {ERIC Number: EJ1202725}
}

@techreport{RochesterCitySchoolDistrict.1986,
  title = {Secondary {{School Profiles}}, 1985-1986. {{Rochester City School District}}. {{Includes New York State Comprehensive Assessment Report Data}}.},
  author = {Rochester City School District, N. Y.},
  year = {1986},
  abstract = {The 1985-86 profiles for the Rochester City School District's (New York) 11 secondary schools and four alternative program schools are tabulated in extensive charts. Information is provided on: (1) special instructional programs; (2) district achievement testing; (3) competency testing; (4) student attainment (percent of students enrolled in ninth grade Regents Level courses and passing ninth grade local courses, and graduation results); (5) Regents testing; (6) staff profiles; (7) average class size; and (8) demography. The latter describes student enrollment; number of students with limited English proficiency, handicaps, short) or long-term suspensions, or receiving free lunches; permits for open enrollment; the bilingual program; out-of-district, area, or zone attendance;  urban-suburban transfer; adjustment transfer; and the Major Achievement Program; attendance; student mobility; and dropouts. This information is also summarized for the district as a whole. (MGD)},
  keywords = {Academic Achievement,Achievement Tests,Enrollment Trends,Minimum Competency Testing,Profiles,School Demography,School Districts,School Statistics,Secondary Education,Secondary Schools,Student Characteristics,Tables (Data)},
  annotation = {ERIC Number: ED286888}
}

@article{Roegman.etal.2018,
  title = {Color-{{Neutral Disaggregation}}? {{Principals}}' {{Practices}} around {{Disaggregating Data}} from {{Three School Districts}}},
  author = {Roegman, Rachel and Samarapungavan, Ala and Maeda, Yukiko and Johns, Gary},
  year = {2018},
  month = oct,
  journal = {Educational Administration Quarterly},
  volume = {54},
  number = {4},
  pages = {559--588},
  issn = {0013-161X},
  abstract = {Purpose: We explored the practices and understandings around using disaggregated data to inform instruction of 18 principals from three Midwestern school districts. Research Method: This qualitative study used one-on-one semistructured interviews with the principals focusing on how they disaggregate data in practice. The protocol included general questions about principals' data practices as well as specific questions around disaggregation. Initial inductive coding began with principals' direct responses to specific questions around disaggregation, and then emerging themes were used to analyze the entire transcripts. Findings: Participants were more likely to talk about disaggregation in relation to performance (by teacher, by grade level, etc.) than by subgroup (by race/ethnicity, by gender, etc.). Further analysis highlighted principals' purposes for disaggregating data that focused on identifying low performance on standards-based assessments, as well as the challenges they faced, particularly in terms of technical skills and software. Implications for Research and Practice: We conclude with a discussion of how disaggregation could support or challenge equity-focused leadership, with implications for policy, practice, and preparation. We consider the role of the principal in identifying inequitable patterns versus focusing on individual students, and different ways that equity can become part of regular leadership practice.},
  langid = {english},
  keywords = {Academic Achievement,Accountability,Administrator Attitudes,Data Analysis,Decision Making,Educational Legislation,Educational Policy,Elementary Secondary Education,Equal Education,Federal Legislation,Instructional Leadership,Outcomes of Education,Phenomenology,Principals,School Districts,Standards,State Policy,Technological Literacy},
  annotation = {ERIC Number: EJ1190125}
}

@article{Rosenheck.etal.2021,
  title = {Approaches to {{Illuminate Content-Specific Gameplay Decisions Using Open-Ended Game Data}}},
  author = {Rosenheck, Louisa and Cheng, Meng-Tzu and Lin, Chen-Yen and Klopfer, Eric},
  year = {2021},
  month = apr,
  journal = {Educational Technology Research and Development},
  volume = {69},
  number = {2},
  pages = {1135--1154},
  issn = {1042-1629},
  abstract = {Games can be rich environments for learning and can elicit evidence of students' conceptual understanding and inquiry processes. Illuminating students' content-specific gameplay decisions, or methods of completing game tasks related to a certain domain, requires a context that is open-ended enough for students to make choices that demonstrate their thinking. Doing this also requires rich log data and methods of Game Learning Analytics (GLA) that are granular enough to look at the specific choices most relevant to that context and domain. This paper presents research done on student exploration of high school level Mendelian genetics in a multiplayer online game called "The Radix Endeavor." The study uses three approaches to identify content-specific gameplay decisions and distinguish players utilizing different methods, looking at actions and tool use, play patterns and player types, and tool input patterns. In the context of the selected game quest, the three approaches were found to yield insights into different ways that students complete tasks in genetics, suggesting the potential for a set of more generalized guiding questions in the GLA field that could be adopted by learning games designers and data scientists to convey information about content-specific gameplay decisions in learning games.},
  langid = {english},
  keywords = {Computer Games,Decision Making,Educational Games,Game Based Learning,Genetics,High School Students,Learning Analytics,Science Instruction,Secondary School Science,Student Behavior},
  annotation = {ERIC Number: EJ1296000}
}

@techreport{Ruberg.Moore.1995,
  title = {Visualizing {{Qualitative Data}} in a {{Study}} of {{Student Interactions}} within a {{Computer Mediated Environment}}.},
  author = {Ruberg, Laurie F. and Moore, D. Mike},
  year = {1995},
  abstract = {This paper discusses the visual organizers and graphic interfaces used to manage and report the findings from a 10-month ethnographic study of student participation and interaction in computer mediated communication (CMC) activities within the classrooms of both a freshman writing class and a plant science lab. The study focuses on social psychological issues, expressed in discourse created from computer-based interactions, from student survey self-reports, or from the observation and reporting process. It is contended that data analysis is problematic, since generation of data is affected by what the ethnographer can treat as writable, readable, visible, and interpretable, and analysis requires various visual organizers and graphic descriptions, the following of which are used  in this study: research questions; tables; quantitative coding of raw data; charts/tables; hypercard stacks; figures; digital photographs; and excerpts from computer-based discussions. Graphical interfaces for the following components of the study are discussed: interviews/field observation; surveys; videotape material; and electronic discussions. Discussion concentrates on graphical interfaces for electronic discussions, and includes issues such as coding data according to content description and affective quality, quantitative measure of network connections, and message act analysis. Data is illustrated in 6 figures. (Contains nine references.) (MAS)},
  keywords = {College Students,Computer Graphics,Computer Interfaces,Computer Mediated Communication,Computer Networks,Content Analysis,Data Analysis,Ethnography,Graphic Organizers,Higher Education,Student Participation,Surveys,Visual Arts},
  annotation = {ERIC Number: ED380071}
}

@article{Ruiz.Perkins.2020,
  title = {{{SpaceX Rocket Data Satisfies Elementary Hohmann Transfer Formula}}},
  author = {Ruiz, Michael J. and Perkins, James},
  year = {Article 025011 Mar 2020},
  journal = {Physics Education},
  volume = {55},
  number = {2},
  issn = {0031-9120},
  abstract = {The private company SpaceX regularly launches satellites into geostationary orbits. SpaceX posts videos of these flights with telemetry data displaying the time from launch, altitude, and rocket speed in real time. In this paper this telemetry information is used to determine the velocity boost of the rocket as it leaves its circular parking orbit around the Earth to enter a Hohmann transfer orbit, an elliptical orbit on which the spacecraft reaches a high altitude. A simple derivation is given for the Hohmann transfer velocity boost that introductory students can derive on their own with a little teacher guidance. They can then use the SpaceX telemetry data to verify the theoretical results, finding the discrepancy between observation and theory to be 3\% or less. The students will love the rocket videos as the launches and transfer burns are very exciting to watch.},
  langid = {english},
  keywords = {College Students,Equations (Mathematics),Mathematical Formulas,Measurement,Physics,Satellites (Aerospace),Science Instruction,Scientific Principles,Secondary School Science,Space Exploration,Video Technology},
  annotation = {ERIC Number: EJ1239955}
}

@techreport{Sable.2009,
  title = {Documentation to the {{NCES Common Core}} of {{Data Public Elementary}}/{{Secondary School Universe Survey}}: {{School Year}} 2006-07. {{Revised File Version}} 1c. {{NCES}} 2009-302 Rev},
  author = {Sable, Jennifer},
  year = {2009},
  institution = {{National Center for Education Statistics}},
  abstract = {The Common Core of Data (CCD) nonfiscal surveys consist of data submitted annually to the National Center for Education Statistics (NCES) by state education agencies (SEAs) in the 50 states, the District of Columbia, Puerto Rico, the four outlying areas (American Samoa, Guam, the Commonwealth of the Northern Mariana Islands, and the U.S. Virgin Islands), the Department of Defense (DoD) dependents schools (overseas and domestic), and the Bureau of Indian Education (BIE). In order to provide data comparable across states to the maximum extent feasible, NCES and representatives of the SEAs have worked since the 1950s to develop and accept common data items and definitions. School, agency, and state education data for the CCD are collected through the U.S. Department of Education's Education Data Exchange Network (EDEN). The data are edited by the U.S. Census Bureau and maintained in machine-readable datasets by NCES. They are used to produce general-purpose publications and specialized reports. The principal users of CCD nonfiscal data are the federal government; the education research community; state and local government officials, including school boards and local education agency (LEA) administrators; and the general public. The purpose of the CCD nonfiscal surveys is to provide a listing of all open schools and agencies providing free public elementary and secondary education, along with basic descriptive statistical information on each school and agency listed. The CCD includes all settings in which free public education is provided to children. However, some SEAs do not provide information on education outside of the traditional public school system--such as schools in correctional facilities or hospitals--while others do provide this information. The Public Elementary/Secondary School Universe file includes data for the following variables: NCES school ID number, state school ID number, name of the school, name of the agency that operates the school, mailing address, physical location address, phone number, school type, operational status, locale code, latitude, longitude, county number, county name, full-time-equivalent (FTE) classroom teacher count, low/high grade span offered, Congressional district code, school level , free lunch eligible students, reduced-price lunch eligible students, total free and reduced-price lunch eligible, migrant students enrolled in the previous year, student totals and detail (by grade, by race/ethnicity, and by gender), and pupil/teacher ratio. The file also contains flags indicating whether a school is Title I eligible, schoolwide Title I eligible, a magnet school, a charter school, and/or a shared time school. The remainder of this document contains a user's guide and four appendices. The user's guide contains information on CCD methodology, including certain conditions that are unique to this data file.},
  keywords = {Data Collection,Elementary Schools,Elementary Secondary Education,Ethnicity,Gender Differences,Geographic Location,Immigrants,Institutional Characteristics,National Surveys,Public Schools,Racial Differences,Records (Forms),Secondary Schools,Socioeconomic Status,Student Characteristics},
  annotation = {ERIC Number: ED591172}
}

@article{Sage.Rubenstein.1972,
  title = {Encounter {{Groups}} and {{Change}}: {{Behavioral}} or {{Self-Report Data}}?},
  author = {Sage, Ellis H. and Rubenstein, Alice},
  year = {1972},
  abstract = {In this study, two hypotheses were tested: (1) Self-report data are unrelated to behavior change; (2) Exposure to competent models of open and helpful behavior increases this skill performance in an encounter group. Two encounter groups were conducted with 18 college students who had the incentive to become more open, honest, and helpful. One group was presented with 1-hour of microlab activities; the other, 1-hour of video tape with instructions and modeling of open and helpful behavior. The Personal Orientation Inventory (POI) was administered before, following, and 3 weeks after each group. Behavioral rating forms for openness and helping were used 50 minutes of each hour by trained raters. The POI data indicated that all participants reported significant change in the  positive direction. No significant differences between groups were evident. Although self report data reflected no level effects, behavioral data reflected significant overall level effects on both combined openness and combined helping. The results of the study supported the hypotheses. Six references and 5 tables are included. (Author)},
  keywords = {Behavior Change,Behavioral Science Research,Data Analysis,Group Therapy,Models,Self Evaluation},
  annotation = {ERIC Number: ED070750}
}

@article{Saldana.2002,
  title = {Analyzing {{Change}} in {{Longitudinal Qualitative Data}}.},
  author = {Saldana, Johnny},
  year = {2002},
  journal = {Youth Theatre Journal},
  volume = {16},
  pages = {1--17},
  issn = {0892-9092},
  abstract = {Outlines inquiry-based methods for analyzing longitudinal qualitative data to assess participant changes in three long-term theater education studies. Encourages qualitative researchers in drama and theatre education to devote more extended periods of time to systematically observing young people or adult practitioners experiencing the art form. (PM)},
  langid = {english},
  keywords = {Academic Achievement,Audience Response,Drama,Educational Research,Elementary Secondary Education,Instructional Effectiveness,Longitudinal Studies,Professional Development,Qualitative Research,Research Methodology,Urban Schools},
  annotation = {ERIC Number: EJ653495}
}

@phdthesis{Scavuzzo-Despagni.2011,
  title = {The {{Experiences}} of {{Middle School Students Using Data}} in an {{Eighth Grade Mathematics Classroom}}},
  author = {{Scavuzzo-Despagni}, Patricia},
  year = {2011},
  abstract = {In education, there is an increasing emphasis on the use of data in schools. Data are reported on academic achievement in school report cards each year. Administrators use data for curricular and evaluative purposes. Teachers are provided with data to improve their pedagogy. All of this data is based on student academic performance; however, students rarely ever see or use any of the data. Students have limited access to their own data and yet they are under tremendous pressure to perform well and demonstrate growth in achievement each year. Ultimately, there is a current focus of students as producers of data with a lack of attention on students as consumers of data. With limited access to their own data, there is little research on students using data. This study, therefore, fills a void in the current research on students using data.    A quasi-experimental mixed methods research design was used to explore students' experiences in using data in a mathematics classroom, their attitudes in using data, and how it affected their learning experience. Ninety-six eighth grade middle school students from a Nassau County, Long Island, suburban, middle school participated in the study, 49 in an intervention group and 47 in a control group. Quantitative data were collected through a survey that measured attitudes towards mathematics. In addition, academic performance on New York State Assessments, midterm exams, and final exams were collected on student participants in order to compare the control group and the intervention group and to see differences in performance based on gender, math support, and math course. Qualitative data were collected through interviews and focus groups from students in the intervention group. In addition, archival and anecdotal data were also collected.    This research study revealed an overall positive experience in students receiving data on their mathematical academic performance throughout the year. Students gained a better understanding of the data analysis process, became more self-aware of their personal math ability, became empowered as a learner, used data to be more time efficient in their study, and expressed a positive emotional impact as a result of using data in their mathematics class. The use of data was also found to have an impact on attitudes towards mathematics as well as on academic achievement.    Exploring student use of data is critical today, as accountability is the cornerstone of education today. Students need to take on a greater responsibility for their learning and we have not given them the opportunity to do so. It is our responsibility to allow students access to their data and train them how to use it in such a way to improve their learning. This is the future of assessment and it is important for us to understand the power of putting the learning into the hand of students. Students and teachers need to work together as they gather data, create meaning of data, and provide appropriate feedback to each other in order to impact learning. This research will hope to inspire students and teachers to work together in a partnership of data users.    [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {9781124973449},
  school = {Hofstra University},
  keywords = {Attitude Measures,Comparative Analysis,Data Analysis,Feedback (Response),Focus Groups,Grade 8,Grades (Scholastic),Interviews,Mathematics Achievement,Mathematics Instruction,Middle School Students,Program Effectiveness,Report Cards,Scores,Secondary School Mathematics,Student Attitudes},
  annotation = {ERIC Number: ED534607}
}

@article{Schmucker.etal.2022,
  title = {Assessing the {{Performance}} of {{Online Students--New Data}}, {{New Approaches}}, {{Improved Accuracy}}},
  author = {Schmucker, Robin and Wang, Jingbo and Hu, Shijia and Mitchell, Tom M.},
  year = {2022},
  journal = {Journal of Educational Data Mining},
  volume = {14},
  number = {1},
  pages = {1--45},
  issn = {2157-2100},
  abstract = {We consider the problem of assessing the changing performance levels of individual students as they go through online courses. This student performance modeling problem is a critical step for building adaptive online teaching systems. Specifically, we conduct a study of how to utilize various types and large amounts of log data from earlier students to train accurate machine learning models that predict the performance of future students. This study is the first to use four very large sets of student data made available recently from four distinct intelligent tutoring systems. Our results include a new machine learning approach that defines a new state of the art for logistic regression based student performance modeling, improving over earlier methods in several ways: First, we achieve improved accuracy of student modeling by introducing new features that can be easily computed from conventional question-response logs (e.g., features such as the pattern in the student's most recent answers). Second, we take advantage of features of the student history that go beyond question-response pairs (e.g., features such as which video segments the student watched, or skipped) as well as background information about prerequisite structure in the curriculum. Third, we train multiple specialized student performance models for different aspects of the curriculum (e.g., specializing in early versus later segments of the student history), then combine these specialized models to create a group prediction of the student performance. Taken together, these innovations yield an average AUC score across these four datasets of 0.808 compared to the previous best logistic regression approach score of 0.767, and also outperforming state-of-the-art deep neural net approaches. Importantly, we observe consistent improvements from each of our three methodological innovations, in each diverse dataset, suggesting that our methods are of general utility and likely to produce improvements for other online tutoring systems as well.},
  langid = {english},
  keywords = {Academic Achievement,Artificial Intelligence,Electronic Learning,Elementary Secondary Education,Foreign Countries,Intelligent Tutoring Systems,Models,Predictor Variables},
  annotation = {ERIC Number: EJ1352163}
}

@phdthesis{Schultz.2019,
  title = {Why {{Parents}} of {{Student}} with {{Disabilities Enrolled Their Child}} in an {{Online Virtual Charter School}}: {{Using Extant Data}}},
  author = {Schultz, Andrew J.},
  year = {2019},
  abstract = {School choice is a long-standing tradition in the United States. New to the options available to K-12 parents are full-time virtual schools, and this option is an even more recent development for parents of students with disabilities. Very little research exists on why parents are choosing full-time virtual education for their school-aged children, and almost no research exists on why parents of students with disabilities (Grades K-12) are choosing this option. This descriptive, nonexperimental exploratory study sought to answer the following research questions: (1) What factors led parents to enroll their child with disabilities in an online virtual charter school?; (2) Were these factors attributable to positive characteristics of the virtual charter school in which the child was enrolling, or were the factors attributable to negative characteristics of the school the child was leaving?; and (3) Do the factors identified by parents vary by parents' race/ethnicity, parent educational levels, or student disability? This study suggests that parents of student with disabilities students chose a virtual charter school for their children due to pull factors related to California Connections Academy (CALCA). Specifically, parents seemed most interested in being able to individualize education for their children and being able to instill their values in their children by educating them at home. Emphases on teaching the basics and on teacher quality were also important factors for parents. Attention should also be given to the several factors (bullying, Special Education/504 Plans, teacher attributes, and quality curriculum) that parents took extra effort to mention in the open-ended response items. Implications for practice, future research, and policy are discussed. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {9781085654838},
  langid = {english},
  school = {California State Polytechnic University},
  keywords = {Charter Schools,Decision Making,Elementary Secondary Education,Individualized Instruction,Influences,Parent Attitudes,School Choice,Students with Disabilities,Virtual Schools},
  annotation = {ERIC Number: ED618340}
}

@article{Schwartz.Barbera.2014,
  title = {Evaluating the {{Content}} and {{Response Process Validity}} of {{Data}} from the {{Chemical Concepts Inventory}}},
  author = {Schwartz, Paul and Barbera, Jack},
  year = {2014},
  month = may,
  journal = {Journal of Chemical Education},
  volume = {91},
  number = {5},
  pages = {630--640},
  issn = {0021-9584},
  abstract = {Data produced by psychometric instruments are often used to inform understanding about a certain population's knowledge of ideas or perspectives about specific topics. Concept inventories are an example of psychometric instruments used to probe students' content knowledge within a defined framework. Concept inventories have been used as a measure of student understanding in science education for over two decades. The Chemical Concepts Inventory (CCI), published in 2002, is one of the most often referenced inventories in chemical education. However, not until the past year has detailed psychometric evidence been published about data from the instrument. Although this prior study focused on quantitative evidence to support the CCI as a whole, there are still no qualitative studies published to investigate the reasoning behind students' responses. Therefore, the purpose of this study was to examine the response process validity of the CCI in order to understand the nature of student responses. In addition to evaluating individual items, this study examined the content validity of the CCI as a whole instrument. To do this, a survey was employed to understand expert judgments about the content being covered on the CCI. This information was used to group items by content prior to investigating student responses. It was found that a majority of the content on the CCI was limited to only two concepts (phase change and conservation of mass-matter). Student reasoning for their responses to items from these groupings was examined through think-aloud interviews. Both support for and threats to the response process validity for several items was observed. The results from this qualitative investigation can be used as a guide to improving the current CCI items, writing new items, and for the development of other concept inventories.},
  langid = {english},
  keywords = {Chemistry,College Science,Content Validity,Course Content,High Schools,Misconceptions,Psychometrics,Qualitative Research,Science Education,Scientific Concepts,Secondary School Science,Statistical Analysis,Surveys,Test Items,Test Validity,Undergraduate Study},
  annotation = {ERIC Number: EJ1032369}
}

@article{Setiawan.Sukoco.2021,
  title = {Exploring {{First Year University Students}}' {{Statistical Literacy}}: {{A Case}} on {{Describing}} and {{Visualizing Data}}},
  author = {Setiawan, Ezra Putranda and Sukoco, Heru},
  year = {2021},
  month = sep,
  journal = {Journal on Mathematics Education},
  volume = {12},
  number = {3},
  pages = {427--448},
  issn = {2087-8885},
  abstract = {Statistical literacy, which is the ability to use statistics in daily life, is an essential skill for facing society 5.0. This study aims to explore first-year university students' ability to properly use simple descriptive statistics and data visualization. Qualitative data were collected using a set of questions from 39 undergraduate students. Many students were able to calculate various descriptive statistics, but some of them were still unable to determine suitable statistics to describe the data clearly. Related to data visualization, many students failed to provide a meaningful chart that effectively shows the difference between two groups of data. Students with higher statistical literacy tend to use comparison or variability reasoning to determine the usage of descriptive statistics, and use data-based reason in visualizing the data. Improvement in statistical teaching -- both in the university and the secondary school -- is needed so that the students can use descriptive statistics and data visualization correctly.},
  langid = {english},
  keywords = {College Freshmen,Data Analysis,Foreign Countries,Statistics Education,Student Attitudes,Visual Aids},
  annotation = {ERIC Number: EJ1339553}
}

@phdthesis{Smiley.2009,
  title = {Characteristics of {{Systems}} and {{Leadership}} in {{K-12 Public School Educational Technology Programs}}: {{Understanding Data Use}}, {{Decision Making}}, and {{Contextual Factors}}},
  author = {Smiley, Robert W.},
  year = {2009},
  abstract = {This qualitative, multi-case research study examines how leaders use data to inform decisions related to technology use, including how they use enGauge program evaluation data, identifies leadership practices and related contextual factors present in four K-12 public school districts. This research study examines the questions:    What are the characteristics of systems and leadership in identified K-12 public schools with reputations for strong educational technology use? Specifically, (1) in what ways do leaders in these identified schools leverage enGauge program evaluation data to inform technology policy and practice? (2) what leadership practices and contextual factors are evident in these identified schools that support strong educational technology use?    Ten emerging themes and major program attributes emerged from this research. Necessary leadership qualities, or leadership areas to leverage, from the study include: (1) a vision for educational technology use for all students by all teachers; (2) accountability to achieve the vision; (3) leveraging the role of the Library Media Specialist(s) and the passionate advocate(s); (4) creating a viable funding model for acquiring and maintaining technology; (5) providing professional development for leaders with position authority concerning data-driven decision making techniques and strategies; (6) attention to creating classroom and common areas that promote educational technology use through building construction and renovation projects; and (7) working with State and Federal leaders to develop and implement policies that have a positive impact educational technology use.    This case study of four K-12 public school districts identifies educational technology leadership best practices and major program attributes that are data driven, research informed, and connected to high-quality programs, relevant to local, state, and national application. Future research should examine these findings in light of new and emerging technologies, the increased role of state and federal governments, and the continued worldwide movement towards a technology- and information-rich global society.    [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.},
  isbn = {9781109660036},
  school = {The University},
  keywords = {Administrator Characteristics,Best Practices,Decision Making,Educational Research,Educational Technology,Effective Schools Research,Elementary Secondary Education,Inferences,Information Utilization,Institutional Characteristics,Management Information Systems,Performance Factors,Public Schools,School Districts,Technology Uses in Education,Theory Practice Relationship,Use Studies},
  annotation = {ERIC Number: ED515294}
}

@article{Snodgrass.etal.2020,
  title = {An {{Iterative Approach}} to {{Qualitative Data Analysis}}: {{Using Theme}}, {{Cultural Models}}, and {{Content Analyses}} to {{Discover}} and {{Confirm}} a {{Grounded Theory}} of {{How Gaming Inculcates Resilience}}},
  author = {Snodgrass, Jeffrey G. and Clements, Kaylin R. and Nixon, William Cody and Ortega, Cynthia and Lauth, Samantha and Anderson, Michelle},
  year = {2020},
  month = nov,
  journal = {Field Methods},
  volume = {32},
  number = {4},
  pages = {399--415},
  issn = {1525-822X},
  abstract = {We present a qualitative data analysis framework that integrates perspectives from theme analysis, cultural models analysis, grounded theory, and content analysis. We demonstrate how these research traditions are united in their aim to, first, uncover meaningful themes and, subsequently, to understand those themes' relationships to each other. To illustrate our approach, we present research on video gamers' understandings of productive and detrimental responses to failure. Initial themes, cultural models, and grounded theory analysis of 10 semi-structured interviews led us to the theory that video games help players learn to cope more productively with failure, which we confirmed in a subsequent content analysis of text extracts from an online survey (N = 64). Overall, we propose that commonly employed approaches for analyzing qualitative data can be usefully conceptualized as research steps or stages, which move from the initial identification of themes to understanding their relationships, and from inductive exploration to deductive confirmation.},
  langid = {english},
  keywords = {Content Analysis,Coping,Data Analysis,Failure,Grounded Theory,Models,Qualitative Research,Resilience (Psychology),Responses,Social Science Research,Video Games},
  annotation = {ERIC Number: EJ1265021}
}

@article{Stamper.etal.2014,
  title = {Proceedings of the {{Seventh International Conference}} on {{Educational Data Mining}} ({{EDM}}) (7th, {{London}}, {{United Kingdom}}, {{July}} 4-7, 2014)},
  author = {Stamper, John and Pardos, Zachary and Mavrikis, Manolis and McLaren, Bruce M.},
  year = {2014},
  journal = {International Educational Data Mining Society},
  abstract = {The 7th International Conference on Education Data Mining held on July 4th-7th, 2014, at the Institute of Education, London, UK is the leading international forum for high-quality research that mines large data sets in order to answer educational research questions that shed light on the learning process. These data sets may come from the traces that students leave when they interact, either individually or collaboratively, with learning management systems, interactive learning environments, intelligent tutoring systems, educational games or when they participate in a data-rich learning context. The types of data therefore range from raw log files to eyetracking devices and other sensor data. Being hosted in London, UK the theme of the conference is "Big Data--Big Ben--Education Data Mining for Big Impact in Teaching and Learning". In this seventh year of EDM conferences, it is clear that the field is continuing to grow at a rapid pace. With renewed focus on education driven by big data learning analytics has put the EDM field in the center of growing interest. Traditional educational technologies, intelligent tutoring systems, educational games, and learning management systems all continue to generate growing amounts of data that are becoming available for analysis. The new interest in MOOCs and their promise to reach thousands or even hundreds of thousands of students per class requires techniques for feedback and grading that are being researched in the EDM domain. The conference submissions this year also continue to grow. A tremendous amount of work has gone into bringing this conference together, and the following are presented: (1) The Field of EDM: Where We Came from and Where We're Going (Joseph Beck); (2) Generative Adaptivity for Optimization of the Learning Ecosystem (Zoran Popovic; (3) 150K+ Online Students at a Time: How to Understand What's Happening in Online 4 Learning (Daniel Russell); (4) Adaptive Practice of Facts in Domains with Varied Prior Knowledge (Jan Papou\v{s}ek, Radek Pel\'anek and V\'it Stanislav); (5) Alternating Recursive Method for Q-Matrix Learning (Yuan Sun, Shiwei Ye, Shunya Inoue and Yi Sun); (6) Application of Time Decay Functions and the Elo System in Student Modeling (Radek Pel\'anek); (7) Causal Discovery with Models: Behavior, Affect, and Learning in Cognitive Tutor Algebra (Stephen Fancsali); (8) Choice-Based Assessment: Can Choices Made in Digital Games Predict 6th-Grade Students' Math Test Scores? (Min Chi, Daniel Schwartz, Kristen Pilner Blair and Doris B. Chin); (9) Comparing Expert and Metric-Based Assessments of Association Rule Interestingness (Diego Luna Bazaldua, Ryan Baker and Maria Ofelia San Pedro); (10) Different Parameters - Same Prediction: An Analysis of Learning Curves (Tanja K\"aser, Kenneth Koedinger and Markus Gross); (11) Discovering Gender-Specific Knowledge from Finnish Basic Education Using PISA Scale Indices (Mirka Saarela and Tommi K\"arkk\"ainen); (12) EduRank: A Collaborative Filtering Approach to Personalization in E-Learning (Avi Segal, Ziv Katzir, Kobi Gal, Guy Shani and Bracha Shapira); (13) Exploring Differences in Problem Solving with Data-Driven Approach Maps (Michael Eagle and Tiffany Barnes); (14) General Features in Knowledge Tracing: Applications to Model Multiple Subskills, Temporal Item Response Theory, and Expert Knowledge (Jos\'e Gonz\'alez-Brenes, Yun Huang and Peter Brusilovsky); (15) Generating Hints for Programming Problems Using Intermediate Output ( Barry Peddycord III, Andrew Hicks and Tiffany Barnes); (16) Integrating Latent-Factor and Knowledge-Tracing Models to Predict Individual Differences in Learning (Mohammad Khajah, Rowan Wing, Robert Lindsey and Michael Mozer); (17) Interpreting Model Discovery and Testing Generalization to a New Dataset (Ran Liu, Elizabeth A. McLaughlin and Kenneth R. Koedinger); (18) Learning Individual Behavior in an Educational Game: A Data-Driven Approach (Seong Jae Lee, Yun-En Liu and Zoran Popovic); (19) Predicting Learning and Affect from Multimodal Data Streams in Task-Oriented Tutorial Dialogue (Joseph Grafsgaard, Joseph Wiggins, Kristy Elizabeth Boyer, Eric Wiebe and James Lester); (20) Sentiment Analysis in MOOC Discussion Forums: What does It Tell Us? (Miaomiao Wen, Diyi Yang and Carolyn Rose); (21) The Effect of Mutual Gaze Perception on Students' Verbal Coordination (Bertrand Schneider and Roy Pea); (22) The Opportunities and Limitations of Scaling Up Sensor-Free Affect Detection (Michael Wixon, Ivon Arroyo, Kasia Muldner, Winslow Burleson, Cecil Lozano and Beverly Woolf); (23) The Problem Solving Genome: Analyzing Sequential Patterns of Student Work with Parameterized Exercises (Julio Guerra, Shaghayegh Sahebi, Peter Brusilovsky and Yu-Ru Lin); (24) Trading Off Scientific Knowledge and User Learning with Multi-Armed Bandits (Yun-En Liu, Travis Mandel, Emma Brunskill and Zoran Popovic); (25) Vertical and Stationary Scales for Progress Maps (Russell Almond, Ilya Goldin, Yuhua Guo and Nan Wang); (26) Visualization and Confirmatory Clustering of Sequence Data from a Simulation- Based Assessment Task (Yoav Bergner, Zhan Shu and Alina von Davier); (27) Who's in Control?: Categorizing Nuanced Patterns of Behaviors within a Game- Based Intelligent Tutoring System (Erica Snow, Laura Allen, Devin Russell and Danielle McNamara); (28) Acquisition of Triples of Knowledge from Lecture Notes: A Natural Language Processing Approach (Thushari Atapattu, Katrina Falkner and Nickolas Falkner); (29) Towards Assessing Students' Prior Knowledge from Tutorial Dialogues (Dan Stefanescu, Vasile Rus and Art Graesser); (30) Assigning Educational Videos at Appropriate Locations in Textbooks (Marios Kokkodis, Anitha Kannan and Krishnaram Kenthapadi) (31) Better Data Beats Big Data (Michael Yudelson, Stephen Fancsali, Steven Ritter, Susan Berman, Tristan Nixon and Ambarish Joshi); (32) Building a Student At-Risk Model: An End-to-End Perspective (Lalitha Agnihotri and Alexander Ott); (33) Can Engagement be Compared? Measuring Academic Engagement for Comparison (Ling Tan, Xiaoxun Sun and Siek Toon Khoo); (34) Comparison of Algorithms for Automatically Building Example-Tracing Tutor Models (Rohit Kumar, Matthew Roy, Bruce Roberts and John Makhoul); (35) Computer-Based Adaptive Speed Tests (Daniel Bengs and Ulf Brefeld); (36) Discovering Students' Complex Problem Solving Strategies in Educational Assessment (Krisztina T\'oth, Heiko R\"olke, Samuel Greiff and Sascha W\"ustenberg); (37) Discovering Theoretically Grounded Predictors of Shallow vs. Deep-Level Learning (Carol Forsyth, Arthur Graesser, Philip I. Pavlik Jr., Keith Millis and Borhan Samei); (38) Domain Independent Assessment of Dialogic Properties of Classroom Discourse (Borhan Samei, Andrew Olney, Sean Kelly, Martin Nystrand, Sidney D'Mello, Nathan Blanchard, Xiaoyi Sun, Marci Glaus and Art Graesser); (39) Empirically Valid Rules for Ill-Defined Domains (Collin Lynch and Kevin Ashley); (40) Entropy: A Stealth Measure of Agency in Learning Environments (Erica Snow, Matthew Jacovina, Laura Allen, Jianmin Dai and Danielle McNamara); (41) Error Analysis as a Validation of Learning Progressions (Brent Morgan, William Baggett and Vasile Rus); (42) Exploration of Student's Use of Rule Application References in a Propositional Logic Tutor (Michael Eagle, Vinaya Polamreddi, Behrooz Mostafavi and Tiffany Barnes); (43) Exploring Real-Time Student Models Based on Natural-Language Tutoring Sessions (Benjamin Nye, Mustafa Hajeer, Carolyn Forsyth, Borhan Samei, Xiangen Hu and Keith Millis); (44) Forum Thread Recommendation for Massive Open Online Courses (Diyi Yang, Mario Piergallini, Iris Howley and Carolyn Rose); (45) Investigating Automated Student Modeling in a Java MOOC (Michael Yudelson, Roya Hosseini, Arto Vihavainen and Peter Brusilovsky); (46) Mining Gap-Fill Questions from Tutorial Dialogues (Nobal B. Niraula, Vasile Rus, Dan Stefanescu and Arthur C. Graesser); (47) Online Optimization of Teaching Sequences with Multi-Armed Bandits (Benjamin Clement, Pierre-Yves Oudeyer, Didier Roy and Manuel Lopes); (48) Predicting MOOC Performance with Week 1 Behavior (Suhang Jiang, Adrienne Williams, Katerina Schenke, Mark Warschauer and Diane O'Dowd); (49) Predicting STEM and Non-STEM College Major Enrollment from Middle School Interaction with Mathematics Educational Software (Maria Ofelia San Pedro, Jaclyn Ocumpaugh, Ryan Baker and Neil Heffernan); (50) Quantized Matrix Completion for Personalized Learning (Andrew Lan, Christoph Studer and Richard Baraniuk); (51) Reengineering the Feature Distillation Process: A Case Study in Detection of Gaming the System (Luc Paquette, Adriana de Carvahlo, Ryan Baker and Jaclyn Ocumpaugh); (52) SKETCHMINER: Mining Learner-Generated Science Drawings with Topological Abstraction (Andy Smith, Eric N. Wiebe, Bradford W. Mott and James C. Lester); (53) Teachers and Students Learn Cyber Security: Comparing Software Quality, Security (Shlomi Boutnaru and Arnon Hershkovitz); (54) Testing the Multimedia Principle in the Real World: A Comparison of Video vs. Text Feedback in Authentic Middle School Math Assignments (Korinn Ostrow and Neil Heffernan); (55) The Importance of Grammar and Mechanics in Writing Assessment and Instruction: Evidence from Data Mining (Scott Crossley, Kris Kyle, Laura Allen and Danielle McNamara); (56) The Long and Winding Road: Investigating the Differential Writing Patterns of High and Low Skilled Writers (Laura Allen, Erica Snow and Danielle McNamara); (57) The Refinement of a Q-Matrix: Assessing Methods to Validate Tasks to Skills Mapping (Michel Desmarais, Behzad Beheshti and Peng Xu); (58) Tracing Knowledge and Engagement in Parallel in an Intelligent Tutoring System (Sarah Schultz and Ivon Arroyo); (59) Tracking Choices: Computational Analysis of Learning Trajectories (Erica Snow, Laura Allen, G.Tanner Jackson and Danielle McNamara); (60) Unraveling Students' Interaction Around a Tangible Interface Using Gesture Recognition (B},
  isbn = {9780983952541},
  keywords = {Academic Achievement,Academic Persistence,Affective Behavior,Algebra,Asynchronous Communication,Behavior,Blended Learning,Case Studies,Causal Models,Classification,Classroom Communication,Coding,Cognitive Processes,College Attendance,Comparative Analysis,Computer Assisted Testing,Computer Mediated Communication,Computer Peripherals,Computer Security,Computer Software,Cooperative Learning,Correlation,Cost Effectiveness,Course Evaluation,Data Analysis,Data Collection,Data Processing,Developmental Studies Programs,Diagnostic Tests,Dropouts,Educational Environment,Educational Games,Educational Objectives,Educational Research,Electronic Learning,Electronic Publishing,Emotional Response,Error Patterns,Essays,Evaluation Methods,Experiential Learning,Eye Movements,Factor Analysis,Feedback (Response),Foreign Countries,Freehand Drawing,Gender Differences,Generalization,Grade 6,Grading,Grammar,Graphs,Group Discussion,Group Dynamics,Homework,Hypothesis Testing,Incentives,Individual Differences,Individualized Instruction,Information Retrieval,Integrated Learning Systems,Intelligent Tutoring Systems,Interaction,Item Response Theory,Knowledge Level,Large Group Instruction,Learner Engagement,Learning Experience,Learning Modalities,Learning Processes,Learning Theories,Lecture Method,Logical Thinking,Majors (Students),Maps,Mathematics,Mathematics Achievement,Mathematics Education,Mathematics Instruction,Matrices,Measurement Techniques,Middle Schools,Models,Natural Language Processing,Nonmajors,Nonverbal Communication,Online Courses,Peer Evaluation,Peer Influence,Planning,Prediction,Prior Learning,Problem Solving,Programming,Questioning Techniques,Reading Comprehension,Remedial Mathematics,Research Methodology,Risk,Science Instruction,Scientific Concepts,Scores,Self Esteem,Self Evaluation (Individuals),Sequential Approach,Simulation,Standardized Tests,Standards,Statistical Analysis,STEM Education,Student Attrition,Student Behavior,Student Characteristics,Student Evaluation,Student Motivation,Student Reaction,Teaching Methods,Tests,Textbooks,Topology,Undergraduate Study,Verbal Ability,Video Games,Video Technology,Visual Aids,Visualization,Writing Evaluation,Writing Instruction,Writing Skills},
  annotation = {ERIC Number: ED558339}
}

@techreport{Starr.1987,
  title = {Increasing {{Vocational Program Relevance}}: {{A Data-based Approach}}. {{Research}} and {{Development Series No}}. 264.},
  author = {Starr, Harold},
  year = {1987},
  abstract = {This guide is intended for local- and state-level vocational education administrators, planners, and evaluators who are responsible for making program planning and evaluation findings and decisions geared toward increasing program relevance. The method differs from more traditional approaches in its heavy reliance upon the selection and application of quantitative as opposed to qualitative, judgmental, or intuitive data. Individuals using this evaluation method must (1) explicitly specify the relative importance they attribute to planning and evaluation components and to the kinds of data they select for use with the methodology and (2) value data quality. The introductory section of the guide includes an overview of the method, background information on the development of the  method, and a description of the guide's intended audience. The second chapter covers design specifications, the procedures entailed in using the method (the information and data selection framework and the scoring and ranking processes used), and the role of the microcomputer in increasing the efficiency of the method's ranking process. The third section, which describes one example of implementation of the method, includes sections dealing with the following: site, ranking process, and grand labor market area context description (context for employment, employers' needs for workers, people's needs for jobs, and capacity to meet needs for training). Appendixes include examples of the following: information categories; performance indicators, measures, and scores; and databases and  sources. (MN)},
  keywords = {Computer Oriented Programs,Data Analysis,Data Interpretation,Databases,Evaluation Criteria,Evaluation Methods,Microcomputers,Models,Needs Assessment,Norms,Outcomes of Education,Program Development,Program Evaluation,Program Improvement,Relevance (Education),Secondary Education,Statewide Planning,Statistical Analysis,Vocational Education},
  annotation = {ERIC Number: ED284978}
}

@techreport{Stringfield.Others.1986,
  title = {School {{Improvement Efforts}}: {{Qualitative Data}} from {{Four Naturally Occurring Experiments}} in {{Phase III}} of the {{Louisiana School Effectiveness Study}}.},
  author = {Stringfield, Sam and Others, And},
  year = {1986},
  abstract = {Phase III of the Louisiana School Effectiveness Study (LSES-III) was designed in part to obtain rich, qualitative data on the characteristics of more and less effective schools in the Gulf South. Data were gathered on eight matched outlier pairs of schools during the 1984-1985 school year. Of the eight historically ineffective schools in LSES-III, four were actively engaged in school improvement efforts during the study. None of these efforts was dictated from the state or district; none was externally funded. This serendipity provided an opportunity to observe improvement efforts which were of the "naturally occurring"--as opposed to externally developed, mandated or otherwise offered--variety. The four projects are described in this paper. The suggestion is made that they fall  along two independent dimensions: Technical vs. Programmatic change efforts, and efforts focused on a point along a continuum ranging from orderliness to excellence. Comparisons and contrasts to the more frequently studied, formally planned and conducted school improvement efforts are made. (Author/LMO)},
  keywords = {Achievement Gains,Data Collection,Educational Change,Elementary Secondary Education,Evaluation,Field Studies,Grade 3,Naturalistic Observation,Qualitative Research,Research Methodology,Rural Schools,School Effectiveness,Standardized Tests,Urban Schools},
  annotation = {ERIC Number: ED275742}
}

@article{Swygart-Hobaugh.etal.2022,
  title = {Diving {{Deep}} into {{Dissertations}}: {{Analyzing Graduate Students}}' {{Methodological}} and {{Data Practices}} to {{Inform Research Data Services}} and {{Subject Liaison Librarian Support}}},
  author = {{Swygart-Hobaugh}, Mandy and Anderson, Raeda and George, Denise and Glogowski, Joel},
  year = {2022},
  month = nov,
  journal = {College \& Research Libraries},
  volume = {83},
  number = {6},
  pages = {887--904},
  issn = {2150-6701},
  abstract = {We present findings from an exploratory quantitative content analysis case study of 156 doctoral dissertations from Georgia State University that investigates doctoral student researchers' methodology practices (used quantitative, qualitative, or mixed methods) and data practices (used primary data, secondary data, or both). We discuss the implications of our findings for provision of data support services provided by the Georgia State University Library's Research Data Services (RDS) Team and subject liaison librarians in the areas of instructional services, data software support and licensing advocacy, collection development, marketing/outreach, and professional development/expansion.},
  langid = {english},
  keywords = {Academic Libraries,Data Analysis,Data Collection,Data Processing,Doctoral Dissertations,Doctoral Students,Intellectual Disciplines,Library Services,Research Methodology},
  annotation = {ERIC Number: EJ1365730}
}

@techreport{Talmage.Rasher.1981,
  title = {Quantifying {{Qualitative Data}}: {{The Best}} of {{Both Worlds}}.},
  author = {Talmage, Harriet and Rasher, Sue Pinzur},
  year = {1981},
  abstract = {An approach for merging quantitative-qualitative data in order to enlarge the evaluators' perspective and provide an enriched data base for evaluating elusive evaluation problems in school settings is described. Mini-case studies were conducted over a period of three years in 11 urban schools to examine the impact of an arts-in-the-schools program and identify the cluster of factors that impede or enhance successful implementation and program effects. The replicable model for conducting mini-case studies and analyzing within and across school data illustrates that quantitative and qualitative data are integrative and serve a confirmatory purpose. Both qualitative and quantitative data have inherent limitations, however; integration of the two will extend the scope of the data  base. Integration of the two types can generate new variables. Abandoning the view of quantitative and qualitative data as dichotomous permits the development of synthesizing methods for discerning program effects in an organized, rational, scientific manner. (Author/GK)},
  keywords = {Case Studies,Data Collection,Elementary Secondary Education,Evaluation Methods,Longitudinal Studies,Models,Program Evaluation,Quasiexperimental Design,Urban Schools},
  annotation = {ERIC Number: ED204396}
}

@article{Tanner.Collins.2021,
  title = {Using {{Publicly Available Long-Term Climate Records}} in {{Undergraduate Interdisciplinary Big Data Curriculum}}},
  author = {Tanner, Richelle L. and Collins, Lisa E.},
  year = {2021},
  month = nov,
  journal = {Journal of College Science Teaching},
  volume = {51},
  number = {2},
  pages = {51--55},
  issn = {0047-231X},
  abstract = {Understanding data analysis and interpreting data are key components of teaching interdisciplinary undergraduate students. We detail a semester-long research project that introduces students to long-term data sets, incorporates the use of widely available statistical analysis, and underscores an inquiry-based method of teaching climate change. Our learning objectives included analysis of large-scale climate data and interpretation of empirical trends in the context of two climate change phenomena: warming and the urban heat island effect. We demonstrate how small groups of students (n = 2 or 3) were empowered to independently download and analyze long-term temperature data to be aggregated into a class data set. Students used the National Centers for Environmental Information (NCEI) to find the long-term data sets of hourly maximum (TMAX) and minimum (TMIN) temperatures. Students used the open-source statistical software R to manage and summarize data. Students also examined changes in land use cover using Google Earth satellite data to quantify whether stations were urban or rural. Students were assessed in their groups based on a research paper and a class presentation. Approaching climate change education from the inquiry-based learning perspective allows students to understand how scientific research is conducted, apply the scientific method, and experience firsthand the importance of open-source data.},
  langid = {english},
  keywords = {Active Learning,Climate,College Science,Data Analysis,Data Interpretation,Data Use,Environmental Education,Inquiry,Interdisciplinary Approach,Outcomes of Education,Research Projects,Science Instruction,Undergraduate Students},
  annotation = {ERIC Number: EJ1327140}
}

@article{Taylor.2011,
  title = {{{UK Schools}}, {{CCTV}} and the {{Data Protection Act}} 1998},
  author = {Taylor, Emmeline},
  year = {2011},
  month = jan,
  journal = {Journal of Education Policy},
  volume = {26},
  number = {1},
  pages = {1--15},
  issn = {0268-0939},
  abstract = {The use of CCTV in schools is now commonplace in the UK. It is estimated that 85\% of all UK secondary schools currently have CCTV systems in operation. The introduction of the Data Protection Act 1998 (DPA) (enacted in March 2000) meant that for the first time CCTV had direct legislation governing its use in the UK. This paper attempts to apply the decree to the widespread introduction of CCTV technology in schools and argues that the various elements of statute are impractical or inappropriate to educational institutions. The ill-defined and vague legislation presented in the DPA 1998 provides very little protection to the data subjects in schools (mainly pupils and teachers). In addition, the ubiquity of CCTV in schools in the UK far surpasses the enforcement capabilities and resources of the Information Commissioner's Office and as such any contravention of the scant provisions of the Act is likely to go unidentified and under-enforced. In consideration of the DPA, the paper elucidates numerous examples to suggest that a large number of schools are in contravention of the law. The paper outlines the need for bespoke policy to govern and regulate the use of CCTV in schools. Whilst the paper focuses on the case of the UK, it speaks to an international audience in concluding that the use of CCTV and surveillance technologies in schools requires greater scrutiny and regulation. (Contains 1 table and 16 notes.)},
  langid = {english},
  keywords = {Administrative Principles,Educational Legislation,Educational Policy,Foreign Countries,Information Management,Information Policy,Information Processing,Information Technology,Law Enforcement,Policy Analysis,Privacy,Safety Equipment,School Safety,Video Technology},
  annotation = {ERIC Number: EJ912304}
}

@article{Thomson.Others.1990,
  title = {The {{Placement}} of {{Pupils Recorded}} as {{Having Special Educational Needs}}: {{An Analysis}} of {{Scottish Data}}, 1986-1988.},
  author = {Thomson, George O. B. and Others, And},
  year = {1990},
  journal = {Oxford Review of Education},
  volume = {16},
  number = {2},
  pages = {159--177},
  issn = {0305-4985},
  abstract = {Combines qualitative and quantitative Scottish data to analyze the frequency of mainstreaming for special needs students from 1986 through 1988. Records of Needs as legislated by the 1981 Education (Scotland) Act, and interviews with educational professionals, provided data. Shows mainstreaming more likely for students with physical or sensory handicaps from specific geographic locations. (CH)},
  langid = {english},
  keywords = {Access to Education,Educational Legislation,Educational Policy,Educational Research,Elementary Secondary Education,Foreign Countries,Geographic Location,Interviews,Longitudinal Studies,Mainstreaming,Parent Role,Special Education,Special Needs Students,Statistical Analysis,Student Placement},
  annotation = {ERIC Number: EJ422089}
}

@article{Toker.Green.2021,
  title = {A {{Comparison}} of {{Latent Class Analysis}} and the {{Mixture Rasch Model Using}} 8th {{Grade Mathematics Data}} in the {{Fourth International Mathematics}} and {{Science Study}} ({{TIMSS-2011}})},
  author = {Toker, Turker and Green, Kathy},
  year = {2021},
  journal = {International Journal of Assessment Tools in Education},
  volume = {8},
  number = {4},
  pages = {959--974},
  issn = {2148-7456},
  abstract = {This study provides a comparison of the results of latent class analysis (LCA) and mixture Rasch model (MRM) analysis using data from the Trends in International Mathematics and Science Study -- 2011 (TIMSS-2011) with a focus on the 8th-grade mathematics section. The research study focuses on the comparison of LCA and MRM to determine if results obtained differ when the assumed psychometric model differs. Also, a log-linear analysis was conducted to understand the interactions between latent classes identified by LCA and MRM. Response data to the three booklets were used to run latent class analysis using Mplus 7.31 (Muth\'en \& Muth\'en, 2012a) for LCA and WINMIRA (von Davier, 2001a). The findings of this paper do not reveal unequivocally whether a model based on primarily qualitative differences (LCA), that is, different strategies, instructional differences, curriculum etc. or a model including additional factors of quantitative differences within strategies (MRM) should be used with this particular dataset. Both of the tests provided similar results with more or less similar interpretations. Both techniques fit the data similarly, a result found in prior research. Nonetheless, for tests similar to TIMSS exams, item difficulty parameters can be useful for educational researchers giving potential priority to use of MRM.},
  langid = {english},
  keywords = {Achievement Tests,Educational Research,Elementary Secondary Education,Foreign Countries,Grade 8,International Assessment,Item Response Theory,Mathematics Achievement,Mathematics Tests,Multivariate Analysis,Psychometrics,Structural Equation Models,Test Validity},
  annotation = {ERIC Number: EJ1329345}
}

@article{Towse.etal.2022,
  title = {{{LUSTRE}}: {{An Online Data Management}} and {{Student Project Resource}}},
  author = {Towse, John and Davies, Rob and Ball, Ellie and James, Rebecca and Gooding, Ben and Ivory, Matthew},
  year = {2022},
  journal = {Journal of Statistics and Data Science Education},
  volume = {30},
  number = {3},
  pages = {266--273},
  issn = {2693-9169},
  abstract = {We advocate for greater emphasis in training students about data management, within the context of supporting experience in reproducible workflows. We introduce the "L"ancaster "U"niversity "ST"atistics "RE"sources (LUSTRE) package, used to manage student research project data in psychology and build capacity with respect to data acumen. LUSTRE provides a safe space to engage students with open research practices--by making tangible different phases of the reproducible research pipeline, while emphasizing its value as a transferable skill. It is an open-source online data catalogue that captures key data management information about a student research project of potential relevance to data scientists. Embedded within a taught programme, it also highlights concepts and examples of data management processes. We document a portfolio of open teaching resources for LUSTRE, and consider how others can implement or adapt them to facilitate data management and open research. We discuss the role of LUSTRE as a; (a) resource and set of activities for promoting good data management practices; (b) framework to enable the delivery of key concepts in open research; (c) an online system to organize and showcase project work.},
  langid = {english},
  keywords = {Best Practices,Data Analysis,Data Science,Graduate Students,Information Management,Open Source Technology,Research Projects,Scientific Research,Shared Resources and Services,Statistics Education,Student Research},
  annotation = {ERIC Number: EJ1371460}
}

@techreport{Turner.1997,
  title = {Secondary {{Analysis}} of {{Qualitative Data}}.},
  author = {Turner, Paul D.},
  year = {1997},
  abstract = {The reanalysis of data to answer the original research question with better statistical techniques or to answer new questions with old data is not uncommon in quantitative studies. Meta analysis and research syntheses have increased with the increase in research using similar statistical analyses, refinements of analytical techniques, and the advent of computerized literature searches. No analogous definition of secondary data analysis from a qualitative point of view has been proposed, but the primary component would include analysis by a researcher removed from the process to continue the original analysis to address different questions or to use different methods to address the original research question. Discussion is just beginning about the possibilities of secondary  analysis of qualitative data. A typology of secondary analysis of qualitative data is proposed that includes secondary analysis, meta-analysis, and collaboration for qualitative inquiry. A classification of models for research synthesis for qualitative study can be conceived of as a series of cells that embody the time of the analysis, reanalysis, and the data set or sets. Because qualitative analysis is very time intensive, considerable savings might be realized with reanalysis of existing data sets. Issues involved in the accessibility of research, its validation, and the education of researchers are discussed, as are concerns about the limitations of reanalysis of qualitative studies. (Contains 2 tables, 4 figures, 4 charts, and 62 references.) (SLD)},
  keywords = {Classification,Meta Analysis,Qualitative Research,Research Methodology,Synthesis},
  annotation = {ERIC Number: ED412231}
}

@article{VanGasse.etal.2017,
  title = {Individual, {{Co-Operative}} and {{Collaborative Data Use}}: {{A Conceptual}} and {{Empirical Exploration}}},
  author = {Van Gasse, Roos and Vanlommel, Kristin and Vanhoof, Jan and Van Petegem, Peter},
  year = {2017},
  month = jun,
  journal = {British Educational Research Journal},
  volume = {43},
  number = {3},
  pages = {608--626},
  issn = {0141-1926},
  abstract = {In recent decades, the belief has originated that data use contributes to more thought-out decisions in schools. The literature has suggested that fruitful data use is often the result of interactions among team members. However, up until now, most of the available research on data use has used "collaboration" as an umbrella concept to describe very different types of interaction, without specifying the nature of collaboration or the degree of interdependency that takes place in interactions. Therefore, the current study investigates and describes Flemish teachers' individual, co-operative and collaborative data use. In doing so, the level of interdependency of teachers' interactive activities (storytelling, helping, sharing, joint work) is taken into account. The results of a qualitative study with semi-structured interviews show that teachers' data use is predominantly of an individual nature and that felt interdependencies among teachers are few. The study enhances knowledge and opens the conceptual debate about teachers' interactions in the context of data use.},
  langid = {english},
  keywords = {Data,Foreign Countries,Information Utilization,Interaction,Qualitative Research,Semi Structured Interviews,Teacher Collaboration},
  annotation = {ERIC Number: EJ1143488}
}

@phdthesis{Wards.2022,
  title = {Tell {{Me Sumthin Good}}: {{Leader Narratives}} to {{Understand Data Use}} in {{Black School Communities}}},
  author = {Wards, Ronetta Paresi},
  year = {2022},
  abstract = {Schooling experiences for Black students in the US have been shaped historically by anti-education laws, mandates, and initiatives that sustain unjust systemic practices and policies. These practices and policies often stagnate academic progress and have led to institutional deficits and the normalization of deficit-orientations towards students in predominantly Black schools. Accountability expectations set forth by federal legislation is just one example of how educational policy play a role in sustained deficit orientations toward Black schools through the utility of student performance information. State education agencies use student performance information from annual assessments to grade, categorize, and make decisions around support resources for students. This annual data snapshot also determine funding and shape the allocation of resources for schools despite their need to support students in non-academic ways. Currently, student performance information is constructed in a way that provide a singular view of student performance information based on proficiency leveling and categorical grouping of students. This grouping is centered on students' lack of skill and in turn automatically posits them in a place of deficit within the data. This view of data also shape the way school leaders draw on, make sense of and interact with data toward decision-making to improve educational outcomes. A new approach is needed to inform leadership decision making and support for alternative perspectives with data use to overcome institutional deficits and ineffective use of data in Black schools. The purpose of this study was to understand the sensemaking of data use through the stories told by school leaders in predominantly Black schools. This study used conceptual frames associated with sensemaking theory (Weick, 1995), school leader sensemaking theory (Gannon-Shilon \& Schechter, 2017) and data use theory (Coburn \& Turner, 2012) as guardrails to better understand elementary school leaders and their data use practices. Data use in school leadership is significant and can serve as a strategy to improve instructional practice. School leaders who have advanced data literacy skill sets can leverage student performance information (data) in ways that bring about insight (knowledge) to inform their leadership practice. School leaders are responsible for many aspects of the school operation and classroom instruction plays a major role toward improvement efforts. The improvement of instructional practice can lead to better educational outcomes for students in Black school communities. This study sought to capture the stories told by school leaders, specifically leaders in predominantly Black schools. This research study aimed to better understand how leaders accessed, interacted with, acted on and made sense of their data use practices toward the improvement of educational outcomes in their school. The main research question that guided this study was: (1) How do the stories of elementary school leaders serving in predominantly Black school communities explain how data is used to make decisions toward educational improvement? This study also sought to answer the following sub- questions: (1) What stories do elementary school leaders tell about how they use data to inform their leadership practice? (2) What contextual factors influence school leader interactions with data? In the analysis of the data, two different approaches helped to arrive at a broadened view of the data. In the first approach, leader stories were restoried and aligned to themes set forth by Clandinin and Connolly's (2000) three-dimensional narrative structure; interaction, continuity, and situation to view their experiences along a continuum. In the second approach, an open qualitative analysis was conducted and the leader stories were posited as data for interpretation. The findings brought forth a rich description of the leader's experience from two distinct analytical perspectives. The participant stories situated in the context of Black school communities provided a glimpse into the benefits and challenges leaders faced with data use towards educational improvement. Through these stories their voices are centered to offer insight into how data use practice can either help or hinder their improvement efforts. This knowledge is significant in that it can be transferable to other education spaces to inform policy at large and potentially re-story the public discourse around educational improvement in ethnically diverse school communities. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {9798438748007},
  school = {Michigan State University},
  keywords = {Academic Achievement,African American Students,Data Use,Decision Making,Educational Improvement,Educational Policy,Elementary Schools,Influences,Leadership,Outcomes of Education,Personal Narratives},
  annotation = {ERIC Number: ED625100}
}

@article{Waterhouse.etal.2022,
  title = {"{{Jeg Skal Sjekke}}": {{Urban Buggy-Wayfaring}} and {{Adventurous Lines}} with {{Data-ing}} and {{Reconfigurations}} of {{Children}}},
  author = {Waterhouse, Ann-Hege Lorvik and Otterstad, Ann Merete and Boucher, Kelly},
  year = {2022},
  month = sep,
  journal = {Contemporary Issues in Early Childhood},
  volume = {23},
  number = {3},
  pages = {220--236},
  issn = {1463-9491},
  abstract = {In this article, the authors experiment with data-ing as a methodology, and wonder how three researchers?--?two in Oslo (Norway) and one in Melbourne (Australia)?--?can come closer to-with the research material by following and buggy-walking a young wayfarer in urban spaces and places. The ideas of not knowing and experimenting, making-with urban landscapes, transportation, materials, sounds, surfaces, bodily movements, minor gestures, and haptic engagement, transform their thinking about data-ing as research-creation while traveling and walking the city with a buggy and a young wayfarer's adventure. Their experimental method uses smartphones and digital technology, and the methodological contours in this article are attuned to and engage in and with multiple surfaces of an urban city landscape. Lines and threads transform into traces and create surfaces, and lines transforming into threads dissolve surfaces. The authors create city maps and investigate what digital tools, social media, and a chat service can generate and unfold when wayfaring locally and talking and writing across continents. Their project follows two layers?--?doing data-ing as research-creation and wayfaring. To do data-ing as collective open-ended productions among researchers invites one to ask what happened and what might occur temporally in cities as minor gestures here and there. The bodily movement offered by an urban wayfarer invites the authors to speculate with what the phenomenon of an investigator, an artist, a maker, a runner, or an activist can unfold in the moments to come.},
  langid = {english},
  keywords = {Children,Computer Mediated Communication,Data,Foreign Countries,Human Body,Learning Modalities,Maps,Nonverbal Communication,Philosophy,Photography,Poetry,Qualitative Research,Research Methodology,Social Media,Urban Areas},
  annotation = {ERIC Number: EJ1354761}
}

@article{Wayman.etal.2017,
  title = {Longitudinal {{Effects}} of {{Teacher Use}} of a {{Computer Data System}} on {{Student Achievement}}},
  author = {Wayman, Jeffrey C. and Shaw, Shana and Cho, Vincent},
  year = {2017},
  month = jan,
  journal = {AERA Open},
  volume = {3},
  number = {1},
  issn = {2332-8584},
  abstract = {Does data use make a difference in student achievement? Despite the field's optimism on this matter, relatively few studies have attempted to quantify the effects of data use. These studies have often used the presence of a data use intervention (e.g., a data system or data coaching) as a proxy for use, as opposed to tracking teachers' direct interactions with data, via data system click logs, for example. Accordingly, the present study sought to address this methodological gap by exploring the 2-year effects of data use through a multilevel cross-classified model of teachers' system interactions and student achievement. A significant relationship was found between system use and elementary reading, but no significant relationships were found for elementary math, junior high math, or junior high reading. The implications of this study on how to conceptualize and measure use, as well as how to support practitioners, are discussed.},
  langid = {english},
  keywords = {Academic Achievement,Computer Uses in Education,Data,Decision Making,Elementary School Students,Elementary School Teachers,Information Systems,Intervention,Junior High School Students,Longitudinal Studies,Mathematics Achievement,Models,Reading Achievement,Secondary School Teachers},
  annotation = {ERIC Number: EJ1194175}
}

@article{White.etal.2022,
  title = {Investigating {{Groundwater}}: {{Middle School Students}}' {{Mapping Data-Driven}}, {{Computer-Based Models}} to {{Socio-Hydrologic Phenomena}}},
  author = {White, Holly and Lally, Diane and Forbes, Cory T.},
  year = {2022},
  journal = {Journal of Geoscience Education},
  volume = {70},
  number = {1},
  pages = {101--113},
  issn = {1089-9995},
  abstract = {Groundwater is a critical component of the global water cycle and standards-based topic within science education. However, students articulate an array of ideas about groundwater systems, including their natural and human elements. One way to support students' learning about groundwater systems is through the use of data-driven, computer-based modeling tools in technology-enabled science learning environments. To use models to reason productively about groundwater, students must be able to interpret the relationship between the model and the phenomena it represents. Here, we report findings from a study conducted in 7th-grade classrooms (n = 209) during implementation of a 3-week curriculum module designed around a data-driven, computer-based groundwater modeling tool -- the Hydrogeology Challenge. Students completed a series of tasks using the model to reason about and engage in problem-solving about a real-world, scenario-based water challenge. Here, we focus on how students relate -- or map -- elements of the model to the components of the authentic water-related phenomena they represent. We conducted quantitative and qualitative analyses of student artifacts and interviews. Findings suggest that students could more easily interpret and understand model elements which represent human dimensions of groundwater systems, such as wells, than they could elements that represent natural dimensions and processes, such as contour lines or groundwater flow direction. These findings provide important insights into students' model-based reasoning about groundwater and teaching and learning about coupled human-hydrological systems.},
  langid = {english},
  keywords = {Computer Assisted Instruction,Earth Science,Grade 7,Middle School Students,Models,Natural Resources,Science Process Skills,Secondary School Science,Topography,Water},
  annotation = {ERIC Number: EJ1329578}
}

@article{Williams.1986,
  title = {Data {{Book}} of {{Social Studies Materials}} and {{Resources}}. {{Volume}} 11.},
  author = {Williams, Ann M.},
  year = {1986},
  abstract = {Analyses of elementary and secondary social studies textbooks, supplementary materials, and teacher resource materials, all published in 1984 and 1985, are presented. The objective is to provide a review of curriculum materials which will allow K-12 teachers, administrators, curriculum coordinators, and college methods teachers to select appropriate materials for their students, school, and community. Analyses of curriculum materials are divided into sections by grade-level clusters. Thus, the first major section contains analyses of elementary (K-6) social studies materials. The second major section of the book is devoted to secondary (7-12) curriculum materials; 18 new analyses of basal programs are presented with 3 shorter analyses of revised editions. The secondary curriculum  materials section concludes with 39 brief descriptions of supplementary materials. These supplementary items include video cassettes, filmstrips, and audio cassettes. Materials appropriate for both elementary and secondary students appear in the elementary section and are cross-referenced in the secondary section. The third section includes 21 short analyses of teacher resource materials. Twenty-four social studies curriculum guides or units, identified through the ERIC system, are described in the fourth section. Indexes are provided for author/editor/developer; grade level; publisher; and subject area. A list of publishers' addresses concludes the publication. (LH)},
  isbn = {0899943047},
  keywords = {Book Reviews,Content Analysis,Curriculum Guides,Elementary Secondary Education,Instructional Material Evaluation,Instructional Materials,Readability,Resource Materials,Social Studies,Supplementary Reading Materials,Textbook Content,Textbook Evaluation,Textbooks},
  annotation = {ERIC Number: ED268022}
}

@article{Willis.etal.2016,
  title = {Ethical {{Oversight}} of {{Student Data}} in {{Learning Analytics}}: {{A Typology Derived}} from a {{Cross-Continental}}, {{Cross-Institutional Perspective}}},
  author = {Willis, James E. and Slade, Sharon and Prinsloo, Paul},
  year = {2016},
  month = oct,
  journal = {Educational Technology Research and Development},
  volume = {64},
  number = {5},
  pages = {881--901},
  issn = {1042-1629},
  abstract = {The growth of learning analytics as a means to improve student learning outcomes means that student data is being collected, analyzed, and applied in previously unforeseen ways. As the use of this data continues to shape academic and support interventions, there is increasing need for ethical reflection on "operational" approvals for learning analytics research. Though there are clear processes for vetting studies resulting in publication of student-gathered data, there is little comparable oversight of "internally" generated student-focused research. Increasingly, ethical concerns about the collection and harvesting of student data have been raised, but there is no clear indication how to address or oversee these ethical concerns. In addition, staff members who are not "typical" researchers may be less familiar with approvals processes and the need to demonstrate potential for harm, etc. If current trends point to a range of individuals harvesting and analyzing student data (mostly without students' informed consent or knowledge), how can the real danger of unethical behavior be curbed to mitigate the risk of unintended consequences? A systematic appraisal of the policy frameworks and processes of ethical review at three research institutions (namely, the University of South Africa, the Open University in the United Kingdom, and Indiana University in the United States) provides an opportunity to compare practices, values, and priorities. From this cross-institutional review, a working typology of ethical approaches is suggested within the scope of determining the moral intersection of internal student data usage and application.},
  langid = {english},
  keywords = {Case Studies,Data Analysis,Data Collection,Educational Research,Ethics,Foreign Countries,Moral Values,Qualitative Research,Research Universities,Researchers,School Policy},
  annotation = {ERIC Number: EJ1117302}
}

@phdthesis{Wilson-Cortez.2013,
  title = {A {{Case Study}} of {{High School Teachers}}' {{Technology Use}} through {{Social Studies Data Teams}}},
  author = {{Wilson-Cortez}, Lauretta},
  year = {2013},
  abstract = {Many schools placed under Program Improvement because they have not met the AYP requirements of the NCLB mandate are required to build in time during the school day for teachers' professional collaboration to improve their performance in the classrooms. A lack of research exists to explore how professional collaboration improves teaching and learning. This qualitative case study is an examination of teachers' perceptions of the value of professional collaborative time and the effectiveness of working together to integrate technology into their daily practice as part of a reform effort. The conceptual framework was Vygotsky's zone of proximal development, Gardner's multiple intelligences theory, and Senge's systems theory. Participants in the study were 6 high school teachers who had participated in data teams for 7 years. Data sources included 2 in-depth interviews with each participant and minutes for data team meetings. A combination of a priori and open coding was used to develop rich themes and patterns. Findings suggested that participants valued the professional collaboration they found in the data teams and were willing to follow a technology leader who mentored them as they adapted to new technologies. The teachers became dependent in using technology for lesson delivery and analyzing student data, but barriers prevented them from further technology integration or transitioning to student use of technology. Positive social change may occur as school leaders and district policy makers promote consistent time for teacher collaboration during the school day. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  isbn = {9781303110504},
  school = {Walden University},
  keywords = {Barriers,Case Studies,Developmental Stages,Educational Change,Educational Indicators,Educational Legislation,Federal Legislation,Federal Programs,High School Students,Interviews,Learning Theories,Meetings,Mentors,Multiple Intelligences,Program Improvement,Qualitative Research,Secondary School Teachers,Social Status,Systems Approach,Teacher Attitudes,Teacher Collaboration,Teamwork,Technology Integration,Technology Uses in Education},
  annotation = {ERIC Number: ED553799}
}

@article{Yorek.Ugulu.2015,
  title = {A {{CFBPN Artificial Neural Network Model}} for {{Educational Qualitative Data Analyses}}: {{Example}} of {{Students}}' {{Attitudes Based}} on {{Kellerts}}' {{Typologies}}},
  author = {Yorek, Nurettin and Ugulu, Ilker},
  year = {2015},
  month = sep,
  journal = {Educational Research and Reviews},
  volume = {10},
  number = {18},
  pages = {2606--2616},
  issn = {1990-3839},
  abstract = {In this study, artificial neural networks are suggested as a model that can be "trained" to yield qualitative results out of a huge amount of categorical data. It can be said that this is a new approach applied in educational qualitative data analysis. In this direction, a cascade-forward back-propagation neural network (CFBPN) model was developed to analyze categorical data for determine students' attitudes. The data were collected using a conceptual understanding test which includes open-ended questions. The results of this study indicate that using CFBPN model in analyzing data from educational research examining attitudes, behaviors, or beliefs may help us obtain more detailed information about the data analyzed and hence about the characteristics of the participants involved.},
  langid = {english},
  keywords = {Artificial Intelligence,Biology,Classification,Concept Formation,Educational Research,Foreign Countries,High School Students,Interviews,Models,Networks,Participant Characteristics,Qualitative Research,Scientific Concepts,Statistical Analysis,Student Attitudes,Tests},
  annotation = {ERIC Number: EJ1078385}
}

@article{Zehner.etal.2021,
  title = {Applying {{Psychometric Modeling}} to {{Aid Feature Engineering}} in {{Predictive Log-Data Analytics}}: {{The NAEP EDM Competition}}},
  author = {Zehner, Fabian and Eichmann, Beate and Deribo, Tobias and Harrison, Scott and Bengs, Daniel and Andersen, Nico and Hahnel, Carolin},
  year = {2021},
  journal = {Journal of Educational Data Mining},
  volume = {13},
  number = {2},
  pages = {80--107},
  issn = {2157-2100},
  abstract = {The NAEP EDM Competition required participants to predict efficient test-taking behavior based on log data. This paper describes our top-down approach for engineering features by means of psychometric modeling, aiming at machine learning for the predictive classification task. For feature engineering, we employed, among others, the Log-Normal Response Time Model for estimating latent person speed, and the Generalized Partial Credit Model for estimating latent person ability. Additionally, we adopted an "n"-gram feature approach for event sequences. Furthermore, instead of using the provided binary target label, we distinguished inefficient test takers who were going too fast and those who were going too slow for training a multi-label classifier. Our best-performing ensemble classifier comprised three sets of low-dimensional classifiers, dominated by test-taker speed. While our classifier reached moderate performance, relative to the competition leaderboard, our approach makes two important contributions. First, we show how classifiers that contain features engineered through literature-derived domain knowledge can provide meaningful predictions if results can be contextualized to test administrators who wish to intervene or take action. Second, our re-engineering of test scores enabled us to incorporate person ability into the models. However, ability was hardly predictive of efficient behavior, leading to the conclusion that the target label's validity needs to be questioned. Beyond competition-related findings, we furthermore report a state sequence analysis for demonstrating the viability of the employed tools. The latter yielded four different test-taking types that described distinctive differences between test takers, providing relevant implications for assessment practice.},
  langid = {english},
  keywords = {Classification,Competition,Data Analysis,Data Collection,Elementary School Students,Engineering Education,Item Response Theory,National Competency Tests,Prediction,Psychometrics,Response Style (Tests),Secondary School Students,Test Items},
  annotation = {ERIC Number: EJ1320539}
}
